<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />   <!--It is necessary to use the UTF-8 encoding with plotly graphics to get e.g. negative signs to render correctly -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Visualisation of Alignment Survey</title>
</head>

<body>
    <h1>Visualisation of Alignment Survey</h1>
    <h2>Papers from each year (2022-2025)</h2>
    <div>                        <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.3.1.min.js" integrity="sha256-4rD3fugVb/nVJYUv5Ky3v+fYXoouHaBSP20WIJuEiWg=" crossorigin="anonymous"></script>                <div id="3e0056ba-c9a9-427f-a885-ddc501c66626" class="plotly-graph-div" style="height:700px; width:900px;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("3e0056ba-c9a9-427f-a885-ddc501c66626")) {                    Plotly.newPlot(                        "3e0056ba-c9a9-427f-a885-ddc501c66626",                        [{"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"bias","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"cultural","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"culture","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"demographics","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"diversity","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"ethical","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"factuality","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"faithfulness","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"general","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"hate","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"humor","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"language","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"legal","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"length","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"moral","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"multilingual","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"offensiveness","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"opinions","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"personalization","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"political","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"safety","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"sexism","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"social","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"toxicity","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"value","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"hoverinfo":"text","hovertext":["Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2022"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity","showlegend":false,"visible":true,"x":{"dtype":"f8","bdata":"EU27ud8s+z8="},"y":{"dtype":"f8","bdata":"zXT3fnzIA0A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general","showlegend":false,"visible":true,"x":{"dtype":"f8","bdata":"\u002fx4FgrpI9L\u002fuOI6VfQrzv2SwPsMzwvG\u002fOoEpSdLk3L8="},"y":{"dtype":"f8","bdata":"bdIhgk4FBkA3MYhOwSUGQDztOiYh2AlA8Ubxac4ZBUA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral","showlegend":false,"visible":true,"x":{"dtype":"f8","bdata":"jRsMvXGrBsA="},"y":{"dtype":"f8","bdata":"3CjHoYKm7r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization","showlegend":false,"visible":true,"x":{"dtype":"f8","bdata":"G1klQviu2r8="},"y":{"dtype":"f8","bdata":"Jn6H+R\u002fMCcA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"P145c1EYCkA="},"y":{"dtype":"f8","bdata":"bvK0vnxj2j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2023"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"OeP4qyQ39T8="},"y":{"dtype":"f8","bdata":"BBdvQnmUBkA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"5rEVjsrI0z8="},"y":{"dtype":"f8","bdata":"avWx4VQBC0A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"m4IR5lJ\u002f978ilVAPNYv2v6aqSHe+Ofe\u002fm3bahv68678kwQ4tH031v+c1Fx67Wea\u002fLQzGbaV48b\u002fOq9wuL4nyv8fqcEE4RfK\u002f8HUWEyNx9r9sGmayuVbzvw=="},"y":{"dtype":"f8","bdata":"JmRy4oHjAUBdp8RVzDsEQE9+OqBoeAVAeyjuuOdRBUB1Z6JqXCsIQCZr5EiLkARAmD7QIKSwB0BqD02pCz8JQP42ja7BYwVAoqlsxP8ACUDaYC162a4BQA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"ut2M+CMjBcA="},"y":{"dtype":"f8","bdata":"N\u002ftJK\u002fof7r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"Tub5Psok478="},"y":{"dtype":"f8","bdata":"zIKf26suAsA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"+brSr4UbBUCc+HcdYz3rP1jRZ01sV\u002fo\u002fzh3hm++Q9T\u002f2JChKHtMBQEZrDH1pHfQ\u002f7BWtG7G6AkAZSfoFA0cDQMGZ\u002fd05xfc\u002fyYKg9OtY\u002fj+3L8sIjwn+P2ZWqDklAQRAILDdcijk9j\u002ffzdKbu+wHQKX+yAYm+AJA4K0b9o\u002fSpD+RcQDvJwTgP9HtmU7rpwVA"},"y":{"dtype":"f8","bdata":"cLO6mEjm3L9DE4jbyEHLv+R\u002f1ZsJyfm\u002f+S8M262uzb\u002fzaTTuiXXEv4J3oExKArI\u002ftd0UoNT94D\u002f7pVTMvXyhvw69awAz7rq\u002fEpvcEYRs979gPcqrLhL0v1S5wZYDUfE\u002fOC8Oju\u002fYx79XItQBdT7hPy4Hyhxz\u002fPI\u002fqhe7Ls3J8r8UA5eE7Nzwv9gT0Bs4ZfM\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2024","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2024"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"hIA1I8nUCUATbQC2TfYFQPHvDI6ZygdA+brSr4UbBUCc+HcdYz3rP6kvnxZXS+0\u002fvE+UQcwFBkBGawx9aR30P9\u002fN0pu77AdAmkY144W2wz8ukdrqvSbAP5SbvIBpGuU\u002fywjFZvhyB0AZkExeVQQHQMwz13+YR98\u002f"},"y":{"dtype":"f8","bdata":"DYfPYIMN4D+1JXUurOjqP9HrOliJE9w\u002fcLO6mEjm3L9DE4jbyEHLv6k9ZTq4Ge6\u002fJWr2DZbv2L+Cd6BMSgKyP1ci1AF1PuE\u002fAIDhItfw9L8Z5ISQq\u002fXNv6WbrTlN1PA\u002fL4ADB0wN8D8DT+Lg3+byP\u002fRqqQamTPM\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2024","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"37ti3escAkDOHeGb75D1P\u002fYkKEoe0wFA7BWtG7G6AkAZSfoFA0cDQMGZ\u002fd05xfc\u002fXzNx38KHAEBmVqg5JQEEQNHtmU7rpwVA"},"y":{"dtype":"f8","bdata":"2Mqtr7Z8+j\u002f5Lwzbra7Nv\u002fNpNO6JdcS\u002ftd0UoNT94D\u002f7pVTMvXyhvw69awAz7rq\u002fEPW4m9P+A0BUucGWA1HxP9gT0Bs4ZfM\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2024","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2024","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2024","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"\u002fe7RShH9\u002fz9CimAqrJL4P6fL2GGaS+U\u002fXzNx38KHAECl\u002fsgGJvgCQJSbvIBpGuU\u002f"},"y":{"dtype":"f8","bdata":"C+AVVsDKA0Cwf7pCoD2pP8tFgAkMBtK\u002fEPW4m9P+A0AuB8occ\u002fzyP6WbrTlN1PA\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"u8Hbly6B6z8D4dge8sPsPw=="},"y":{"dtype":"f8","bdata":"f7hHgEwF7L8J3yCJ4nkFQA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"UD1B6TJC1D8ePW8rS3TgP6J9\u002fMsE8uo\u002fMenCm2d33D+rVNb7U13PP66J8sfmpsm\u002fHhAsJ18j4z+CQKl\u002fwFvqP67nBlvVzeI\u002fILDdcijk9j+t7YF0RFTIP7Q9PIvZjeI\u002fK5kyQ6MJ0D9bk1ZH3tbRP+aoOn8iedY\u002f"},"y":{"dtype":"f8","bdata":"iW0v9nr0B0BoE1\u002fqmQAMQCK+V0fv09U\u002fCm5JtdzqBEDgs\u002fSUAwgJQKtv9xNjIAdAvP7qKjvwBkCEuwd4PWvJP+e8a6L9+QpAOC8Oju\u002fYx7+sncr3SlwFQNb1FRiONQNA5T79m\u002fl8CUD0ABqqTMEGQNpmEMkpYwVA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2024","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"jK\u002fdR4Lv878JfXbHU7Lwv+P4uJjUAPO\u002fLJ6A\u002fcrR9r8LW9N0hZfxv7Pzu+2bwvK\u002forfNLxsg8r8soRfhECf2v8+YbOhVSPe\u002fhMLx+gJD9b9j\u002f7VLZXX0v1CkQh2rQP+\u002fkYQgEf3g87+KjHCZhOP5vwwuhaELpfK\u002f\u002f2\u002fKohDk479lsoWbeYD5vxMF9maNBfi\u002fnwvSvC9c+r\u002fqxIilOpTvvwDUFEf4DvS\u002fhBiW3epb1b\u002fWIyubNF\u002f2vw=="},"y":{"dtype":"f8","bdata":"yAXDowx4CUDLeIV1IlsHQIF4S4bNIgZAFCbHB2tdBUDafEsVI2EFQJEB+fVVNgVA\u002f\u002fcqW5auAkA\u002fz1\u002frd6YFQIR1srx+5gNAYCJcJgmiBUAKp+pYMxADQGu91e2NawZA4M3ovq9kBUDywH\u002fvccsDQJYPQ86quwVAaEZD4YmhBUBJsHO+9BAFQMRTUhwP\u002fAVA8SJc7u2XB0D03X6tymwHQHJ7kdeZ0QVAgh9CU4uXv7+NRYE99yMHQA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2024"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"8ihDasTQwL8="},"y":{"dtype":"f8","bdata":"5nGR2GOc3L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2024"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"gMtL1Nzr\u002fL8="},"y":{"dtype":"f8","bdata":"B\u002fs58kDm\u002fz8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2024"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"zDPXf5hH3z8="},"y":{"dtype":"f8","bdata":"9GqpBqZM8z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"p9p+aR4bB8Cc+HcdYz3rP0ZrDH1pHfQ\u002fLpHa6r0mwD\u002fgrRv2j9KkP5SbvIBpGuU\u002fkXEA7ycE4D\u002fjaOKzJycHwGzjVjfuGgbA"},"y":{"dtype":"f8","bdata":"AO6PBqCT8L9DE4jbyEHLv4J3oExKArI\u002fGeSEkKv1zb+qF7suzcnyv6WbrTlN1PA\u002fFAOXhOzc8L\u002fc1UuIQl7pv2IqctYZjve\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"D2OWvdCRBcCaRjXjhbbDPxIkcNwdnwTA"},"y":{"dtype":"f8","bdata":"e0x9hxia9r8AgOEi1\u002fD0v9wDRCk5hfu\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2024"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"uiV2QDb6AMA="},"y":{"dtype":"f8","bdata":"Y0qHjfTmAcA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"zh3hm++Q9T+PJVxY14rgP8GZ\u002fd05xfc\u002f"},"y":{"dtype":"f8","bdata":"+S8M262uzb8AUnINnQkFwA69awAz7rq\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2024","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"isHdv9EY7L+pL58WV0vtP046FQCCmuy\u002fIaAv0pxQ5r+ny9hhmkvlP7vB25cuges\u002fRwg360aU5L\u002fS1ayWdyTkvzgfK1wzNuu\u002f"},"y":{"dtype":"f8","bdata":"SBi03oq+CcCpPWU6uBnuv5qzIix1vgjAQJjsCfhNB8DLRYAJDAbSv3+4R4BMBey\u002fEGM2ZO4yBcBSuPIFWCYKwJ3LWmjcxgbA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2024"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"WNFnTWxX+j\u002fJgqD061j+P7cvywiPCf4\u002fILDdcijk9j\u002fgrRv2j9KkP\u002fZjLVgfXuU\u002f"},"y":{"dtype":"f8","bdata":"5H\u002fVmwnJ+b8Sm9wRhGz3v2A9yqsuEvS\u002fOC8Oju\u002fYx7+qF7suzcnyv7BlLtiJtAfA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2024","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2024","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2024","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2024","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"nk7n0Las5j9xiX0Zm3DzPzweP\u002fjwiu8\u002fAsVbYsXi6D\u002fpPWpGG2b0P1ON0yKQSek\u002fkoHy93eX4z\u002fyKENqxNDAv6J9\u002fMsE8uo\u002fSCoT8EC35z8tCBnpkcP0P8ICHEziHeE\u002fiN\u002fscbm28T9CimAqrJL4Pz2ndAhZ3PI\u002fvm3q\u002fAlx6j\u002f2JChKHtMBQHxuA\u002f140eg\u002fKjUSrM\u002fM3T9UR6Jgdi\u002fnP1Yytcxtg\u002fY\u002fK39qGnff8D9+agJBL2HsP\u002fbQN8ZlW9k\u002fgkCpf8Bb6j+ptLsK5wvsP5pGNeOFtsM\u002ftWUqR4uZ9D\u002fJL1a4R07dP7LIqbptF\u002fo\u002f2A65493y1T80XT30aQ7\u002fP8PakVCdW\u002fg\u002f2Tj\u002fjDt++j+EGJbd6lvVv2t14QDByuc\u002f"},"y":{"dtype":"f8","bdata":"BIe67rsUBMA\u002fkoOZeX4MwO7WsIDf\u002fATATvkeOCZuA8BIp7Hyn7AEwBeqJ6RpSgnAFc5qPuMzB8DmcZHYY5zcvyK+V0fv09U\u002fddLihrKiBcDErhGuV44IwOps2Vqg3wXAxF2EcohbB8Cwf7pCoD2pP+OpoxCkvQrAhxDndDZjBsDzaTTuiXXEv9NIXkoWtgPAHbDfsE4dBcCJCt7S17YFwJvPekdUCwnAsUGOwBORCMBwf2RZEi4GwAkE6PWqaQTAhLsHeD1ryT8x7BDAaqIHwACA4SLX8PS\u002fNfoYYk1nB8A0Bp2J3BIGwDxAD\u002f4FeAnA1C3XjpJoC8BZtxO+xVX8vyPDwtusKgHA\u002fnoXY\u002frWCMCCH0JTi5e\u002fv5i9mLyABwXA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"kXEA7ycE4D8="},"y":{"dtype":"f8","bdata":"FAOXhOzc8L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"+brSr4UbBUAT1R7Lh7ICQLxPlEHMBQZA7BWtG7G6AkCPJVxY14rgP7vB25cuges\u002fGUn6BQNHA0DJgqD061j+Pw=="},"y":{"dtype":"f8","bdata":"cLO6mEjm3L8NOPTteaQBwCVq9g2W79i\u002ftd0UoNT94D8AUnINnQkFwH+4R4BMBey\u002f+6VUzL18ob8Sm9wRhGz3vw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2024","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"+MSlcwcNAUBmhIG1ykwFQENa+FvVRAZAw9qRUJ1b+D9mbUKFdxIDQA=="},"y":{"dtype":"f8","bdata":"zV67J3GV8r8DTayHHfj6v6no0JiYVfi\u002fI8PC26wqAcBiB\u002fBtHzD0vw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2024","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"NF099GkO\u002fz91lhohzvAHQA=="},"y":{"dtype":"f8","bdata":"WbcTvsVV\u002fL+ZQKwG8zDnvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"V3EABv8pBEA="},"y":{"dtype":"f8","bdata":"DgmoLW385D8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2025","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2025","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"RZxupLCrqj\u002foY17dXiHNPwPGnnixiQhANHDesOSj+z9XcQAG\u002fykEQGKdPz1D5QVA63Heej3XBkCg0oOE0MYGQEWdLgofxwRAS8ovSqlNBUC1hjYl9wgKQEjvG2M1eQVA\u002fu\u002fAsyOk+T83xnKVqFf8Pw=="},"y":{"dtype":"f8","bdata":"yjWlqBBQ1L+wgNttXtvmv4ZfTeGhQ+k\u002fKwPa2VZ07r8OCagtbfzkP5q+mdWW+t0\u002fiX\u002fRp\u002fHF8j\u002fWuFBzoKj1P0otcnfXT+8\u002fe1VYJC5a2D8SIUhlG4zqP24FhdsLV+U\u002fegJp+kVE\u002fD\u002fxjVATp9fCvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"EM4aIy9vA0DswQzAEwEFQHHTDKIWZwVA"},"y":{"dtype":"f8","bdata":"mhCIrLQf\u002fj9c84c3N\u002fH7PwwRD5Tl+f0\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2025","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2025"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"DMeILJpm0T\u002f091tiGy4DQEA8TomucAFA3LvoxVMpA0DuP8zA9aAAQA=="},"y":{"dtype":"f8","bdata":"ClRTexBp4b9g81mAgDj9P7wJmtkjGf8\u002fijxL00k6A0BrtnrX1fyyvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2025"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"5Kc26Ino9T9mVWPLyD7DPw=="},"y":{"dtype":"f8","bdata":"SCZ6c4tswr\u002fQMnByRROkvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"nlovd09+4T9gRoNAKtv2P6ce8mTWZPE\u002fN8ZylahX\u002fD8="},"y":{"dtype":"f8","bdata":"Zg4a2F54A0DDnX2AhxoHQJlTDZRbWgdA8Y1QE6fXwr8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2025"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"rjkDriqOsD8V5xLHeeu0P9Yu3tJf5dc\u002frv4SwP+Kw7\u002f+78CzI6T5Pw=="},"y":{"dtype":"f8","bdata":"05CmaWZxBkDGT\u002fjJNqUJQF1YsLkMaAlAn9CbBPcYCEB6Amn6RUT8Pw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2025"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"40tGsN6z4L8="},"y":{"dtype":"f8","bdata":"egSax4s\u002fBkA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2025","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"9q2Hx9B2+7\u002flcQMSkzP8v5RntCh\u002fnPW\u002fPUKuzH3Z8b8L\u002f7ETdxn0v6Iypkd81fW\u002fuYsR+rYt8r\u002fecQEMcwX3v3kPN\u002f2rJOi\u002fGdq8\u002fDTM8b+6L4pL1Gfzv9cDHpUMOQHAiezMvxoa678kSyjrSRz3v17pgHP7jvK\u002fZHxmntR567\u002fAM9pey8T3v8bEnhigEva\u002fIqkWa3258r\u002fYpe03YOr3vw9UO7H0Ife\u002fgGObLUFd8r+tI7SxhsDmv8qQZ0t3wv2\u002fsX4YuObu87\u002fqenqINrT3vxvuC+tlave\u002fV6xuINDC9788vXkw7HH1v\u002fr9F1RBSO2\u002f0On8aG+R978="},"y":{"dtype":"f8","bdata":"B3MRA+xtBkAVnTTAnRoHQEDkdH\u002fICAlA8qMVvhvHA0Cb24rNxZAGQLDCXOaJOgdAtfbxX24xAkBJW9Rbkb4BQK2WLz2jdgZAQ+k97NXlB0D\u002f8vG7EuAGQLi2O5IlkPQ\u002fUGE9ZHFpB0D1XXYJQK0CQPAUuz\u002fxuwNAbTz5tgUUBkBLGKzmHnEGQP4\u002frYGklAhA2hQQEM8DCkC6w8f6NJ8DQIRyvTe7QQVAjDqdKXEEB0D1s4fcLPAGQPyu5zgJygNA9i6vKt+TCEBFrcVCayMEQFXrn6ftDAVArZlsUxeNBUB4Uk0bCHsAQD8L9jMkCAdA27uSzxd5A0A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"bYnGRpGxBcD3jsB1vOEIwGvI3T+kRQrA"},"y":{"dtype":"f8","bdata":"OfDLgE9p9z\u002fjhEnQj07pP8m5TL6pg\u002fE\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2025"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"5Ygo2nlACsA="},"y":{"dtype":"f8","bdata":"ent4WHOe4j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2025"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"1wMelQw5AcA="},"y":{"dtype":"f8","bdata":"uLY7kiWQ9D8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2025","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2025"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"guXwweDsB8A1sLDmfmfqv5a\u002fiWkpDArARZxupLCrqj9NeH1sDQ4JwB+oTEyixgjA++lfvlWTB8DtOKBteFgFwOhpbxaIy4Q\u002f"},"y":{"dtype":"f8","bdata":"HKWOKGSM6b+z0eLfxCj9v+rVv+RyNfG\u002fyjWlqBBQ1L8D3KQg7XHyv545VrqK7vW\u002fBfsXxBnQ9b80R9Kow2Tuv19Iq\u002fBS8u2\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2025","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2025","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2025"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"0tbsJn3S2b967JcFJP4EwOhjXt1eIc0\u002f"},"y":{"dtype":"f8","bdata":"fdZQcHLuAcBspUJEqM3+v7CA221e2+a\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2025"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"DMeILJpm0T8="},"y":{"dtype":"f8","bdata":"ClRTexBp4b8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2025","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2025","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"sHjlvk+vlD9mVWPLyD7DP6\u002f8Wm+WauG\u002fqlR8LLytyL+8ZSXNZhDwvwaJc2oVJMy\u002fAxSHpS2M0L9Op4qjnFDfv8\u002fPiIfpBde\u002fnl3lZDHZ4r+\u002fqU2ADPLgv+XQ5C1rs+K\u002fFKGBzvEZ8L+X7fKZcV\u002fiv+QPFvI3Cum\u002fskpBMo+uxr+khnHPexTYv2Atf8zjsOa\u002fNKILXDF94r83xnKVqFf8Pw=="},"y":{"dtype":"f8","bdata":"NBE39UeCBsDQMnByRROkv3tvtnTB\u002fwjAPjuJb3rhDMCVAjNpA6AJwBH9HWxUJQfAQCXYenRmCcBsOyBbTMQDwCES3s2DIwnAXEwJCZdJCMDyi3YJ9soFwPK7OUnDqQPAuwbvQTdQCcDv\u002fbbO\u002fjwGwGV\u002fBnWM6QTAiBvXAQMtCMC4qlC1p4gGwNF55GeF1AbAkCYSxkajCcDxjVATp9fCvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2025","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2025","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2025","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2025","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2025","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"NbCw5n5n6r\u002fS1uwmfdLZv7B45b5Pr5Q\u002fOzKllS126z\u002fkpzboiej1P+q7Fbdj1ABANHDesOSj+z+A7QD3TmTxP5SLeO3KouY\u002fGyY4\u002fuzY+j\u002f38eLX65zxPxCSb\u002fNcNeA\u002f+SSI72bg8T80BGdZsj\u002f0P0JcjOGgb\u002fM\u002fhxyU8D8I6T+bCRxjw0H3P24ioIrc4eU\u002fAQ6WCQtU8D+C3lFbx6fgP053uHfDM+w\u002fyfNN6T+f8T+2k0AAflncPzqM0MQ\u002fSgJABX+GD9ih8z\u002fSfB1W0bTyPw=="},"y":{"dtype":"f8","bdata":"s9Hi38Qo\u002fb991lBwcu4BwDQRN\u002fVHggbAeHFKWdZVBMBIJnpzi2zCv8R0grKmyQLAKwPa2VZ07r\u002fq7qmDAiILwKIUI9CxVwrAu\u002fEiA+tDA8AeUkQ5bm0EwO5JsMeG+wPAS99vvfvZBsCPt+Z1QegGwH7voRrDkAjA4TPxzAAnBMAPAdUE8Tj9v6m3L5aqqwjAYIdO3FzfB8Cs85vkPesGwEbBlVuAxAfADh+wYny5BcDQB5pq1hUFwJSdMIhdcPm\u002fm\u002fZLBlugA8AYoB9T50ENwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2025","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"AIBbg39lAkBPX1iWMIUBQIOu6ZdqHAJAKA2bp23VA0CdCTzh6nADQCAL\u002fa0WOgBACDFJxSc\u002fAUDuP8zA9aAAQD74QKlDsAJAN8ZylahX\u002fD8="},"y":{"dtype":"f8","bdata":"NqRd9CWCAsAHQP4Jf7D+v1Dek8Kbi\u002f6\u002fbo\u002fJFrWC+L9MdaLGQV4FwIYhTGVDNP2\u002fWuoepP+Z+L9rtnrX1fyyv28w9T+h0\u002fy\u002f8Y1QE6fXwr8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2025"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"6rsVt2PUAEA="},"y":{"dtype":"f8","bdata":"xHSCsqbJAsA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2025","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"ujPYtG\u002fNB0C8xck9hMAGQFETE2bzOQpARwZ1U9kdCECNKG+j4ToLQFO18OUrxAVAmwkcY8NB9z9IubxMvLcCQOhpbxaIy4Q\u002fQecNf6BODEA8DkGDz5AHQDqM0MQ\u002fSgJAK1CArz\u002f+B0A="},"y":{"dtype":"f8","bdata":"yozrR+1F5r9Lv1qncSnmvx7knBwX5ea\u002fJT5aPPJz3b+UCFwPsVXZv8gtw3thNO2\u002fDwHVBPE4\u002fb89o82+eub0v19Iq\u002fBS8u2\u002f9IvMg7Mozr8IA3DfE+3tv5SdMIhdcPm\u002f\u002f\u002fapLdSu778="},"type":"scatter"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scattermap":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermap"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"font":{"size":16},"text":"Multi-label Clusters for each Year"},"xaxis":{"range":[-4.5,4.5],"title":{"text":""},"showgrid":true,"gridcolor":"lightgray"},"yaxis":{"range":[-4.5,4.5],"title":{"text":""},"showgrid":true,"gridcolor":"lightgray","scaleanchor":"x","scaleratio":1},"height":700,"width":900,"hovermode":"closest","sliders":[{"active":0,"currentvalue":{"prefix":"Year: ","visible":true,"xanchor":"center"},"len":0.9,"pad":{"b":10,"t":50},"steps":[{"args":[{"visible":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false]}],"label":"2022","method":"update"},{"args":[{"visible":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false]}],"label":"2023","method":"update"},{"args":[{"visible":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false]}],"label":"2024","method":"update"},{"args":[{"visible":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true]}],"label":"2025","method":"update"}],"x":0.0,"xanchor":"left","y":-0.1,"yanchor":"top"}],"showlegend":true},                        {"responsive": true}                    )                };            </script>        </div>
    <br>    
    <h2>All papers</h2>
    <div>                        <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.3.1.min.js" integrity="sha256-4rD3fugVb/nVJYUv5Ky3v+fYXoouHaBSP20WIJuEiWg=" crossorigin="anonymous"></script>                <div id="cec0a783-69da-4b22-b219-564d74e3a1ed" class="plotly-graph-div" style="height:800px; width:1000px;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("cec0a783-69da-4b22-b219-564d74e3a1ed")) {                    Plotly.newPlot(                        "cec0a783-69da-4b22-b219-564d74e3a1ed",                        [{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2022","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2022","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2022","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2022","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2022","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2022","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2022","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2022","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2022","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2022","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2022","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2022","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2022"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias (19)","showlegend":true,"x":{"dtype":"f8","bdata":"V3EABv8pBED5utKvhRsFQJz4dx1jPes\u002fWNFnTWxX+j\u002fOHeGb75D1P\u002fYkKEoe0wFARmsMfWkd9D\u002fsFa0bsboCQBlJ+gUDRwNAwZn93TnF9z\u002fJgqD061j+P7cvywiPCf4\u002fZlaoOSUBBEAgsN1yKOT2P9\u002fN0pu77AdApf7IBib4AkDgrRv2j9KkP5FxAO8nBOA\u002f0e2ZTuunBUA="},"y":{"dtype":"f8","bdata":"DgmoLW385D9ws7qYSObcv0MTiNvIQcu\u002f5H\u002fVmwnJ+b\u002f5Lwzbra7Nv\u002fNpNO6JdcS\u002fgnegTEoCsj+13RSg1P3gP\u002fulVMy9fKG\u002fDr1rADPuur8Sm9wRhGz3v2A9yqsuEvS\u002fVLnBlgNR8T84Lw6O79jHv1ci1AF1PuE\u002fLgfKHHP88j+qF7suzcnyvxQDl4Ts3PC\u002f2BPQGzhl8z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2022","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2022","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2022","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2022","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2022","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2022","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2022","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2022","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2022","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2022","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2022","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2022","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2022","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2022"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural (30)","showlegend":true,"x":{"dtype":"f8","bdata":"RZxupLCrqj\u002foY17dXiHNPwPGnnixiQhANHDesOSj+z9XcQAG\u002fykEQGKdPz1D5QVA63Heej3XBkCg0oOE0MYGQISANSPJ1AlAE20Atk32BUDx7wyOmcoHQD9eOXNRGApA+brSr4UbBUCc+HcdYz3rP6kvnxZXS+0\u002fvE+UQcwFBkBGawx9aR30P9\u002fN0pu77AdAmkY144W2wz8ukdrqvSbAP5SbvIBpGuU\u002fRZ0uCh\u002fHBEBLyi9KqU0FQLWGNiX3CApASO8bYzV5BUD+78CzI6T5PzfGcpWoV\u002fw\u002fywjFZvhyB0AZkExeVQQHQMwz13+YR98\u002f"},"y":{"dtype":"f8","bdata":"yjWlqBBQ1L+wgNttXtvmv4ZfTeGhQ+k\u002fKwPa2VZ07r8OCagtbfzkP5q+mdWW+t0\u002fiX\u002fRp\u002fHF8j\u002fWuFBzoKj1Pw2Hz2CDDeA\u002ftSV1Lqzo6j\u002fR6zpYiRPcP27ytL58Y9o\u002fcLO6mEjm3L9DE4jbyEHLv6k9ZTq4Ge6\u002fJWr2DZbv2L+Cd6BMSgKyP1ci1AF1PuE\u002fAIDhItfw9L8Z5ISQq\u002fXNv6WbrTlN1PA\u002fSi1yd9dP7z97VVgkLlrYPxIhSGUbjOo\u002fbgWF2wtX5T96Amn6RUT8P\u002fGNUBOn18K\u002fL4ADB0wN8D8DT+Lg3+byP\u002fRqqQamTPM\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2022","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2022","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2022"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture (3)","showlegend":true,"x":{"dtype":"f8","bdata":"EM4aIy9vA0DswQzAEwEFQHHTDKIWZwVA"},"y":{"dtype":"f8","bdata":"mhCIrLQf\u002fj9c84c3N\u002fH7PwwRD5Tl+f0\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2022","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2022","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2022","Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2022","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2022","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2022","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2022","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2022","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2022","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2022"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics (14)","showlegend":true,"x":{"dtype":"f8","bdata":"DMeILJpm0T\u002f091tiGy4DQEA8TomucAFA37ti3escAkDOHeGb75D1P\u002fYkKEoe0wFA7BWtG7G6AkAZSfoFA0cDQMGZ\u002fd05xfc\u002fXzNx38KHAEBmVqg5JQEEQNHtmU7rpwVA3LvoxVMpA0DuP8zA9aAAQA=="},"y":{"dtype":"f8","bdata":"ClRTexBp4b9g81mAgDj9P7wJmtkjGf8\u002f2Mqtr7Z8+j\u002f5Lwzbra7Nv\u002fNpNO6JdcS\u002ftd0UoNT94D\u002f7pVTMvXyhvw69awAz7rq\u002fEPW4m9P+A0BUucGWA1HxP9gT0Bs4ZfM\u002fijxL00k6A0BrtnrX1fyyvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2022","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2022","Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2022","Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2022","Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2022","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2022","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2022","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2022","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2022","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2022"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity (10)","showlegend":true,"x":{"dtype":"f8","bdata":"5Kc26Ino9T9mVWPLyD7DP\u002f3u0UoR\u002ff8\u002fOeP4qyQ39T8RTbu53yz7P0KKYCqskvg\u002fp8vYYZpL5T9fM3HfwocAQKX+yAYm+AJAlJu8gGka5T8="},"y":{"dtype":"f8","bdata":"SCZ6c4tswr\u002fQMnByRROkvwvgFVbAygNABBdvQnmUBkDNdPd+fMgDQLB\u002fukKgPak\u002fy0WACQwG0r8Q9bib0\u002f4DQC4Hyhxz\u002fPI\u002fpZutOU3U8D8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2022","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2022","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2022","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2022","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2022","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2022"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical (6)","showlegend":true,"x":{"dtype":"f8","bdata":"nlovd09+4T9gRoNAKtv2P6ce8mTWZPE\u002fu8Hbly6B6z83xnKVqFf8PwPh2B7yw+w\u002f"},"y":{"dtype":"f8","bdata":"Zg4a2F54A0DDnX2AhxoHQJlTDZRbWgdAf7hHgEwF7L\u002fxjVATp9fCvwnfIInieQVA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2022","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2022","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2022","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2022","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality (21)","showlegend":true,"x":{"dtype":"f8","bdata":"rjkDriqOsD8V5xLHeeu0P+axFY7KyNM\u002fUD1B6TJC1D8ePW8rS3TgP6J9\u002fMsE8uo\u002fMenCm2d33D+rVNb7U13PP66J8sfmpsm\u002fHhAsJ18j4z+CQKl\u002fwFvqP67nBlvVzeI\u002fILDdcijk9j+t7YF0RFTIP7Q9PIvZjeI\u002fK5kyQ6MJ0D9bk1ZH3tbRP9Yu3tJf5dc\u002frv4SwP+Kw7\u002f+78CzI6T5P+aoOn8iedY\u002f"},"y":{"dtype":"f8","bdata":"05CmaWZxBkDGT\u002fjJNqUJQGr1seFUAQtAiW0v9nr0B0BoE1\u002fqmQAMQCK+V0fv09U\u002fCm5JtdzqBEDgs\u002fSUAwgJQKtv9xNjIAdAvP7qKjvwBkCEuwd4PWvJP+e8a6L9+QpAOC8Oju\u002fYx7+sncr3SlwFQNb1FRiONQNA5T79m\u002fl8CUD0ABqqTMEGQF1YsLkMaAlAn9CbBPcYCEB6Amn6RUT8P9pmEMkpYwVA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2022"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness (1)","showlegend":true,"x":{"dtype":"f8","bdata":"40tGsN6z4L8="},"y":{"dtype":"f8","bdata":"egSax4s\u002fBkA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2022","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2022","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general (69)","showlegend":true,"x":{"dtype":"f8","bdata":"9q2Hx9B2+7\u002flcQMSkzP8v5RntCh\u002fnPW\u002fPUKuzH3Z8b8L\u002f7ETdxn0v6Iypkd81fW\u002fuYsR+rYt8r\u002fecQEMcwX3v4yv3UeC7\u002fO\u002fCX12x1Oy8L\u002fj+LiY1ADzvyyegP3K0fa\u002fC1vTdIWX8b+z87vtm8Lyv6K3zS8bIPK\u002fLKEX4RAn9r\u002fPmGzoVUj3v5uCEeZSf\u002fe\u002fIpVQDzWL9r+mqkh3vjn3v5t22ob+vOu\u002fJMEOLR9N9b\u002fnNRceu1nmvy0Mxm2lePG\u002fzqvcLi+J8r\u002fH6nBBOEXyv\u002fB1FhMjcfa\u002fbBpmsrlW87\u002f\u002fHgWCukj0v+44jpV9CvO\u002fZLA+wzPC8b86gSlJ0uTcv4TC8foCQ\u002fW\u002fY\u002f+1S2V19L9QpEIdq0D\u002fv5GEIBH94PO\u002fioxwmYTj+b8MLoWhC6Xyv\u002f9vyqIQ5OO\u002fZbKFm3mA+b8TBfZmjQX4v58L0rwvXPq\u002feQ83\u002fask6L8Z2rz8NMzxv7ovikvUZ\u002fO\u002f1wMelQw5AcCJ7My\u002fGhrrvyRLKOtJHPe\u002fXumAc\u002fuO8r9kfGae1Hnrv8Az2l7LxPe\u002fxsSeGKAS9r8iqRZrfbnyv9il7Tdg6ve\u002fD1Q7sfQh97+AY5stQV3yv60jtLGGwOa\u002fypBnS3fC\u002fb+xfhi45u7zv+p6eog2tPe\u002fG+4L62Vq979XrG4g0ML3vzy9eTDscfW\u002f+v0XVEFI7b\u002fQ6fxob5H3v+rEiKU6lO+\u002fANQUR\u002fgO9L+EGJbd6lvVv9YjK5s0X\u002fa\u002f"},"y":{"dtype":"f8","bdata":"B3MRA+xtBkAVnTTAnRoHQEDkdH\u002fICAlA8qMVvhvHA0Cb24rNxZAGQLDCXOaJOgdAtfbxX24xAkBJW9Rbkb4BQMgFw6MMeAlAy3iFdSJbB0CBeEuGzSIGQBQmxwdrXQVA2nxLFSNhBUCRAfn1VTYFQP\u002f3KluWrgJAP89f63emBUCEdbK8fuYDQCZkcuKB4wFAXafEVcw7BEBPfjqgaHgFQHso7rjnUQVAdWeialwrCEAma+RIi5AEQJg+0CCksAdAag9NqQs\u002fCUD+No2uwWMFQKKpbMT\u002fAAlA2mAtetmuAUBt0iGCTgUGQDcxiE7BJQZAPO06JiHYCUDxRvFpzhkFQGAiXCYJogVACqfqWDMQA0BrvdXtjWsGQODN6L6vZAVA8sB\u002f73HLA0CWD0POqrsFQGhGQ+GJoQVASbBzvvQQBUDEU1IcD\u002fwFQPEiXO7tlwdArZYvPaN2BkBD6T3s1eUHQP\u002fy8bsS4AZAuLY7kiWQ9D9QYT1kcWkHQPVddglArQJA8BS7P\u002fG7A0BtPPm2BRQGQEsYrOYecQZA\u002fj+tgaSUCEDaFBAQzwMKQLrDx\u002fo0nwNAhHK9N7tBBUCMOp0pcQQHQPWzh9ws8AZA\u002fK7nOAnKA0D2Lq8q35MIQEWtxUJrIwRAVeufp+0MBUCtmWxTF40FQHhSTRsIewBAPwv2MyQIB0Dbu5LPF3kDQPTdfq3KbAdAcnuR15nRBUCCH0JTi5e\u002fv41FgT33IwdA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2022"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate (1)","showlegend":true,"x":{"dtype":"f8","bdata":"8ihDasTQwL8="},"y":{"dtype":"f8","bdata":"5nGR2GOc3L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2022"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor (1)","showlegend":true,"x":{"dtype":"f8","bdata":"gMtL1Nzr\u002fL8="},"y":{"dtype":"f8","bdata":"B\u002fs58kDm\u002fz8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2022","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2022","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2022","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2022"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language (4)","showlegend":true,"x":{"dtype":"f8","bdata":"bYnGRpGxBcD3jsB1vOEIwGvI3T+kRQrAzDPXf5hH3z8="},"y":{"dtype":"f8","bdata":"OfDLgE9p9z\u002fjhEnQj07pP8m5TL6pg\u002fE\u002f9GqpBqZM8z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2022"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal (1)","showlegend":true,"x":{"dtype":"f8","bdata":"5Ygo2nlACsA="},"y":{"dtype":"f8","bdata":"ent4WHOe4j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2022"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length (1)","showlegend":true,"x":{"dtype":"f8","bdata":"1wMelQw5AcA="},"y":{"dtype":"f8","bdata":"uLY7kiWQ9D8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2022","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2022","Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2022","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2022","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2022","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2022","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2022","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral (20)","showlegend":true,"x":{"dtype":"f8","bdata":"guXwweDsB8A1sLDmfmfqv5a\u002fiWkpDArARZxupLCrqj+n2n5pHhsHwLrdjPgjIwXAjRsMvXGrBsCc+HcdYz3rP0ZrDH1pHfQ\u002fLpHa6r0mwD\u002fgrRv2j9KkP5SbvIBpGuU\u002fkXEA7ycE4D9NeH1sDQ4JwB+oTEyixgjA++lfvlWTB8DtOKBteFgFwOhpbxaIy4Q\u002f42jisycnB8Bs41Y37hoGwA=="},"y":{"dtype":"f8","bdata":"HKWOKGSM6b+z0eLfxCj9v+rVv+RyNfG\u002fyjWlqBBQ1L8A7o8GoJPwvzf7SSv6H+6\u002f3CjHoYKm7r9DE4jbyEHLv4J3oExKArI\u002fGeSEkKv1zb+qF7suzcnyv6WbrTlN1PA\u002fFAOXhOzc8L8D3KQg7XHyv545VrqK7vW\u002fBfsXxBnQ9b80R9Kow2Tuv19Iq\u002fBS8u2\u002f3NVLiEJe6b9iKnLWGY73vw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2022","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2022","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2022","Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2022","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2022","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2022"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual (6)","showlegend":true,"x":{"dtype":"f8","bdata":"0tbsJn3S2b967JcFJP4EwOhjXt1eIc0\u002fD2OWvdCRBcCaRjXjhbbDPxIkcNwdnwTA"},"y":{"dtype":"f8","bdata":"fdZQcHLuAcBspUJEqM3+v7CA221e2+a\u002fe0x9hxia9r8AgOEi1\u002fD0v9wDRCk5hfu\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2022"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness (1)","showlegend":true,"x":{"dtype":"f8","bdata":"uiV2QDb6AMA="},"y":{"dtype":"f8","bdata":"Y0qHjfTmAcA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2022","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2022","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions (4)","showlegend":true,"x":{"dtype":"f8","bdata":"DMeILJpm0T\u002fOHeGb75D1P48lXFjXiuA\u002fwZn93TnF9z8="},"y":{"dtype":"f8","bdata":"ClRTexBp4b\u002f5Lwzbra7NvwBScg2dCQXADr1rADPuur8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2022","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2022","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2022","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2022","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2022","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2022","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization (31)","showlegend":true,"x":{"dtype":"f8","bdata":"sHjlvk+vlD9mVWPLyD7DP6\u002f8Wm+WauG\u002fisHdv9EY7L9O5vk+yiTjvxtZJUL4rtq\u002fqS+fFldL7T9OOhUAgprsvyGgL9KcUOa\u002fp8vYYZpL5T+7wduXLoHrP0cIN+tGlOS\u002f0tWslnck5L+qVHwsvK3Iv7xlJc1mEPC\u002fBolzahUkzL8DFIelLYzQv06niqOcUN+\u002fz8+Ih+kF17+eXeVkMdniv7+pTYAM8uC\u002f5dDkLWuz4r8UoYHO8Rnwv5ft8plxX+K\u002f5A8W8jcK6b+ySkEyj67Gv6SGcc97FNi\u002fYC1\u002fzOOw5r80ogtcMX3ivzfGcpWoV\u002fw\u002fOB8rXDM2678="},"y":{"dtype":"f8","bdata":"NBE39UeCBsDQMnByRROkv3tvtnTB\u002fwjASBi03oq+CcDMgp\u002fbqy4CwCZ+h\u002fkfzAnAqT1lOrgZ7r+asyIsdb4IwECY7An4TQfAy0WACQwG0r9\u002fuEeATAXsvxBjNmTuMgXAUrjyBVgmCsA+O4lveuEMwJUCM2kDoAnAEf0dbFQlB8BAJdh6dGYJwGw7IFtMxAPAIRLezYMjCcBcTAkJl0kIwPKLdgn2ygXA8rs5ScOpA8C7Bu9BN1AJwO\u002f9ts7+PAbAZX8GdYzpBMCIG9cBAy0IwLiqULWniAbA0XnkZ4XUBsCQJhLGRqMJwPGNUBOn18K\u002fnctaaNzGBsA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2022","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2022","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2022","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2022","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2022","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2022"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political (6)","showlegend":true,"x":{"dtype":"f8","bdata":"WNFnTWxX+j\u002fJgqD061j+P7cvywiPCf4\u002fILDdcijk9j\u002fgrRv2j9KkP\u002fZjLVgfXuU\u002f"},"y":{"dtype":"f8","bdata":"5H\u002fVmwnJ+b8Sm9wRhGz3v2A9yqsuEvS\u002fOC8Oju\u002fYx7+qF7suzcnyv7BlLtiJtAfA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2022","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2022","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2022","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2022","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2022","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2022","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2022","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2022","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2022","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2022","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2022","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2022","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2022","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2022","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2022","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2022","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2022","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety (62)","showlegend":true,"x":{"dtype":"f8","bdata":"NbCw5n5n6r\u002fS1uwmfdLZv7B45b5Pr5Q\u002fOzKllS126z\u002fkpzboiej1P+q7Fbdj1ABANHDesOSj+z+A7QD3TmTxP5SLeO3KouY\u002fnk7n0Las5j9xiX0Zm3DzPzweP\u002fjwiu8\u002fAsVbYsXi6D\u002fpPWpGG2b0P1ON0yKQSek\u002fkoHy93eX4z\u002fyKENqxNDAv6J9\u002fMsE8uo\u002fSCoT8EC35z8tCBnpkcP0P8ICHEziHeE\u002fiN\u002fscbm28T9CimAqrJL4Pz2ndAhZ3PI\u002fvm3q\u002fAlx6j\u002f2JChKHtMBQHxuA\u002f140eg\u002fKjUSrM\u002fM3T9UR6Jgdi\u002fnP1Yytcxtg\u002fY\u002fK39qGnff8D9+agJBL2HsP\u002fbQN8ZlW9k\u002fgkCpf8Bb6j+ptLsK5wvsP5pGNeOFtsM\u002ftWUqR4uZ9D\u002fJL1a4R07dPxsmOP7s2Po\u002f9\u002fHi1+uc8T8Qkm\u002fzXDXgP\u002fkkiO9m4PE\u002fNARnWbI\u002f9D9CXIzhoG\u002fzP4cclPA\u002fCOk\u002fmwkcY8NB9z9uIqCK3OHlPwEOlgkLVPA\u002fgt5RW8en4D9Od7h3wzPsP8nzTek\u002fn\u002fE\u002ftpNAAH5Z3D86jNDEP0oCQAV\u002fhg\u002fYofM\u002f0nwdVtG08j+yyKm6bRf6P9gOuePd8tU\u002fNF099GkO\u002fz\u002fD2pFQnVv4P9k4\u002f4w7fvo\u002fhBiW3epb1b9rdeEAwcrnPw=="},"y":{"dtype":"f8","bdata":"s9Hi38Qo\u002fb991lBwcu4BwDQRN\u002fVHggbAeHFKWdZVBMBIJnpzi2zCv8R0grKmyQLAKwPa2VZ07r\u002fq7qmDAiILwKIUI9CxVwrABIe67rsUBMA\u002fkoOZeX4MwO7WsIDf\u002fATATvkeOCZuA8BIp7Hyn7AEwBeqJ6RpSgnAFc5qPuMzB8DmcZHYY5zcvyK+V0fv09U\u002fddLihrKiBcDErhGuV44IwOps2Vqg3wXAxF2EcohbB8Cwf7pCoD2pP+OpoxCkvQrAhxDndDZjBsDzaTTuiXXEv9NIXkoWtgPAHbDfsE4dBcCJCt7S17YFwJvPekdUCwnAsUGOwBORCMBwf2RZEi4GwAkE6PWqaQTAhLsHeD1ryT8x7BDAaqIHwACA4SLX8PS\u002fNfoYYk1nB8A0Bp2J3BIGwLvxIgPrQwPAHlJEOW5tBMDuSbDHhvsDwEvfb7372QbAj7fmdUHoBsB+76Eaw5AIwOEz8cwAJwTADwHVBPE4\u002fb+pty+WqqsIwGCHTtxc3wfArPOb5D3rBsBGwZVbgMQHwA4fsGJ8uQXA0AeaatYVBcCUnTCIXXD5v5v2SwZboAPAGKAfU+dBDcA8QA\u002f+BXgJwNQt146SaAvAWbcTvsVV\u002fL8jw8LbrCoBwP56F2P61gjAgh9CU4uXv7+YvZi8gAcFwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2022"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism (1)","showlegend":true,"x":{"dtype":"f8","bdata":"kXEA7ycE4D8="},"y":{"dtype":"f8","bdata":"FAOXhOzc8L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2022","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2022","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2022","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2022","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2022","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2022","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2022"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social (18)","showlegend":true,"x":{"dtype":"f8","bdata":"AIBbg39lAkBPX1iWMIUBQIOu6ZdqHAJAKA2bp23VA0CdCTzh6nADQPm60q+FGwVAE9Uey4eyAkC8T5RBzAUGQOwVrRuxugJAjyVcWNeK4D+7wduXLoHrPxlJ+gUDRwNAyYKg9OtY\u002fj8gC\u002f2tFjoAQAgxScUnPwFA7j\u002fMwPWgAEA++ECpQ7ACQDfGcpWoV\u002fw\u002f"},"y":{"dtype":"f8","bdata":"NqRd9CWCAsAHQP4Jf7D+v1Dek8Kbi\u002f6\u002fbo\u002fJFrWC+L9MdaLGQV4FwHCzuphI5ty\u002fDTj07XmkAcAlavYNlu\u002fYv7XdFKDU\u002feA\u002fAFJyDZ0JBcB\u002fuEeATAXsv\u002fulVMy9fKG\u002fEpvcEYRs97+GIUxlQzT9v1rqHqT\u002fmfi\u002fa7Z619X8sr9vMPU\u002fodP8v\u002fGNUBOn18K\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2022","Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2022","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2022","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2022","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2022","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2022"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity (6)","showlegend":true,"x":{"dtype":"f8","bdata":"6rsVt2PUAED4xKVzBw0BQGaEgbXKTAVAQ1r4W9VEBkDD2pFQnVv4P2ZtQoV3EgNA"},"y":{"dtype":"f8","bdata":"xHSCsqbJAsDNXrsncZXyvwNNrIcd+Pq\u002fqejQmJhV+L8jw8LbrCoBwGIH8G0fMPS\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2022","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2022","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2022","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2022","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value (15)","showlegend":true,"x":{"dtype":"f8","bdata":"ujPYtG\u002fNB0C8xck9hMAGQFETE2bzOQpARwZ1U9kdCECNKG+j4ToLQFO18OUrxAVAmwkcY8NB9z9IubxMvLcCQOhpbxaIy4Q\u002fQecNf6BODEA8DkGDz5AHQDqM0MQ\u002fSgJAK1CArz\u002f+B0A0XT30aQ7\u002fP3WWGiHO8AdA"},"y":{"dtype":"f8","bdata":"yozrR+1F5r9Lv1qncSnmvx7knBwX5ea\u002fJT5aPPJz3b+UCFwPsVXZv8gtw3thNO2\u002fDwHVBPE4\u002fb89o82+eub0v19Iq\u002fBS8u2\u002f9IvMg7Mozr8IA3DfE+3tv5SdMIhdcPm\u002f\u002f\u002fapLdSu779ZtxO+xVX8v5lArAbzMOe\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2023","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2023","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2023","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2023","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2023","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2023","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2023","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2023","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2023","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2023","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2023","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2023"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias (19)","showlegend":false,"x":{"dtype":"f8","bdata":"V3EABv8pBED5utKvhRsFQJz4dx1jPes\u002fWNFnTWxX+j\u002fOHeGb75D1P\u002fYkKEoe0wFARmsMfWkd9D\u002fsFa0bsboCQBlJ+gUDRwNAwZn93TnF9z\u002fJgqD061j+P7cvywiPCf4\u002fZlaoOSUBBEAgsN1yKOT2P9\u002fN0pu77AdApf7IBib4AkDgrRv2j9KkP5FxAO8nBOA\u002f0e2ZTuunBUA="},"y":{"dtype":"f8","bdata":"DgmoLW385D9ws7qYSObcv0MTiNvIQcu\u002f5H\u002fVmwnJ+b\u002f5Lwzbra7Nv\u002fNpNO6JdcS\u002fgnegTEoCsj+13RSg1P3gP\u002fulVMy9fKG\u002fDr1rADPuur8Sm9wRhGz3v2A9yqsuEvS\u002fVLnBlgNR8T84Lw6O79jHv1ci1AF1PuE\u002fLgfKHHP88j+qF7suzcnyvxQDl4Ts3PC\u002f2BPQGzhl8z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2023","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2023","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2023","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2023","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2023","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2023","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2023","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2023","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2023","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2023","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2023","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2023","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2023"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural (30)","showlegend":false,"x":{"dtype":"f8","bdata":"RZxupLCrqj\u002foY17dXiHNPwPGnnixiQhANHDesOSj+z9XcQAG\u002fykEQGKdPz1D5QVA63Heej3XBkCg0oOE0MYGQISANSPJ1AlAE20Atk32BUDx7wyOmcoHQD9eOXNRGApA+brSr4UbBUCc+HcdYz3rP6kvnxZXS+0\u002fvE+UQcwFBkBGawx9aR30P9\u002fN0pu77AdAmkY144W2wz8ukdrqvSbAP5SbvIBpGuU\u002fRZ0uCh\u002fHBEBLyi9KqU0FQLWGNiX3CApASO8bYzV5BUD+78CzI6T5PzfGcpWoV\u002fw\u002fywjFZvhyB0AZkExeVQQHQMwz13+YR98\u002f"},"y":{"dtype":"f8","bdata":"yjWlqBBQ1L+wgNttXtvmv4ZfTeGhQ+k\u002fKwPa2VZ07r8OCagtbfzkP5q+mdWW+t0\u002fiX\u002fRp\u002fHF8j\u002fWuFBzoKj1Pw2Hz2CDDeA\u002ftSV1Lqzo6j\u002fR6zpYiRPcP27ytL58Y9o\u002fcLO6mEjm3L9DE4jbyEHLv6k9ZTq4Ge6\u002fJWr2DZbv2L+Cd6BMSgKyP1ci1AF1PuE\u002fAIDhItfw9L8Z5ISQq\u002fXNv6WbrTlN1PA\u002fSi1yd9dP7z97VVgkLlrYPxIhSGUbjOo\u002fbgWF2wtX5T96Amn6RUT8P\u002fGNUBOn18K\u002fL4ADB0wN8D8DT+Lg3+byP\u002fRqqQamTPM\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2023","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2023","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2023"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture (3)","showlegend":false,"x":{"dtype":"f8","bdata":"EM4aIy9vA0DswQzAEwEFQHHTDKIWZwVA"},"y":{"dtype":"f8","bdata":"mhCIrLQf\u002fj9c84c3N\u002fH7PwwRD5Tl+f0\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2023","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2023","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2023","Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2023","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2023","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2023","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2023","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2023","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2023","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2023"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics (14)","showlegend":false,"x":{"dtype":"f8","bdata":"DMeILJpm0T\u002f091tiGy4DQEA8TomucAFA37ti3escAkDOHeGb75D1P\u002fYkKEoe0wFA7BWtG7G6AkAZSfoFA0cDQMGZ\u002fd05xfc\u002fXzNx38KHAEBmVqg5JQEEQNHtmU7rpwVA3LvoxVMpA0DuP8zA9aAAQA=="},"y":{"dtype":"f8","bdata":"ClRTexBp4b9g81mAgDj9P7wJmtkjGf8\u002f2Mqtr7Z8+j\u002f5Lwzbra7Nv\u002fNpNO6JdcS\u002ftd0UoNT94D\u002f7pVTMvXyhvw69awAz7rq\u002fEPW4m9P+A0BUucGWA1HxP9gT0Bs4ZfM\u002fijxL00k6A0BrtnrX1fyyvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2023","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2023","Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2023","Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2023","Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2023","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2023","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2023","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2023","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2023","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2023"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity (10)","showlegend":false,"x":{"dtype":"f8","bdata":"5Kc26Ino9T9mVWPLyD7DP\u002f3u0UoR\u002ff8\u002fOeP4qyQ39T8RTbu53yz7P0KKYCqskvg\u002fp8vYYZpL5T9fM3HfwocAQKX+yAYm+AJAlJu8gGka5T8="},"y":{"dtype":"f8","bdata":"SCZ6c4tswr\u002fQMnByRROkvwvgFVbAygNABBdvQnmUBkDNdPd+fMgDQLB\u002fukKgPak\u002fy0WACQwG0r8Q9bib0\u002f4DQC4Hyhxz\u002fPI\u002fpZutOU3U8D8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2023","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2023","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2023","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2023","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2023","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2023"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical (6)","showlegend":false,"x":{"dtype":"f8","bdata":"nlovd09+4T9gRoNAKtv2P6ce8mTWZPE\u002fu8Hbly6B6z83xnKVqFf8PwPh2B7yw+w\u002f"},"y":{"dtype":"f8","bdata":"Zg4a2F54A0DDnX2AhxoHQJlTDZRbWgdAf7hHgEwF7L\u002fxjVATp9fCvwnfIInieQVA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2023","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2023","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2023","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2023","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality (21)","showlegend":false,"x":{"dtype":"f8","bdata":"rjkDriqOsD8V5xLHeeu0P+axFY7KyNM\u002fUD1B6TJC1D8ePW8rS3TgP6J9\u002fMsE8uo\u002fMenCm2d33D+rVNb7U13PP66J8sfmpsm\u002fHhAsJ18j4z+CQKl\u002fwFvqP67nBlvVzeI\u002fILDdcijk9j+t7YF0RFTIP7Q9PIvZjeI\u002fK5kyQ6MJ0D9bk1ZH3tbRP9Yu3tJf5dc\u002frv4SwP+Kw7\u002f+78CzI6T5P+aoOn8iedY\u002f"},"y":{"dtype":"f8","bdata":"05CmaWZxBkDGT\u002fjJNqUJQGr1seFUAQtAiW0v9nr0B0BoE1\u002fqmQAMQCK+V0fv09U\u002fCm5JtdzqBEDgs\u002fSUAwgJQKtv9xNjIAdAvP7qKjvwBkCEuwd4PWvJP+e8a6L9+QpAOC8Oju\u002fYx7+sncr3SlwFQNb1FRiONQNA5T79m\u002fl8CUD0ABqqTMEGQF1YsLkMaAlAn9CbBPcYCEB6Amn6RUT8P9pmEMkpYwVA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2023"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"40tGsN6z4L8="},"y":{"dtype":"f8","bdata":"egSax4s\u002fBkA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2023","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2023","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general (69)","showlegend":false,"x":{"dtype":"f8","bdata":"9q2Hx9B2+7\u002flcQMSkzP8v5RntCh\u002fnPW\u002fPUKuzH3Z8b8L\u002f7ETdxn0v6Iypkd81fW\u002fuYsR+rYt8r\u002fecQEMcwX3v4yv3UeC7\u002fO\u002fCX12x1Oy8L\u002fj+LiY1ADzvyyegP3K0fa\u002fC1vTdIWX8b+z87vtm8Lyv6K3zS8bIPK\u002fLKEX4RAn9r\u002fPmGzoVUj3v5uCEeZSf\u002fe\u002fIpVQDzWL9r+mqkh3vjn3v5t22ob+vOu\u002fJMEOLR9N9b\u002fnNRceu1nmvy0Mxm2lePG\u002fzqvcLi+J8r\u002fH6nBBOEXyv\u002fB1FhMjcfa\u002fbBpmsrlW87\u002f\u002fHgWCukj0v+44jpV9CvO\u002fZLA+wzPC8b86gSlJ0uTcv4TC8foCQ\u002fW\u002fY\u002f+1S2V19L9QpEIdq0D\u002fv5GEIBH94PO\u002fioxwmYTj+b8MLoWhC6Xyv\u002f9vyqIQ5OO\u002fZbKFm3mA+b8TBfZmjQX4v58L0rwvXPq\u002feQ83\u002fask6L8Z2rz8NMzxv7ovikvUZ\u002fO\u002f1wMelQw5AcCJ7My\u002fGhrrvyRLKOtJHPe\u002fXumAc\u002fuO8r9kfGae1Hnrv8Az2l7LxPe\u002fxsSeGKAS9r8iqRZrfbnyv9il7Tdg6ve\u002fD1Q7sfQh97+AY5stQV3yv60jtLGGwOa\u002fypBnS3fC\u002fb+xfhi45u7zv+p6eog2tPe\u002fG+4L62Vq979XrG4g0ML3vzy9eTDscfW\u002f+v0XVEFI7b\u002fQ6fxob5H3v+rEiKU6lO+\u002fANQUR\u002fgO9L+EGJbd6lvVv9YjK5s0X\u002fa\u002f"},"y":{"dtype":"f8","bdata":"B3MRA+xtBkAVnTTAnRoHQEDkdH\u002fICAlA8qMVvhvHA0Cb24rNxZAGQLDCXOaJOgdAtfbxX24xAkBJW9Rbkb4BQMgFw6MMeAlAy3iFdSJbB0CBeEuGzSIGQBQmxwdrXQVA2nxLFSNhBUCRAfn1VTYFQP\u002f3KluWrgJAP89f63emBUCEdbK8fuYDQCZkcuKB4wFAXafEVcw7BEBPfjqgaHgFQHso7rjnUQVAdWeialwrCEAma+RIi5AEQJg+0CCksAdAag9NqQs\u002fCUD+No2uwWMFQKKpbMT\u002fAAlA2mAtetmuAUBt0iGCTgUGQDcxiE7BJQZAPO06JiHYCUDxRvFpzhkFQGAiXCYJogVACqfqWDMQA0BrvdXtjWsGQODN6L6vZAVA8sB\u002f73HLA0CWD0POqrsFQGhGQ+GJoQVASbBzvvQQBUDEU1IcD\u002fwFQPEiXO7tlwdArZYvPaN2BkBD6T3s1eUHQP\u002fy8bsS4AZAuLY7kiWQ9D9QYT1kcWkHQPVddglArQJA8BS7P\u002fG7A0BtPPm2BRQGQEsYrOYecQZA\u002fj+tgaSUCEDaFBAQzwMKQLrDx\u002fo0nwNAhHK9N7tBBUCMOp0pcQQHQPWzh9ws8AZA\u002fK7nOAnKA0D2Lq8q35MIQEWtxUJrIwRAVeufp+0MBUCtmWxTF40FQHhSTRsIewBAPwv2MyQIB0Dbu5LPF3kDQPTdfq3KbAdAcnuR15nRBUCCH0JTi5e\u002fv41FgT33IwdA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2023"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate (1)","showlegend":false,"x":{"dtype":"f8","bdata":"8ihDasTQwL8="},"y":{"dtype":"f8","bdata":"5nGR2GOc3L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2023"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor (1)","showlegend":false,"x":{"dtype":"f8","bdata":"gMtL1Nzr\u002fL8="},"y":{"dtype":"f8","bdata":"B\u002fs58kDm\u002fz8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2023","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2023","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2023","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2023"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language (4)","showlegend":false,"x":{"dtype":"f8","bdata":"bYnGRpGxBcD3jsB1vOEIwGvI3T+kRQrAzDPXf5hH3z8="},"y":{"dtype":"f8","bdata":"OfDLgE9p9z\u002fjhEnQj07pP8m5TL6pg\u002fE\u002f9GqpBqZM8z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2023"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal (1)","showlegend":false,"x":{"dtype":"f8","bdata":"5Ygo2nlACsA="},"y":{"dtype":"f8","bdata":"ent4WHOe4j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2023"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length (1)","showlegend":false,"x":{"dtype":"f8","bdata":"1wMelQw5AcA="},"y":{"dtype":"f8","bdata":"uLY7kiWQ9D8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2023","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2023","Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2023","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2023","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2023","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2023","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2023","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral (20)","showlegend":false,"x":{"dtype":"f8","bdata":"guXwweDsB8A1sLDmfmfqv5a\u002fiWkpDArARZxupLCrqj+n2n5pHhsHwLrdjPgjIwXAjRsMvXGrBsCc+HcdYz3rP0ZrDH1pHfQ\u002fLpHa6r0mwD\u002fgrRv2j9KkP5SbvIBpGuU\u002fkXEA7ycE4D9NeH1sDQ4JwB+oTEyixgjA++lfvlWTB8DtOKBteFgFwOhpbxaIy4Q\u002f42jisycnB8Bs41Y37hoGwA=="},"y":{"dtype":"f8","bdata":"HKWOKGSM6b+z0eLfxCj9v+rVv+RyNfG\u002fyjWlqBBQ1L8A7o8GoJPwvzf7SSv6H+6\u002f3CjHoYKm7r9DE4jbyEHLv4J3oExKArI\u002fGeSEkKv1zb+qF7suzcnyv6WbrTlN1PA\u002fFAOXhOzc8L8D3KQg7XHyv545VrqK7vW\u002fBfsXxBnQ9b80R9Kow2Tuv19Iq\u002fBS8u2\u002f3NVLiEJe6b9iKnLWGY73vw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2023","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2023","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2023","Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2023","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2023","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2023"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual (6)","showlegend":false,"x":{"dtype":"f8","bdata":"0tbsJn3S2b967JcFJP4EwOhjXt1eIc0\u002fD2OWvdCRBcCaRjXjhbbDPxIkcNwdnwTA"},"y":{"dtype":"f8","bdata":"fdZQcHLuAcBspUJEqM3+v7CA221e2+a\u002fe0x9hxia9r8AgOEi1\u002fD0v9wDRCk5hfu\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2023"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"uiV2QDb6AMA="},"y":{"dtype":"f8","bdata":"Y0qHjfTmAcA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2023","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2023","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions (4)","showlegend":false,"x":{"dtype":"f8","bdata":"DMeILJpm0T\u002fOHeGb75D1P48lXFjXiuA\u002fwZn93TnF9z8="},"y":{"dtype":"f8","bdata":"ClRTexBp4b\u002f5Lwzbra7NvwBScg2dCQXADr1rADPuur8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2023","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2023","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2023","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2023","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2023","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2023","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization (31)","showlegend":false,"x":{"dtype":"f8","bdata":"sHjlvk+vlD9mVWPLyD7DP6\u002f8Wm+WauG\u002fisHdv9EY7L9O5vk+yiTjvxtZJUL4rtq\u002fqS+fFldL7T9OOhUAgprsvyGgL9KcUOa\u002fp8vYYZpL5T+7wduXLoHrP0cIN+tGlOS\u002f0tWslnck5L+qVHwsvK3Iv7xlJc1mEPC\u002fBolzahUkzL8DFIelLYzQv06niqOcUN+\u002fz8+Ih+kF17+eXeVkMdniv7+pTYAM8uC\u002f5dDkLWuz4r8UoYHO8Rnwv5ft8plxX+K\u002f5A8W8jcK6b+ySkEyj67Gv6SGcc97FNi\u002fYC1\u002fzOOw5r80ogtcMX3ivzfGcpWoV\u002fw\u002fOB8rXDM2678="},"y":{"dtype":"f8","bdata":"NBE39UeCBsDQMnByRROkv3tvtnTB\u002fwjASBi03oq+CcDMgp\u002fbqy4CwCZ+h\u002fkfzAnAqT1lOrgZ7r+asyIsdb4IwECY7An4TQfAy0WACQwG0r9\u002fuEeATAXsvxBjNmTuMgXAUrjyBVgmCsA+O4lveuEMwJUCM2kDoAnAEf0dbFQlB8BAJdh6dGYJwGw7IFtMxAPAIRLezYMjCcBcTAkJl0kIwPKLdgn2ygXA8rs5ScOpA8C7Bu9BN1AJwO\u002f9ts7+PAbAZX8GdYzpBMCIG9cBAy0IwLiqULWniAbA0XnkZ4XUBsCQJhLGRqMJwPGNUBOn18K\u002fnctaaNzGBsA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2023","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2023","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2023","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2023","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2023","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2023"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political (6)","showlegend":false,"x":{"dtype":"f8","bdata":"WNFnTWxX+j\u002fJgqD061j+P7cvywiPCf4\u002fILDdcijk9j\u002fgrRv2j9KkP\u002fZjLVgfXuU\u002f"},"y":{"dtype":"f8","bdata":"5H\u002fVmwnJ+b8Sm9wRhGz3v2A9yqsuEvS\u002fOC8Oju\u002fYx7+qF7suzcnyv7BlLtiJtAfA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2023","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2023","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2023","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2023","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2023","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2023","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2023","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2023","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2023","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2023","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2023","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2023","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2023","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2023","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2023","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2023","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2023","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety (62)","showlegend":false,"x":{"dtype":"f8","bdata":"NbCw5n5n6r\u002fS1uwmfdLZv7B45b5Pr5Q\u002fOzKllS126z\u002fkpzboiej1P+q7Fbdj1ABANHDesOSj+z+A7QD3TmTxP5SLeO3KouY\u002fnk7n0Las5j9xiX0Zm3DzPzweP\u002fjwiu8\u002fAsVbYsXi6D\u002fpPWpGG2b0P1ON0yKQSek\u002fkoHy93eX4z\u002fyKENqxNDAv6J9\u002fMsE8uo\u002fSCoT8EC35z8tCBnpkcP0P8ICHEziHeE\u002fiN\u002fscbm28T9CimAqrJL4Pz2ndAhZ3PI\u002fvm3q\u002fAlx6j\u002f2JChKHtMBQHxuA\u002f140eg\u002fKjUSrM\u002fM3T9UR6Jgdi\u002fnP1Yytcxtg\u002fY\u002fK39qGnff8D9+agJBL2HsP\u002fbQN8ZlW9k\u002fgkCpf8Bb6j+ptLsK5wvsP5pGNeOFtsM\u002ftWUqR4uZ9D\u002fJL1a4R07dPxsmOP7s2Po\u002f9\u002fHi1+uc8T8Qkm\u002fzXDXgP\u002fkkiO9m4PE\u002fNARnWbI\u002f9D9CXIzhoG\u002fzP4cclPA\u002fCOk\u002fmwkcY8NB9z9uIqCK3OHlPwEOlgkLVPA\u002fgt5RW8en4D9Od7h3wzPsP8nzTek\u002fn\u002fE\u002ftpNAAH5Z3D86jNDEP0oCQAV\u002fhg\u002fYofM\u002f0nwdVtG08j+yyKm6bRf6P9gOuePd8tU\u002fNF099GkO\u002fz\u002fD2pFQnVv4P9k4\u002f4w7fvo\u002fhBiW3epb1b9rdeEAwcrnPw=="},"y":{"dtype":"f8","bdata":"s9Hi38Qo\u002fb991lBwcu4BwDQRN\u002fVHggbAeHFKWdZVBMBIJnpzi2zCv8R0grKmyQLAKwPa2VZ07r\u002fq7qmDAiILwKIUI9CxVwrABIe67rsUBMA\u002fkoOZeX4MwO7WsIDf\u002fATATvkeOCZuA8BIp7Hyn7AEwBeqJ6RpSgnAFc5qPuMzB8DmcZHYY5zcvyK+V0fv09U\u002fddLihrKiBcDErhGuV44IwOps2Vqg3wXAxF2EcohbB8Cwf7pCoD2pP+OpoxCkvQrAhxDndDZjBsDzaTTuiXXEv9NIXkoWtgPAHbDfsE4dBcCJCt7S17YFwJvPekdUCwnAsUGOwBORCMBwf2RZEi4GwAkE6PWqaQTAhLsHeD1ryT8x7BDAaqIHwACA4SLX8PS\u002fNfoYYk1nB8A0Bp2J3BIGwLvxIgPrQwPAHlJEOW5tBMDuSbDHhvsDwEvfb7372QbAj7fmdUHoBsB+76Eaw5AIwOEz8cwAJwTADwHVBPE4\u002fb+pty+WqqsIwGCHTtxc3wfArPOb5D3rBsBGwZVbgMQHwA4fsGJ8uQXA0AeaatYVBcCUnTCIXXD5v5v2SwZboAPAGKAfU+dBDcA8QA\u002f+BXgJwNQt146SaAvAWbcTvsVV\u002fL8jw8LbrCoBwP56F2P61gjAgh9CU4uXv7+YvZi8gAcFwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2023"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism (1)","showlegend":false,"x":{"dtype":"f8","bdata":"kXEA7ycE4D8="},"y":{"dtype":"f8","bdata":"FAOXhOzc8L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2023","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2023","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2023","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2023","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2023","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2023","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2023"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social (18)","showlegend":false,"x":{"dtype":"f8","bdata":"AIBbg39lAkBPX1iWMIUBQIOu6ZdqHAJAKA2bp23VA0CdCTzh6nADQPm60q+FGwVAE9Uey4eyAkC8T5RBzAUGQOwVrRuxugJAjyVcWNeK4D+7wduXLoHrPxlJ+gUDRwNAyYKg9OtY\u002fj8gC\u002f2tFjoAQAgxScUnPwFA7j\u002fMwPWgAEA++ECpQ7ACQDfGcpWoV\u002fw\u002f"},"y":{"dtype":"f8","bdata":"NqRd9CWCAsAHQP4Jf7D+v1Dek8Kbi\u002f6\u002fbo\u002fJFrWC+L9MdaLGQV4FwHCzuphI5ty\u002fDTj07XmkAcAlavYNlu\u002fYv7XdFKDU\u002feA\u002fAFJyDZ0JBcB\u002fuEeATAXsv\u002fulVMy9fKG\u002fEpvcEYRs97+GIUxlQzT9v1rqHqT\u002fmfi\u002fa7Z619X8sr9vMPU\u002fodP8v\u002fGNUBOn18K\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2023","Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2023","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2023","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2023","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2023","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2023"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity (6)","showlegend":false,"x":{"dtype":"f8","bdata":"6rsVt2PUAED4xKVzBw0BQGaEgbXKTAVAQ1r4W9VEBkDD2pFQnVv4P2ZtQoV3EgNA"},"y":{"dtype":"f8","bdata":"xHSCsqbJAsDNXrsncZXyvwNNrIcd+Pq\u002fqejQmJhV+L8jw8LbrCoBwGIH8G0fMPS\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2023","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2023","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2023","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2023","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value (15)","showlegend":false,"x":{"dtype":"f8","bdata":"ujPYtG\u002fNB0C8xck9hMAGQFETE2bzOQpARwZ1U9kdCECNKG+j4ToLQFO18OUrxAVAmwkcY8NB9z9IubxMvLcCQOhpbxaIy4Q\u002fQecNf6BODEA8DkGDz5AHQDqM0MQ\u002fSgJAK1CArz\u002f+B0A0XT30aQ7\u002fP3WWGiHO8AdA"},"y":{"dtype":"f8","bdata":"yozrR+1F5r9Lv1qncSnmvx7knBwX5ea\u002fJT5aPPJz3b+UCFwPsVXZv8gtw3thNO2\u002fDwHVBPE4\u002fb89o82+eub0v19Iq\u002fBS8u2\u002f9IvMg7Mozr8IA3DfE+3tv5SdMIhdcPm\u002f\u002f\u002fapLdSu779ZtxO+xVX8v5lArAbzMOe\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias (19)","showlegend":false,"x":{"dtype":"f8","bdata":"V3EABv8pBED5utKvhRsFQJz4dx1jPes\u002fWNFnTWxX+j\u002fOHeGb75D1P\u002fYkKEoe0wFARmsMfWkd9D\u002fsFa0bsboCQBlJ+gUDRwNAwZn93TnF9z\u002fJgqD061j+P7cvywiPCf4\u002fZlaoOSUBBEAgsN1yKOT2P9\u002fN0pu77AdApf7IBib4AkDgrRv2j9KkP5FxAO8nBOA\u002f0e2ZTuunBUA="},"y":{"dtype":"f8","bdata":"DgmoLW385D9ws7qYSObcv0MTiNvIQcu\u002f5H\u002fVmwnJ+b\u002f5Lwzbra7Nv\u002fNpNO6JdcS\u002fgnegTEoCsj+13RSg1P3gP\u002fulVMy9fKG\u002fDr1rADPuur8Sm9wRhGz3v2A9yqsuEvS\u002fVLnBlgNR8T84Lw6O79jHv1ci1AF1PuE\u002fLgfKHHP88j+qF7suzcnyvxQDl4Ts3PC\u002f2BPQGzhl8z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2024","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2024","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2024","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2024","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2024"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural (30)","showlegend":false,"x":{"dtype":"f8","bdata":"RZxupLCrqj\u002foY17dXiHNPwPGnnixiQhANHDesOSj+z9XcQAG\u002fykEQGKdPz1D5QVA63Heej3XBkCg0oOE0MYGQISANSPJ1AlAE20Atk32BUDx7wyOmcoHQD9eOXNRGApA+brSr4UbBUCc+HcdYz3rP6kvnxZXS+0\u002fvE+UQcwFBkBGawx9aR30P9\u002fN0pu77AdAmkY144W2wz8ukdrqvSbAP5SbvIBpGuU\u002fRZ0uCh\u002fHBEBLyi9KqU0FQLWGNiX3CApASO8bYzV5BUD+78CzI6T5PzfGcpWoV\u002fw\u002fywjFZvhyB0AZkExeVQQHQMwz13+YR98\u002f"},"y":{"dtype":"f8","bdata":"yjWlqBBQ1L+wgNttXtvmv4ZfTeGhQ+k\u002fKwPa2VZ07r8OCagtbfzkP5q+mdWW+t0\u002fiX\u002fRp\u002fHF8j\u002fWuFBzoKj1Pw2Hz2CDDeA\u002ftSV1Lqzo6j\u002fR6zpYiRPcP27ytL58Y9o\u002fcLO6mEjm3L9DE4jbyEHLv6k9ZTq4Ge6\u002fJWr2DZbv2L+Cd6BMSgKyP1ci1AF1PuE\u002fAIDhItfw9L8Z5ISQq\u002fXNv6WbrTlN1PA\u002fSi1yd9dP7z97VVgkLlrYPxIhSGUbjOo\u002fbgWF2wtX5T96Amn6RUT8P\u002fGNUBOn18K\u002fL4ADB0wN8D8DT+Lg3+byP\u002fRqqQamTPM\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2024","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2024","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2024"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture (3)","showlegend":false,"x":{"dtype":"f8","bdata":"EM4aIy9vA0DswQzAEwEFQHHTDKIWZwVA"},"y":{"dtype":"f8","bdata":"mhCIrLQf\u002fj9c84c3N\u002fH7PwwRD5Tl+f0\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2024","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2024","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2024"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics (14)","showlegend":false,"x":{"dtype":"f8","bdata":"DMeILJpm0T\u002f091tiGy4DQEA8TomucAFA37ti3escAkDOHeGb75D1P\u002fYkKEoe0wFA7BWtG7G6AkAZSfoFA0cDQMGZ\u002fd05xfc\u002fXzNx38KHAEBmVqg5JQEEQNHtmU7rpwVA3LvoxVMpA0DuP8zA9aAAQA=="},"y":{"dtype":"f8","bdata":"ClRTexBp4b9g81mAgDj9P7wJmtkjGf8\u002f2Mqtr7Z8+j\u002f5Lwzbra7Nv\u002fNpNO6JdcS\u002ftd0UoNT94D\u002f7pVTMvXyhvw69awAz7rq\u002fEPW4m9P+A0BUucGWA1HxP9gT0Bs4ZfM\u002fijxL00k6A0BrtnrX1fyyvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2024","Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2024","Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2024","Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2024","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2024","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2024","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity (10)","showlegend":false,"x":{"dtype":"f8","bdata":"5Kc26Ino9T9mVWPLyD7DP\u002f3u0UoR\u002ff8\u002fOeP4qyQ39T8RTbu53yz7P0KKYCqskvg\u002fp8vYYZpL5T9fM3HfwocAQKX+yAYm+AJAlJu8gGka5T8="},"y":{"dtype":"f8","bdata":"SCZ6c4tswr\u002fQMnByRROkvwvgFVbAygNABBdvQnmUBkDNdPd+fMgDQLB\u002fukKgPak\u002fy0WACQwG0r8Q9bib0\u002f4DQC4Hyhxz\u002fPI\u002fpZutOU3U8D8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical (6)","showlegend":false,"x":{"dtype":"f8","bdata":"nlovd09+4T9gRoNAKtv2P6ce8mTWZPE\u002fu8Hbly6B6z83xnKVqFf8PwPh2B7yw+w\u002f"},"y":{"dtype":"f8","bdata":"Zg4a2F54A0DDnX2AhxoHQJlTDZRbWgdAf7hHgEwF7L\u002fxjVATp9fCvwnfIInieQVA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2024","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality (21)","showlegend":false,"x":{"dtype":"f8","bdata":"rjkDriqOsD8V5xLHeeu0P+axFY7KyNM\u002fUD1B6TJC1D8ePW8rS3TgP6J9\u002fMsE8uo\u002fMenCm2d33D+rVNb7U13PP66J8sfmpsm\u002fHhAsJ18j4z+CQKl\u002fwFvqP67nBlvVzeI\u002fILDdcijk9j+t7YF0RFTIP7Q9PIvZjeI\u002fK5kyQ6MJ0D9bk1ZH3tbRP9Yu3tJf5dc\u002frv4SwP+Kw7\u002f+78CzI6T5P+aoOn8iedY\u002f"},"y":{"dtype":"f8","bdata":"05CmaWZxBkDGT\u002fjJNqUJQGr1seFUAQtAiW0v9nr0B0BoE1\u002fqmQAMQCK+V0fv09U\u002fCm5JtdzqBEDgs\u002fSUAwgJQKtv9xNjIAdAvP7qKjvwBkCEuwd4PWvJP+e8a6L9+QpAOC8Oju\u002fYx7+sncr3SlwFQNb1FRiONQNA5T79m\u002fl8CUD0ABqqTMEGQF1YsLkMaAlAn9CbBPcYCEB6Amn6RUT8P9pmEMkpYwVA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2024"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"40tGsN6z4L8="},"y":{"dtype":"f8","bdata":"egSax4s\u002fBkA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2024","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2024","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general (69)","showlegend":false,"x":{"dtype":"f8","bdata":"9q2Hx9B2+7\u002flcQMSkzP8v5RntCh\u002fnPW\u002fPUKuzH3Z8b8L\u002f7ETdxn0v6Iypkd81fW\u002fuYsR+rYt8r\u002fecQEMcwX3v4yv3UeC7\u002fO\u002fCX12x1Oy8L\u002fj+LiY1ADzvyyegP3K0fa\u002fC1vTdIWX8b+z87vtm8Lyv6K3zS8bIPK\u002fLKEX4RAn9r\u002fPmGzoVUj3v5uCEeZSf\u002fe\u002fIpVQDzWL9r+mqkh3vjn3v5t22ob+vOu\u002fJMEOLR9N9b\u002fnNRceu1nmvy0Mxm2lePG\u002fzqvcLi+J8r\u002fH6nBBOEXyv\u002fB1FhMjcfa\u002fbBpmsrlW87\u002f\u002fHgWCukj0v+44jpV9CvO\u002fZLA+wzPC8b86gSlJ0uTcv4TC8foCQ\u002fW\u002fY\u002f+1S2V19L9QpEIdq0D\u002fv5GEIBH94PO\u002fioxwmYTj+b8MLoWhC6Xyv\u002f9vyqIQ5OO\u002fZbKFm3mA+b8TBfZmjQX4v58L0rwvXPq\u002feQ83\u002fask6L8Z2rz8NMzxv7ovikvUZ\u002fO\u002f1wMelQw5AcCJ7My\u002fGhrrvyRLKOtJHPe\u002fXumAc\u002fuO8r9kfGae1Hnrv8Az2l7LxPe\u002fxsSeGKAS9r8iqRZrfbnyv9il7Tdg6ve\u002fD1Q7sfQh97+AY5stQV3yv60jtLGGwOa\u002fypBnS3fC\u002fb+xfhi45u7zv+p6eog2tPe\u002fG+4L62Vq979XrG4g0ML3vzy9eTDscfW\u002f+v0XVEFI7b\u002fQ6fxob5H3v+rEiKU6lO+\u002fANQUR\u002fgO9L+EGJbd6lvVv9YjK5s0X\u002fa\u002f"},"y":{"dtype":"f8","bdata":"B3MRA+xtBkAVnTTAnRoHQEDkdH\u002fICAlA8qMVvhvHA0Cb24rNxZAGQLDCXOaJOgdAtfbxX24xAkBJW9Rbkb4BQMgFw6MMeAlAy3iFdSJbB0CBeEuGzSIGQBQmxwdrXQVA2nxLFSNhBUCRAfn1VTYFQP\u002f3KluWrgJAP89f63emBUCEdbK8fuYDQCZkcuKB4wFAXafEVcw7BEBPfjqgaHgFQHso7rjnUQVAdWeialwrCEAma+RIi5AEQJg+0CCksAdAag9NqQs\u002fCUD+No2uwWMFQKKpbMT\u002fAAlA2mAtetmuAUBt0iGCTgUGQDcxiE7BJQZAPO06JiHYCUDxRvFpzhkFQGAiXCYJogVACqfqWDMQA0BrvdXtjWsGQODN6L6vZAVA8sB\u002f73HLA0CWD0POqrsFQGhGQ+GJoQVASbBzvvQQBUDEU1IcD\u002fwFQPEiXO7tlwdArZYvPaN2BkBD6T3s1eUHQP\u002fy8bsS4AZAuLY7kiWQ9D9QYT1kcWkHQPVddglArQJA8BS7P\u002fG7A0BtPPm2BRQGQEsYrOYecQZA\u002fj+tgaSUCEDaFBAQzwMKQLrDx\u002fo0nwNAhHK9N7tBBUCMOp0pcQQHQPWzh9ws8AZA\u002fK7nOAnKA0D2Lq8q35MIQEWtxUJrIwRAVeufp+0MBUCtmWxTF40FQHhSTRsIewBAPwv2MyQIB0Dbu5LPF3kDQPTdfq3KbAdAcnuR15nRBUCCH0JTi5e\u002fv41FgT33IwdA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2024"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate (1)","showlegend":false,"x":{"dtype":"f8","bdata":"8ihDasTQwL8="},"y":{"dtype":"f8","bdata":"5nGR2GOc3L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2024"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor (1)","showlegend":false,"x":{"dtype":"f8","bdata":"gMtL1Nzr\u002fL8="},"y":{"dtype":"f8","bdata":"B\u002fs58kDm\u002fz8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2024","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2024","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2024","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2024"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language (4)","showlegend":false,"x":{"dtype":"f8","bdata":"bYnGRpGxBcD3jsB1vOEIwGvI3T+kRQrAzDPXf5hH3z8="},"y":{"dtype":"f8","bdata":"OfDLgE9p9z\u002fjhEnQj07pP8m5TL6pg\u002fE\u002f9GqpBqZM8z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2024"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal (1)","showlegend":false,"x":{"dtype":"f8","bdata":"5Ygo2nlACsA="},"y":{"dtype":"f8","bdata":"ent4WHOe4j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2024"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length (1)","showlegend":false,"x":{"dtype":"f8","bdata":"1wMelQw5AcA="},"y":{"dtype":"f8","bdata":"uLY7kiWQ9D8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2024","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2024","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral (20)","showlegend":false,"x":{"dtype":"f8","bdata":"guXwweDsB8A1sLDmfmfqv5a\u002fiWkpDArARZxupLCrqj+n2n5pHhsHwLrdjPgjIwXAjRsMvXGrBsCc+HcdYz3rP0ZrDH1pHfQ\u002fLpHa6r0mwD\u002fgrRv2j9KkP5SbvIBpGuU\u002fkXEA7ycE4D9NeH1sDQ4JwB+oTEyixgjA++lfvlWTB8DtOKBteFgFwOhpbxaIy4Q\u002f42jisycnB8Bs41Y37hoGwA=="},"y":{"dtype":"f8","bdata":"HKWOKGSM6b+z0eLfxCj9v+rVv+RyNfG\u002fyjWlqBBQ1L8A7o8GoJPwvzf7SSv6H+6\u002f3CjHoYKm7r9DE4jbyEHLv4J3oExKArI\u002fGeSEkKv1zb+qF7suzcnyv6WbrTlN1PA\u002fFAOXhOzc8L8D3KQg7XHyv545VrqK7vW\u002fBfsXxBnQ9b80R9Kow2Tuv19Iq\u002fBS8u2\u002f3NVLiEJe6b9iKnLWGY73vw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2024","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2024","Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual (6)","showlegend":false,"x":{"dtype":"f8","bdata":"0tbsJn3S2b967JcFJP4EwOhjXt1eIc0\u002fD2OWvdCRBcCaRjXjhbbDPxIkcNwdnwTA"},"y":{"dtype":"f8","bdata":"fdZQcHLuAcBspUJEqM3+v7CA221e2+a\u002fe0x9hxia9r8AgOEi1\u002fD0v9wDRCk5hfu\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2024"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"uiV2QDb6AMA="},"y":{"dtype":"f8","bdata":"Y0qHjfTmAcA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions (4)","showlegend":false,"x":{"dtype":"f8","bdata":"DMeILJpm0T\u002fOHeGb75D1P48lXFjXiuA\u002fwZn93TnF9z8="},"y":{"dtype":"f8","bdata":"ClRTexBp4b\u002f5Lwzbra7NvwBScg2dCQXADr1rADPuur8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2024","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2024","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2024","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization (31)","showlegend":false,"x":{"dtype":"f8","bdata":"sHjlvk+vlD9mVWPLyD7DP6\u002f8Wm+WauG\u002fisHdv9EY7L9O5vk+yiTjvxtZJUL4rtq\u002fqS+fFldL7T9OOhUAgprsvyGgL9KcUOa\u002fp8vYYZpL5T+7wduXLoHrP0cIN+tGlOS\u002f0tWslnck5L+qVHwsvK3Iv7xlJc1mEPC\u002fBolzahUkzL8DFIelLYzQv06niqOcUN+\u002fz8+Ih+kF17+eXeVkMdniv7+pTYAM8uC\u002f5dDkLWuz4r8UoYHO8Rnwv5ft8plxX+K\u002f5A8W8jcK6b+ySkEyj67Gv6SGcc97FNi\u002fYC1\u002fzOOw5r80ogtcMX3ivzfGcpWoV\u002fw\u002fOB8rXDM2678="},"y":{"dtype":"f8","bdata":"NBE39UeCBsDQMnByRROkv3tvtnTB\u002fwjASBi03oq+CcDMgp\u002fbqy4CwCZ+h\u002fkfzAnAqT1lOrgZ7r+asyIsdb4IwECY7An4TQfAy0WACQwG0r9\u002fuEeATAXsvxBjNmTuMgXAUrjyBVgmCsA+O4lveuEMwJUCM2kDoAnAEf0dbFQlB8BAJdh6dGYJwGw7IFtMxAPAIRLezYMjCcBcTAkJl0kIwPKLdgn2ygXA8rs5ScOpA8C7Bu9BN1AJwO\u002f9ts7+PAbAZX8GdYzpBMCIG9cBAy0IwLiqULWniAbA0XnkZ4XUBsCQJhLGRqMJwPGNUBOn18K\u002fnctaaNzGBsA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2024"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political (6)","showlegend":false,"x":{"dtype":"f8","bdata":"WNFnTWxX+j\u002fJgqD061j+P7cvywiPCf4\u002fILDdcijk9j\u002fgrRv2j9KkP\u002fZjLVgfXuU\u002f"},"y":{"dtype":"f8","bdata":"5H\u002fVmwnJ+b8Sm9wRhGz3v2A9yqsuEvS\u002fOC8Oju\u002fYx7+qF7suzcnyv7BlLtiJtAfA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2024","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2024","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2024","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2024","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2024","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2024","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2024","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2024","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2024","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2024","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2024","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety (62)","showlegend":false,"x":{"dtype":"f8","bdata":"NbCw5n5n6r\u002fS1uwmfdLZv7B45b5Pr5Q\u002fOzKllS126z\u002fkpzboiej1P+q7Fbdj1ABANHDesOSj+z+A7QD3TmTxP5SLeO3KouY\u002fnk7n0Las5j9xiX0Zm3DzPzweP\u002fjwiu8\u002fAsVbYsXi6D\u002fpPWpGG2b0P1ON0yKQSek\u002fkoHy93eX4z\u002fyKENqxNDAv6J9\u002fMsE8uo\u002fSCoT8EC35z8tCBnpkcP0P8ICHEziHeE\u002fiN\u002fscbm28T9CimAqrJL4Pz2ndAhZ3PI\u002fvm3q\u002fAlx6j\u002f2JChKHtMBQHxuA\u002f140eg\u002fKjUSrM\u002fM3T9UR6Jgdi\u002fnP1Yytcxtg\u002fY\u002fK39qGnff8D9+agJBL2HsP\u002fbQN8ZlW9k\u002fgkCpf8Bb6j+ptLsK5wvsP5pGNeOFtsM\u002ftWUqR4uZ9D\u002fJL1a4R07dPxsmOP7s2Po\u002f9\u002fHi1+uc8T8Qkm\u002fzXDXgP\u002fkkiO9m4PE\u002fNARnWbI\u002f9D9CXIzhoG\u002fzP4cclPA\u002fCOk\u002fmwkcY8NB9z9uIqCK3OHlPwEOlgkLVPA\u002fgt5RW8en4D9Od7h3wzPsP8nzTek\u002fn\u002fE\u002ftpNAAH5Z3D86jNDEP0oCQAV\u002fhg\u002fYofM\u002f0nwdVtG08j+yyKm6bRf6P9gOuePd8tU\u002fNF099GkO\u002fz\u002fD2pFQnVv4P9k4\u002f4w7fvo\u002fhBiW3epb1b9rdeEAwcrnPw=="},"y":{"dtype":"f8","bdata":"s9Hi38Qo\u002fb991lBwcu4BwDQRN\u002fVHggbAeHFKWdZVBMBIJnpzi2zCv8R0grKmyQLAKwPa2VZ07r\u002fq7qmDAiILwKIUI9CxVwrABIe67rsUBMA\u002fkoOZeX4MwO7WsIDf\u002fATATvkeOCZuA8BIp7Hyn7AEwBeqJ6RpSgnAFc5qPuMzB8DmcZHYY5zcvyK+V0fv09U\u002fddLihrKiBcDErhGuV44IwOps2Vqg3wXAxF2EcohbB8Cwf7pCoD2pP+OpoxCkvQrAhxDndDZjBsDzaTTuiXXEv9NIXkoWtgPAHbDfsE4dBcCJCt7S17YFwJvPekdUCwnAsUGOwBORCMBwf2RZEi4GwAkE6PWqaQTAhLsHeD1ryT8x7BDAaqIHwACA4SLX8PS\u002fNfoYYk1nB8A0Bp2J3BIGwLvxIgPrQwPAHlJEOW5tBMDuSbDHhvsDwEvfb7372QbAj7fmdUHoBsB+76Eaw5AIwOEz8cwAJwTADwHVBPE4\u002fb+pty+WqqsIwGCHTtxc3wfArPOb5D3rBsBGwZVbgMQHwA4fsGJ8uQXA0AeaatYVBcCUnTCIXXD5v5v2SwZboAPAGKAfU+dBDcA8QA\u002f+BXgJwNQt146SaAvAWbcTvsVV\u002fL8jw8LbrCoBwP56F2P61gjAgh9CU4uXv7+YvZi8gAcFwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism (1)","showlegend":false,"x":{"dtype":"f8","bdata":"kXEA7ycE4D8="},"y":{"dtype":"f8","bdata":"FAOXhOzc8L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2024","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2024"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social (18)","showlegend":false,"x":{"dtype":"f8","bdata":"AIBbg39lAkBPX1iWMIUBQIOu6ZdqHAJAKA2bp23VA0CdCTzh6nADQPm60q+FGwVAE9Uey4eyAkC8T5RBzAUGQOwVrRuxugJAjyVcWNeK4D+7wduXLoHrPxlJ+gUDRwNAyYKg9OtY\u002fj8gC\u002f2tFjoAQAgxScUnPwFA7j\u002fMwPWgAEA++ECpQ7ACQDfGcpWoV\u002fw\u002f"},"y":{"dtype":"f8","bdata":"NqRd9CWCAsAHQP4Jf7D+v1Dek8Kbi\u002f6\u002fbo\u002fJFrWC+L9MdaLGQV4FwHCzuphI5ty\u002fDTj07XmkAcAlavYNlu\u002fYv7XdFKDU\u002feA\u002fAFJyDZ0JBcB\u002fuEeATAXsv\u002fulVMy9fKG\u002fEpvcEYRs97+GIUxlQzT9v1rqHqT\u002fmfi\u002fa7Z619X8sr9vMPU\u002fodP8v\u002fGNUBOn18K\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2024","Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2024","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity (6)","showlegend":false,"x":{"dtype":"f8","bdata":"6rsVt2PUAED4xKVzBw0BQGaEgbXKTAVAQ1r4W9VEBkDD2pFQnVv4P2ZtQoV3EgNA"},"y":{"dtype":"f8","bdata":"xHSCsqbJAsDNXrsncZXyvwNNrIcd+Pq\u002fqejQmJhV+L8jw8LbrCoBwGIH8G0fMPS\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2024","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2024","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2024","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2024","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value (15)","showlegend":false,"x":{"dtype":"f8","bdata":"ujPYtG\u002fNB0C8xck9hMAGQFETE2bzOQpARwZ1U9kdCECNKG+j4ToLQFO18OUrxAVAmwkcY8NB9z9IubxMvLcCQOhpbxaIy4Q\u002fQecNf6BODEA8DkGDz5AHQDqM0MQ\u002fSgJAK1CArz\u002f+B0A0XT30aQ7\u002fP3WWGiHO8AdA"},"y":{"dtype":"f8","bdata":"yozrR+1F5r9Lv1qncSnmvx7knBwX5ea\u002fJT5aPPJz3b+UCFwPsVXZv8gtw3thNO2\u002fDwHVBPE4\u002fb89o82+eub0v19Iq\u002fBS8u2\u002f9IvMg7Mozr8IA3DfE+3tv5SdMIhdcPm\u002f\u002f\u002fapLdSu779ZtxO+xVX8v5lArAbzMOe\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2025","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2025","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2025","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2025","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2025","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2025","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2025","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2025","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2025","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2025","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2025"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias (19)","showlegend":false,"x":{"dtype":"f8","bdata":"V3EABv8pBED5utKvhRsFQJz4dx1jPes\u002fWNFnTWxX+j\u002fOHeGb75D1P\u002fYkKEoe0wFARmsMfWkd9D\u002fsFa0bsboCQBlJ+gUDRwNAwZn93TnF9z\u002fJgqD061j+P7cvywiPCf4\u002fZlaoOSUBBEAgsN1yKOT2P9\u002fN0pu77AdApf7IBib4AkDgrRv2j9KkP5FxAO8nBOA\u002f0e2ZTuunBUA="},"y":{"dtype":"f8","bdata":"DgmoLW385D9ws7qYSObcv0MTiNvIQcu\u002f5H\u002fVmwnJ+b\u002f5Lwzbra7Nv\u002fNpNO6JdcS\u002fgnegTEoCsj+13RSg1P3gP\u002fulVMy9fKG\u002fDr1rADPuur8Sm9wRhGz3v2A9yqsuEvS\u002fVLnBlgNR8T84Lw6O79jHv1ci1AF1PuE\u002fLgfKHHP88j+qF7suzcnyvxQDl4Ts3PC\u002f2BPQGzhl8z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2025","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2025","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2025","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2025","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2025","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2025","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2025","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2025"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural (30)","showlegend":false,"x":{"dtype":"f8","bdata":"RZxupLCrqj\u002foY17dXiHNPwPGnnixiQhANHDesOSj+z9XcQAG\u002fykEQGKdPz1D5QVA63Heej3XBkCg0oOE0MYGQISANSPJ1AlAE20Atk32BUDx7wyOmcoHQD9eOXNRGApA+brSr4UbBUCc+HcdYz3rP6kvnxZXS+0\u002fvE+UQcwFBkBGawx9aR30P9\u002fN0pu77AdAmkY144W2wz8ukdrqvSbAP5SbvIBpGuU\u002fRZ0uCh\u002fHBEBLyi9KqU0FQLWGNiX3CApASO8bYzV5BUD+78CzI6T5PzfGcpWoV\u002fw\u002fywjFZvhyB0AZkExeVQQHQMwz13+YR98\u002f"},"y":{"dtype":"f8","bdata":"yjWlqBBQ1L+wgNttXtvmv4ZfTeGhQ+k\u002fKwPa2VZ07r8OCagtbfzkP5q+mdWW+t0\u002fiX\u002fRp\u002fHF8j\u002fWuFBzoKj1Pw2Hz2CDDeA\u002ftSV1Lqzo6j\u002fR6zpYiRPcP27ytL58Y9o\u002fcLO6mEjm3L9DE4jbyEHLv6k9ZTq4Ge6\u002fJWr2DZbv2L+Cd6BMSgKyP1ci1AF1PuE\u002fAIDhItfw9L8Z5ISQq\u002fXNv6WbrTlN1PA\u002fSi1yd9dP7z97VVgkLlrYPxIhSGUbjOo\u002fbgWF2wtX5T96Amn6RUT8P\u002fGNUBOn18K\u002fL4ADB0wN8D8DT+Lg3+byP\u002fRqqQamTPM\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture (3)","showlegend":false,"x":{"dtype":"f8","bdata":"EM4aIy9vA0DswQzAEwEFQHHTDKIWZwVA"},"y":{"dtype":"f8","bdata":"mhCIrLQf\u002fj9c84c3N\u002fH7PwwRD5Tl+f0\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2025","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2025","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2025","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2025","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2025","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2025"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics (14)","showlegend":false,"x":{"dtype":"f8","bdata":"DMeILJpm0T\u002f091tiGy4DQEA8TomucAFA37ti3escAkDOHeGb75D1P\u002fYkKEoe0wFA7BWtG7G6AkAZSfoFA0cDQMGZ\u002fd05xfc\u002fXzNx38KHAEBmVqg5JQEEQNHtmU7rpwVA3LvoxVMpA0DuP8zA9aAAQA=="},"y":{"dtype":"f8","bdata":"ClRTexBp4b9g81mAgDj9P7wJmtkjGf8\u002f2Mqtr7Z8+j\u002f5Lwzbra7Nv\u002fNpNO6JdcS\u002ftd0UoNT94D\u002f7pVTMvXyhvw69awAz7rq\u002fEPW4m9P+A0BUucGWA1HxP9gT0Bs4ZfM\u002fijxL00k6A0BrtnrX1fyyvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2025","Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2025","Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2025","Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2025","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2025","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2025","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2025","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2025"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity (10)","showlegend":false,"x":{"dtype":"f8","bdata":"5Kc26Ino9T9mVWPLyD7DP\u002f3u0UoR\u002ff8\u002fOeP4qyQ39T8RTbu53yz7P0KKYCqskvg\u002fp8vYYZpL5T9fM3HfwocAQKX+yAYm+AJAlJu8gGka5T8="},"y":{"dtype":"f8","bdata":"SCZ6c4tswr\u002fQMnByRROkvwvgFVbAygNABBdvQnmUBkDNdPd+fMgDQLB\u002fukKgPak\u002fy0WACQwG0r8Q9bib0\u002f4DQC4Hyhxz\u002fPI\u002fpZutOU3U8D8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical (6)","showlegend":false,"x":{"dtype":"f8","bdata":"nlovd09+4T9gRoNAKtv2P6ce8mTWZPE\u002fu8Hbly6B6z83xnKVqFf8PwPh2B7yw+w\u002f"},"y":{"dtype":"f8","bdata":"Zg4a2F54A0DDnX2AhxoHQJlTDZRbWgdAf7hHgEwF7L\u002fxjVATp9fCvwnfIInieQVA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2025","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2025","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2025","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2025","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality (21)","showlegend":false,"x":{"dtype":"f8","bdata":"rjkDriqOsD8V5xLHeeu0P+axFY7KyNM\u002fUD1B6TJC1D8ePW8rS3TgP6J9\u002fMsE8uo\u002fMenCm2d33D+rVNb7U13PP66J8sfmpsm\u002fHhAsJ18j4z+CQKl\u002fwFvqP67nBlvVzeI\u002fILDdcijk9j+t7YF0RFTIP7Q9PIvZjeI\u002fK5kyQ6MJ0D9bk1ZH3tbRP9Yu3tJf5dc\u002frv4SwP+Kw7\u002f+78CzI6T5P+aoOn8iedY\u002f"},"y":{"dtype":"f8","bdata":"05CmaWZxBkDGT\u002fjJNqUJQGr1seFUAQtAiW0v9nr0B0BoE1\u002fqmQAMQCK+V0fv09U\u002fCm5JtdzqBEDgs\u002fSUAwgJQKtv9xNjIAdAvP7qKjvwBkCEuwd4PWvJP+e8a6L9+QpAOC8Oju\u002fYx7+sncr3SlwFQNb1FRiONQNA5T79m\u002fl8CUD0ABqqTMEGQF1YsLkMaAlAn9CbBPcYCEB6Amn6RUT8P9pmEMkpYwVA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2025"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"40tGsN6z4L8="},"y":{"dtype":"f8","bdata":"egSax4s\u002fBkA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2025","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2025","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general (69)","showlegend":false,"x":{"dtype":"f8","bdata":"9q2Hx9B2+7\u002flcQMSkzP8v5RntCh\u002fnPW\u002fPUKuzH3Z8b8L\u002f7ETdxn0v6Iypkd81fW\u002fuYsR+rYt8r\u002fecQEMcwX3v4yv3UeC7\u002fO\u002fCX12x1Oy8L\u002fj+LiY1ADzvyyegP3K0fa\u002fC1vTdIWX8b+z87vtm8Lyv6K3zS8bIPK\u002fLKEX4RAn9r\u002fPmGzoVUj3v5uCEeZSf\u002fe\u002fIpVQDzWL9r+mqkh3vjn3v5t22ob+vOu\u002fJMEOLR9N9b\u002fnNRceu1nmvy0Mxm2lePG\u002fzqvcLi+J8r\u002fH6nBBOEXyv\u002fB1FhMjcfa\u002fbBpmsrlW87\u002f\u002fHgWCukj0v+44jpV9CvO\u002fZLA+wzPC8b86gSlJ0uTcv4TC8foCQ\u002fW\u002fY\u002f+1S2V19L9QpEIdq0D\u002fv5GEIBH94PO\u002fioxwmYTj+b8MLoWhC6Xyv\u002f9vyqIQ5OO\u002fZbKFm3mA+b8TBfZmjQX4v58L0rwvXPq\u002feQ83\u002fask6L8Z2rz8NMzxv7ovikvUZ\u002fO\u002f1wMelQw5AcCJ7My\u002fGhrrvyRLKOtJHPe\u002fXumAc\u002fuO8r9kfGae1Hnrv8Az2l7LxPe\u002fxsSeGKAS9r8iqRZrfbnyv9il7Tdg6ve\u002fD1Q7sfQh97+AY5stQV3yv60jtLGGwOa\u002fypBnS3fC\u002fb+xfhi45u7zv+p6eog2tPe\u002fG+4L62Vq979XrG4g0ML3vzy9eTDscfW\u002f+v0XVEFI7b\u002fQ6fxob5H3v+rEiKU6lO+\u002fANQUR\u002fgO9L+EGJbd6lvVv9YjK5s0X\u002fa\u002f"},"y":{"dtype":"f8","bdata":"B3MRA+xtBkAVnTTAnRoHQEDkdH\u002fICAlA8qMVvhvHA0Cb24rNxZAGQLDCXOaJOgdAtfbxX24xAkBJW9Rbkb4BQMgFw6MMeAlAy3iFdSJbB0CBeEuGzSIGQBQmxwdrXQVA2nxLFSNhBUCRAfn1VTYFQP\u002f3KluWrgJAP89f63emBUCEdbK8fuYDQCZkcuKB4wFAXafEVcw7BEBPfjqgaHgFQHso7rjnUQVAdWeialwrCEAma+RIi5AEQJg+0CCksAdAag9NqQs\u002fCUD+No2uwWMFQKKpbMT\u002fAAlA2mAtetmuAUBt0iGCTgUGQDcxiE7BJQZAPO06JiHYCUDxRvFpzhkFQGAiXCYJogVACqfqWDMQA0BrvdXtjWsGQODN6L6vZAVA8sB\u002f73HLA0CWD0POqrsFQGhGQ+GJoQVASbBzvvQQBUDEU1IcD\u002fwFQPEiXO7tlwdArZYvPaN2BkBD6T3s1eUHQP\u002fy8bsS4AZAuLY7kiWQ9D9QYT1kcWkHQPVddglArQJA8BS7P\u002fG7A0BtPPm2BRQGQEsYrOYecQZA\u002fj+tgaSUCEDaFBAQzwMKQLrDx\u002fo0nwNAhHK9N7tBBUCMOp0pcQQHQPWzh9ws8AZA\u002fK7nOAnKA0D2Lq8q35MIQEWtxUJrIwRAVeufp+0MBUCtmWxTF40FQHhSTRsIewBAPwv2MyQIB0Dbu5LPF3kDQPTdfq3KbAdAcnuR15nRBUCCH0JTi5e\u002fv41FgT33IwdA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2025"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate (1)","showlegend":false,"x":{"dtype":"f8","bdata":"8ihDasTQwL8="},"y":{"dtype":"f8","bdata":"5nGR2GOc3L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2025"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor (1)","showlegend":false,"x":{"dtype":"f8","bdata":"gMtL1Nzr\u002fL8="},"y":{"dtype":"f8","bdata":"B\u002fs58kDm\u002fz8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2025"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language (4)","showlegend":false,"x":{"dtype":"f8","bdata":"bYnGRpGxBcD3jsB1vOEIwGvI3T+kRQrAzDPXf5hH3z8="},"y":{"dtype":"f8","bdata":"OfDLgE9p9z\u002fjhEnQj07pP8m5TL6pg\u002fE\u002f9GqpBqZM8z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2025"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal (1)","showlegend":false,"x":{"dtype":"f8","bdata":"5Ygo2nlACsA="},"y":{"dtype":"f8","bdata":"ent4WHOe4j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2025"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length (1)","showlegend":false,"x":{"dtype":"f8","bdata":"1wMelQw5AcA="},"y":{"dtype":"f8","bdata":"uLY7kiWQ9D8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2025","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2025","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2025","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2025","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2025","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral (20)","showlegend":false,"x":{"dtype":"f8","bdata":"guXwweDsB8A1sLDmfmfqv5a\u002fiWkpDArARZxupLCrqj+n2n5pHhsHwLrdjPgjIwXAjRsMvXGrBsCc+HcdYz3rP0ZrDH1pHfQ\u002fLpHa6r0mwD\u002fgrRv2j9KkP5SbvIBpGuU\u002fkXEA7ycE4D9NeH1sDQ4JwB+oTEyixgjA++lfvlWTB8DtOKBteFgFwOhpbxaIy4Q\u002f42jisycnB8Bs41Y37hoGwA=="},"y":{"dtype":"f8","bdata":"HKWOKGSM6b+z0eLfxCj9v+rVv+RyNfG\u002fyjWlqBBQ1L8A7o8GoJPwvzf7SSv6H+6\u002f3CjHoYKm7r9DE4jbyEHLv4J3oExKArI\u002fGeSEkKv1zb+qF7suzcnyv6WbrTlN1PA\u002fFAOXhOzc8L8D3KQg7XHyv545VrqK7vW\u002fBfsXxBnQ9b80R9Kow2Tuv19Iq\u002fBS8u2\u002f3NVLiEJe6b9iKnLWGY73vw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2025","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2025","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2025","Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2025","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2025","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2025"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual (6)","showlegend":false,"x":{"dtype":"f8","bdata":"0tbsJn3S2b967JcFJP4EwOhjXt1eIc0\u002fD2OWvdCRBcCaRjXjhbbDPxIkcNwdnwTA"},"y":{"dtype":"f8","bdata":"fdZQcHLuAcBspUJEqM3+v7CA221e2+a\u002fe0x9hxia9r8AgOEi1\u002fD0v9wDRCk5hfu\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2025"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"uiV2QDb6AMA="},"y":{"dtype":"f8","bdata":"Y0qHjfTmAcA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2025","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2025","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions (4)","showlegend":false,"x":{"dtype":"f8","bdata":"DMeILJpm0T\u002fOHeGb75D1P48lXFjXiuA\u002fwZn93TnF9z8="},"y":{"dtype":"f8","bdata":"ClRTexBp4b\u002f5Lwzbra7NvwBScg2dCQXADr1rADPuur8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2025","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2025","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2025","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2025","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2025","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization (31)","showlegend":false,"x":{"dtype":"f8","bdata":"sHjlvk+vlD9mVWPLyD7DP6\u002f8Wm+WauG\u002fisHdv9EY7L9O5vk+yiTjvxtZJUL4rtq\u002fqS+fFldL7T9OOhUAgprsvyGgL9KcUOa\u002fp8vYYZpL5T+7wduXLoHrP0cIN+tGlOS\u002f0tWslnck5L+qVHwsvK3Iv7xlJc1mEPC\u002fBolzahUkzL8DFIelLYzQv06niqOcUN+\u002fz8+Ih+kF17+eXeVkMdniv7+pTYAM8uC\u002f5dDkLWuz4r8UoYHO8Rnwv5ft8plxX+K\u002f5A8W8jcK6b+ySkEyj67Gv6SGcc97FNi\u002fYC1\u002fzOOw5r80ogtcMX3ivzfGcpWoV\u002fw\u002fOB8rXDM2678="},"y":{"dtype":"f8","bdata":"NBE39UeCBsDQMnByRROkv3tvtnTB\u002fwjASBi03oq+CcDMgp\u002fbqy4CwCZ+h\u002fkfzAnAqT1lOrgZ7r+asyIsdb4IwECY7An4TQfAy0WACQwG0r9\u002fuEeATAXsvxBjNmTuMgXAUrjyBVgmCsA+O4lveuEMwJUCM2kDoAnAEf0dbFQlB8BAJdh6dGYJwGw7IFtMxAPAIRLezYMjCcBcTAkJl0kIwPKLdgn2ygXA8rs5ScOpA8C7Bu9BN1AJwO\u002f9ts7+PAbAZX8GdYzpBMCIG9cBAy0IwLiqULWniAbA0XnkZ4XUBsCQJhLGRqMJwPGNUBOn18K\u002fnctaaNzGBsA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2025","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2025","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2025","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2025","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2025","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2025"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political (6)","showlegend":false,"x":{"dtype":"f8","bdata":"WNFnTWxX+j\u002fJgqD061j+P7cvywiPCf4\u002fILDdcijk9j\u002fgrRv2j9KkP\u002fZjLVgfXuU\u002f"},"y":{"dtype":"f8","bdata":"5H\u002fVmwnJ+b8Sm9wRhGz3v2A9yqsuEvS\u002fOC8Oju\u002fYx7+qF7suzcnyv7BlLtiJtAfA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2025","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2025","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2025","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2025","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2025","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2025","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2025","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2025","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2025","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2025","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2025","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2025","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2025","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety (62)","showlegend":false,"x":{"dtype":"f8","bdata":"NbCw5n5n6r\u002fS1uwmfdLZv7B45b5Pr5Q\u002fOzKllS126z\u002fkpzboiej1P+q7Fbdj1ABANHDesOSj+z+A7QD3TmTxP5SLeO3KouY\u002fnk7n0Las5j9xiX0Zm3DzPzweP\u002fjwiu8\u002fAsVbYsXi6D\u002fpPWpGG2b0P1ON0yKQSek\u002fkoHy93eX4z\u002fyKENqxNDAv6J9\u002fMsE8uo\u002fSCoT8EC35z8tCBnpkcP0P8ICHEziHeE\u002fiN\u002fscbm28T9CimAqrJL4Pz2ndAhZ3PI\u002fvm3q\u002fAlx6j\u002f2JChKHtMBQHxuA\u002f140eg\u002fKjUSrM\u002fM3T9UR6Jgdi\u002fnP1Yytcxtg\u002fY\u002fK39qGnff8D9+agJBL2HsP\u002fbQN8ZlW9k\u002fgkCpf8Bb6j+ptLsK5wvsP5pGNeOFtsM\u002ftWUqR4uZ9D\u002fJL1a4R07dPxsmOP7s2Po\u002f9\u002fHi1+uc8T8Qkm\u002fzXDXgP\u002fkkiO9m4PE\u002fNARnWbI\u002f9D9CXIzhoG\u002fzP4cclPA\u002fCOk\u002fmwkcY8NB9z9uIqCK3OHlPwEOlgkLVPA\u002fgt5RW8en4D9Od7h3wzPsP8nzTek\u002fn\u002fE\u002ftpNAAH5Z3D86jNDEP0oCQAV\u002fhg\u002fYofM\u002f0nwdVtG08j+yyKm6bRf6P9gOuePd8tU\u002fNF099GkO\u002fz\u002fD2pFQnVv4P9k4\u002f4w7fvo\u002fhBiW3epb1b9rdeEAwcrnPw=="},"y":{"dtype":"f8","bdata":"s9Hi38Qo\u002fb991lBwcu4BwDQRN\u002fVHggbAeHFKWdZVBMBIJnpzi2zCv8R0grKmyQLAKwPa2VZ07r\u002fq7qmDAiILwKIUI9CxVwrABIe67rsUBMA\u002fkoOZeX4MwO7WsIDf\u002fATATvkeOCZuA8BIp7Hyn7AEwBeqJ6RpSgnAFc5qPuMzB8DmcZHYY5zcvyK+V0fv09U\u002fddLihrKiBcDErhGuV44IwOps2Vqg3wXAxF2EcohbB8Cwf7pCoD2pP+OpoxCkvQrAhxDndDZjBsDzaTTuiXXEv9NIXkoWtgPAHbDfsE4dBcCJCt7S17YFwJvPekdUCwnAsUGOwBORCMBwf2RZEi4GwAkE6PWqaQTAhLsHeD1ryT8x7BDAaqIHwACA4SLX8PS\u002fNfoYYk1nB8A0Bp2J3BIGwLvxIgPrQwPAHlJEOW5tBMDuSbDHhvsDwEvfb7372QbAj7fmdUHoBsB+76Eaw5AIwOEz8cwAJwTADwHVBPE4\u002fb+pty+WqqsIwGCHTtxc3wfArPOb5D3rBsBGwZVbgMQHwA4fsGJ8uQXA0AeaatYVBcCUnTCIXXD5v5v2SwZboAPAGKAfU+dBDcA8QA\u002f+BXgJwNQt146SaAvAWbcTvsVV\u002fL8jw8LbrCoBwP56F2P61gjAgh9CU4uXv7+YvZi8gAcFwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2025"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism (1)","showlegend":false,"x":{"dtype":"f8","bdata":"kXEA7ycE4D8="},"y":{"dtype":"f8","bdata":"FAOXhOzc8L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2025","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2025","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2025","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2025","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2025","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2025","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social (18)","showlegend":false,"x":{"dtype":"f8","bdata":"AIBbg39lAkBPX1iWMIUBQIOu6ZdqHAJAKA2bp23VA0CdCTzh6nADQPm60q+FGwVAE9Uey4eyAkC8T5RBzAUGQOwVrRuxugJAjyVcWNeK4D+7wduXLoHrPxlJ+gUDRwNAyYKg9OtY\u002fj8gC\u002f2tFjoAQAgxScUnPwFA7j\u002fMwPWgAEA++ECpQ7ACQDfGcpWoV\u002fw\u002f"},"y":{"dtype":"f8","bdata":"NqRd9CWCAsAHQP4Jf7D+v1Dek8Kbi\u002f6\u002fbo\u002fJFrWC+L9MdaLGQV4FwHCzuphI5ty\u002fDTj07XmkAcAlavYNlu\u002fYv7XdFKDU\u002feA\u002fAFJyDZ0JBcB\u002fuEeATAXsv\u002fulVMy9fKG\u002fEpvcEYRs97+GIUxlQzT9v1rqHqT\u002fmfi\u002fa7Z619X8sr9vMPU\u002fodP8v\u002fGNUBOn18K\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2025","Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2025","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2025","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2025","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2025","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2025"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity (6)","showlegend":false,"x":{"dtype":"f8","bdata":"6rsVt2PUAED4xKVzBw0BQGaEgbXKTAVAQ1r4W9VEBkDD2pFQnVv4P2ZtQoV3EgNA"},"y":{"dtype":"f8","bdata":"xHSCsqbJAsDNXrsncZXyvwNNrIcd+Pq\u002fqejQmJhV+L8jw8LbrCoBwGIH8G0fMPS\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2025","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2025","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value (15)","showlegend":false,"x":{"dtype":"f8","bdata":"ujPYtG\u002fNB0C8xck9hMAGQFETE2bzOQpARwZ1U9kdCECNKG+j4ToLQFO18OUrxAVAmwkcY8NB9z9IubxMvLcCQOhpbxaIy4Q\u002fQecNf6BODEA8DkGDz5AHQDqM0MQ\u002fSgJAK1CArz\u002f+B0A0XT30aQ7\u002fP3WWGiHO8AdA"},"y":{"dtype":"f8","bdata":"yozrR+1F5r9Lv1qncSnmvx7knBwX5ea\u002fJT5aPPJz3b+UCFwPsVXZv8gtw3thNO2\u002fDwHVBPE4\u002fb89o82+eub0v19Iq\u002fBS8u2\u002f9IvMg7Mozr8IA3DfE+3tv5SdMIhdcPm\u002f\u002f\u002fapLdSu779ZtxO+xVX8v5lArAbzMOe\u002f"},"type":"scatter"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scattermap":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermap"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"font":{"size":16},"text":"Multi-label Clusters (All Years)"},"xaxis":{"range":[-4.5,4.5],"title":{"text":""},"showgrid":true,"gridcolor":"lightgray"},"yaxis":{"range":[-4.5,4.5],"title":{"text":""},"showgrid":true,"gridcolor":"lightgray","scaleanchor":"x","scaleratio":1},"height":800,"width":1000,"hovermode":"closest"},                        {"responsive": true}                    )                };            </script>        </div>
</body>
</html>