<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8" />   <!--It is necessary to use the UTF-8 encoding with plotly graphics to get e.g. negative signs to render correctly -->
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Visualisation of Alignment Survey</title>
</head>

<body>
<h1>Papers from each year (2022-2025)</h1>
<div>                            <div id="703941c1-df29-47a6-b909-4307fda5ec0a" class="plotly-graph-div" style="height:700px; width:900px;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("703941c1-df29-47a6-b909-4307fda5ec0a")) {                    Plotly.newPlot(                        "703941c1-df29-47a6-b909-4307fda5ec0a",                        [{"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"bias","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"cultural","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"culture","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"demographics","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"diversity","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"ethical","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"factuality","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"faithfulness","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"general","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"hate","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"humor","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"language","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"legal","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"length","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"moral","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"multilingual","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"offensiveness","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"opinions","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"personalization","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"political","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"safety","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"sexism","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"social","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"toxicity","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"value","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2022"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity","showlegend":false,"visible":true,"x":{"dtype":"f8","bdata":"5bAHxYPqAEA="},"y":{"dtype":"f8","bdata":"QpZF05wIB0A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general","showlegend":false,"visible":true,"x":{"dtype":"f8","bdata":"CPQDYqQq87+o\u002fjd2lDn7v+qoXf\u002fonvC\u002feY\u002fTwPOc8L8="},"y":{"dtype":"f8","bdata":"kiNLwu2UC0DSZBU\u002fTbcFQGpoJpkKQwlAp3lOV9T5A0A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral","showlegend":false,"visible":true,"x":{"dtype":"f8","bdata":"3zdB3EGXBcA="},"y":{"dtype":"f8","bdata":"doAO\u002fuaC9b8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization","showlegend":false,"visible":true,"x":{"dtype":"f8","bdata":"JTBavkhn3r8="},"y":{"dtype":"f8","bdata":"pI0hPZm1B8A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"lekG+6wlBkA="},"y":{"dtype":"f8","bdata":"yIGHi7Xp3z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2023"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"70jOcXSE8z8="},"y":{"dtype":"f8","bdata":"oqlSvu1hCEA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"jkVfVeOS478="},"y":{"dtype":"f8","bdata":"jtcEPVPbDEA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"NLZ9f2y38b9+hbumeDr1vzX+eO\u002fsrvO\u002fqmU7K2m047\u002faM66niKDvv04JI8WL+vC\u002f72FZ5\u002fEc8r8gPKBaL4PzvxZS9yLD7fS\u002fc3LqrEq09r+iYS95tI71vw=="},"y":{"dtype":"f8","bdata":"5C321DL2BECI\u002fYIxjJ4IQIjRPpH5AwNA2zVeqDwMB0BYzcLXmlUEQJC2MXjKwQZA3XDs0EXmBEBcqNKm1DEFQMYx\u002fP1JZAlAvKV\u002few38BkBWGb1BYE4GQA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"7r3WgrbJBMA="},"y":{"dtype":"f8","bdata":"GI715LuQ5b8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"iJt1Vxif478="},"y":{"dtype":"f8","bdata":"Uecb0kmZBcA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"sR7q0xelBkDqiVO4GBnlP20X\u002fDmVrP0\u002fPBo\u002fdjTv9T\u002fnP2D1YQkBQGFdvERaSOs\u002fwtFPHX06BUANrNtwmtMCQFg1BMHNO\u002fc\u002fuBjW482c+z+53bwvQdL7P+ASmZZKqwFAlrqGP+9q8T8N93jQRT8GQFKzC9tFEgJA8AIUK\u002fxnsr+Ava914T3kP7bdLJdxswdA"},"y":{"dtype":"f8","bdata":"yxQd5lvo1L\u002fMANem1Y\u002fZv1PAQae6j\u002fa\u002fGa7jVejG2L8IHwXJq8O7vwD7kaZiC1S\u002fApkZ\u002fnKUjb+\u002fTGv2cy62vyVg4\u002fJhmco\u002fq83xgVux9798X5R9Phb8v31zSYc9xek\u002fW5sx2AvbwT\u002fkPqoCy5rQPz0V\u002fLmpivo\u002fFt7aeRqR+7\u002fmHfx2nKvtv49yplGu1+w\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2024","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2024"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"5zMIYs\u002fTAkDrWQHL8pgHQIbF8SQ\u002f6AxAsR7q0xelBkDqiVO4GBnlP9i72JGhcPQ\u002fWyaXpyZUA0BhXbxEWkjrPw33eNBFPwZA1HUckhhr2T8YxRRvZneHP\u002fBqp4IU5+I\u002f+Amld5f5BkCN8VT1fOgJQLg9iB4awpM\u002f"},"y":{"dtype":"f8","bdata":"dIHjogBfzj\u002fC++XVvJDvP+JoKjGV4vI\u002fyxQd5lvo1L\u002fMANem1Y\u002fZv5nhZ8suy\u002fK\u002foEzvh3DD678A+5GmYgtUv+Q+qgLLmtA\u002fVrTqhU1h8b\u002f0tPwo4zbWv4U6EPFkfO0\u002fzusB0Yss5T+pcnrC5oHmP55pODuXTuk\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2024","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"Mk0YyRqZAkA8Gj92NO\u002f1P+c\u002fYPVhCQFAwtFPHX06BUANrNtwmtMCQFg1BMHNO\u002fc\u002feu7sHEfb\u002fz\u002fgEpmWSqsBQLbdLJdxswdA"},"y":{"dtype":"f8","bdata":"uRQYyVFDAUAZruNV6MbYvwgfBcmrw7u\u002fApkZ\u002fnKUjb+\u002fTGv2cy62vyVg4\u002fJhmco\u002fLbNBpCBLBEB9c0mHPcXpP49yplGu1+w\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2024","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2024","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2024","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"zPHVxBdB8j\u002f\u002f325OtLv7P0CKOekiMdQ\u002feu7sHEfb\u002fz9SswvbRRICQPBqp4IU5+I\u002f"},"y":{"dtype":"f8","bdata":"\u002fJbvF1KsBEDcC+G1R5HNv3yosWf\u002frr+\u002fLbNBpCBLBEA9Ffy5qYr6P4U6EPFkfO0\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"x6QtP4Pi6T\u002fTr75Zwc\u002fqPw=="},"y":{"dtype":"f8","bdata":"VPH4CzGe6r8ZOHPFKIkIQA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"nNerP67f3D+sOUwTEHvCv6Qmdy7hiOw\u002foNLjgp+6wT\u002fX\u002ffkqZirMP1MrJwyl9cM\u002f8F2Z97t23j8aKciOcx3OPwpyhkJor8g\u002flrqGP+9q8T9wihg8yqXGP261ihJPG90\u002fQoFHQ\u002fQZ7T+sCFxvODrmPz\u002fXdaisQ+E\u002f"},"y":{"dtype":"f8","bdata":"5EDsIjYBBEBGguezHQUJQOCtPb1HJ7e\u002fBqbQpc1GCEDpCJwAaigHQHTGh2RPpQdAOCjV+ENoDUBgO3CZS4t7P3tGIHvISgVAW5sx2AvbwT+bK4yvMhMGQALEWtPuoQtAGVHIOYRwCkBvF+cJ+VgIQCvVzfIxeAdA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2024","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"4hmCa9jT9b\u002fjM0j3BvX2vxgZgHIS3Pq\u002fOZRIM4uu8b+boM8c+GDyv\u002fAZ31vpSvG\u002fkRNyymIE9b9Tt3Denyf0v7CPK5zO5Pa\u002fVx4gkXoX67++Nap0dcDzv40TUY8URfe\u002fEtJ8v6n39b+bAWLWGif5vznZvFJgZvK\u002frkGpZ+mn9L8zltzzdiP3v6fxUFxPoO2\u002f+ICgBzcw\u002fr8RfbKYIhfuvwA+v+fnsPK\u002fIi+1sz6ArL\u002fNgMl4HW\u002f6vw=="},"y":{"dtype":"f8","bdata":"\u002f7SyTEIACEApo617tpEDQONg+so3gwVAs\u002fdtMOYfCkD2I41\u002fPGoHQPfUbNlP7QRAl4MBezYLBUAGXRSwnD4HQLFJwCWoaghAMRWts7oYB0BGgUOqwjsDQM\u002fAkm+r0ARA3MmX2p2hBUCQjQxwCOQFQPVctjvo+QJA3UkVLE6DA0CfHRcPgL0HQAlce1Ji4ARAy3SVEidgBUDaxddV0SYGQLcTp043wgdAFFB54ZaSzz8VRb3zed4HQA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2024"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"o2HJU3Ci3L8="},"y":{"dtype":"f8","bdata":"hhMnrMXhu78="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2024"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"hEsMsAk+B8A="},"y":{"dtype":"f8","bdata":"YK0mAt+e\u002fj8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2024"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"uD2IHhrCkz8="},"y":{"dtype":"f8","bdata":"nmk4O5dO6T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"lP+7vtkFB8DqiVO4GBnlP2FdvERaSOs\u002fGMUUb2Z3hz\u002fwAhQr\u002fGeyv\u002fBqp4IU5+I\u002fgL2vdeE95D+F31AoJC0GwNXFTYZdwAnA"},"y":{"dtype":"f8","bdata":"OkjXwOMr87\u002fMANem1Y\u002fZvwD7kaZiC1S\u002f9LT8KOM21r8W3tp5GpH7v4U6EPFkfO0\u002f5h38dpyr7b\u002fl865\u002fXRvwv0AX9TVPBOm\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"pMU6jo5xAcDUdRySGGvZP5B2vvLQYATA"},"y":{"dtype":"f8","bdata":"UfIWiLg4\u002fb9WtOqFTWHxv7D75u0Puve\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2024"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"q6K4gaNi+r8="},"y":{"dtype":"f8","bdata":"UVAfaaRTAsA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"PBo\u002fdjTv9T\u002fgt3UiJpStv1g1BMHNO\u002fc\u002f"},"y":{"dtype":"f8","bdata":"Ga7jVejG2L\u002fYp+Mlj2X\u002fvyVg4\u002fJhmco\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2024","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"mqNwD2GIxL\u002fYu9iRoXD0P02ZO7Q1wui\u002f4\u002f1pAwW+4r9AijnpIjHUP8ekLT+D4uk\u002f5paXSk+o5b9UrUeuhHPWvygq3Qc+e96\u002f"},"y":{"dtype":"f8","bdata":"1uTuAxpiBcCZ4WfLLsvyv5riK7FjEQfAb2pNd4YsB8B8qLFn\u002f66\u002fv1Tx+Asxnuq\u002f75iPSuqWA8CoJZ5nz+gIwImmLaXY0AXA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2024"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"bRf8OZWs\u002fT+4GNbjzZz7P7ndvC9B0vs\u002flrqGP+9q8T\u002fwAhQr\u002fGeyv7gT6Vyaw5o\u002f"},"y":{"dtype":"f8","bdata":"U8BBp7qP9r+rzfGBW7H3v3xflH0+Fvy\u002fW5sx2AvbwT8W3tp5GpH7v9l3CwRCEwnA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2024","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2024","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2024","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2024","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"m66zrxL56z9WLCqGWAn5P+XBZuCbM\u002fk\u002fc9lQfuju8z\u002fMoa1uh0fqP6pZzklXMdQ\u002f+OjwitsP4D+jYclTcKLcv6Qmdy7hiOw\u002ffK1N7YK86D8yBM8d8RT0P5pjhQSkAvQ\u002fE6pJdGnD7D\u002f\u002f325OtLv7P\u002fHzGdz8B+g\u002fQCayFvkZ4D\u002fnP2D1YQkBQNk7UcxQePA\u002fs+CucAf04z8\u002fSoVBpRDzP6I+pKbOgOc\u002fKd1cBOLc8T9SBAd18JPiP2D5QxjFQ\u002fM\u002fGinIjnMdzj88ED5T+QTzP9R1HJIYa9k\u002fg0YFjc7p3j\u002fgWyx0xOL2PwDdIWA54Nc\u002fiuVYWLuU8z+IRexUbd4AQMhlSYL9Jf4\u002fv5Hzz59Y5j8iL7WzPoCsv5NnSkxmxN8\u002f"},"y":{"dtype":"f8","bdata":"Kjj3BEzvCcDAvbg5GOkIwLDykrgnqgjAlJEsx5aTCMD0mGhoYgUIwOxgD2UCNgrAcXoGpOfMCcCGEyesxeG7v+CtPb1HJ7e\u002fG+ZyXdcQBsCN0oktpSwJwNc\u002feziKWQXArRzsJgWEB8DcC+G1R5HNv7sU2UImCQbAua5fOdLsB8AIHwXJq8O7v3M9pNd\u002ftQbA6vt3Sz0ECMAgEPQIVoYDwMJk6nW0AAvAmX4palv6BMB3tx7JKBwGwCAPISxq\u002fgTAYDtwmUuLez++UXnFPOQGwFa06oVNYfG\u002fA9OkM7GPBcDG+G7\u002fSswKwK8FThbvmwjAt4SUeE+TB8CFOTKiUG73v7ycY73Clfy\u002f178bj3z1B8AUUHnhlpLPP8qTFmK\u002fTwXA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"gL2vdeE95D8="},"y":{"dtype":"f8","bdata":"5h38dpyr7b8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"sR7q0xelBkC0Tt2B7gcCQFsml6cmVANAwtFPHX06BUDgt3UiJpStv8ekLT+D4uk\u002fDazbcJrTAkC4GNbjzZz7Pw=="},"y":{"dtype":"f8","bdata":"yxQd5lvo1L9rJBqoAdcBwKBM74dww+u\u002fApkZ\u002fnKUjb\u002fYp+Mlj2X\u002fv1Tx+Asxnuq\u002fv0xr9nMutr+rzfGBW7H3vw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2024","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"egc5CMudBUBdCN6bEo8CQIleDLwdDgVAyGVJgv0l\u002fj81eG843tsEQA=="},"y":{"dtype":"f8","bdata":"IR3azLKQ+L+uQI1RMWbyv77uA\u002f28tfS\u002fvJxjvcKV\u002fL81bsXcnd71vw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2024","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"iEXsVG3eAEBbovjTrIgGQA=="},"y":{"dtype":"f8","bdata":"hTkyolBu97\u002fD7DX7kdPyvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"8hCaJ2WQB0A="},"y":{"dtype":"f8","bdata":"\u002fkFWUZcT5z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2025","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2025","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"Fcuj+J3n0z8yQ1CRSg3aP8oCTKdVzQhA3qfk3Jfa+T\u002fyEJonZZAHQGPDTxgw7AhAi6v2DxCxBkAq7HpvM0oKQAYiYl9pSQtAAYMeD3kzC0Au1TpzFWwHQF0tYpdutwZAYNkYN5jP+z9RuXH96ynyPw=="},"y":{"dtype":"f8","bdata":"2LOO7d1wzr+ihJ3eavjbv1sx+9NWQO4\u002fsVOnISwA87\u002f+QVZRlxPnP0\u002fT4UlNnuQ\u002fb+OaTTJ55D\u002f44tej4VXuP4xsA8FreN4\u002f6r74\u002fIl33j8qeHvJJBnjP+R65BTdNuY\u002foxHq5vME\u002fj\u002fsUh5gi3nNvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"hB6DXHK7B0BivzRIxoAGQGHbLUF7jwFA"},"y":{"dtype":"f8","bdata":"nl0Ov9tg6j\u002fvwWSvAxsBQJhXCHuKYvo\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2025","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2025"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"OLm3kior1z9DAqaQZeICQMMyr0suPvw\u002fhya9pXctA0BhkJptiOwBQA=="},"y":{"dtype":"f8","bdata":"YSIr4hbj3r9md7oCx4kAQMXLtC86yQFAEvzdgIPR+T\u002fV6AAs\u002f9y8Pw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2025"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"ulYgTEet7j8+L42Jrr7TPw=="},"y":{"dtype":"f8","bdata":"lZ4otxkttL8obz7SD4Klvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"0AdLiHG79T\u002fYpsivs5DlP6B1bY5NHfY\u002fUblx\u002fesp8j8="},"y":{"dtype":"f8","bdata":"LGjTEsuACEDAabtzbk8GQI954RIhJgRA7FIeYIt5zb8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2025"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"5nQ9BTPz4D9svJ8eVZzJP26Ed4h1wcy\u002fICYLHQbqyb9g2Rg3mM\u002f7Pw=="},"y":{"dtype":"f8","bdata":"RPyP2F8ZBUCuu9\u002f7LWUFQLd0qXCiJwlA4wt2urb\u002fB0CjEerm8wT+Pw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2025"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"Rqr5FIP92r8="},"y":{"dtype":"f8","bdata":"XlgBf3e1C0A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2025","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"DZ4S9YsY7L9cuBLLEVH1v6jwzMZ3oPO\u002fyQzqcPWB979y0FGPirf1v3kA2zQaYPS\u002f3DR4RbMP8L\u002fcac5U6mzzvxypHB6rsPO\u002fs17fiw7P9L+9iA5rUaXyvwntpGfKhwPA3\u002fjDLYdvAMBItckDIPr+vzhdDIAFYALA2Mapv+F5\u002fr9a4pRoQvTwvzRBtEWhAe+\u002fM1L+LDsS9r\u002fbT2zjjUTkv3MTTl+T6vS\u002fnpHmNOOq0r9jogDj+DzyvyQqwYNw\u002f\u002fW\u002fMmO7DcEi8r\u002fE8iHNnkX0v8wPWsy74fu\u002fM\u002f5JYwh++L\u002fwh47dqwryvxkwGrD8Fvu\u002fbtMzbDYt\u002fL8="},"y":{"dtype":"f8","bdata":"L+pLnwvMBUA6i6Heu80CQMLWAebijgVALmmI\u002fFQOB0CWWiJ98vgEQNBYVg5CFwNAVKUzoCDeBkBqT7hYOzYMQPAR+OZXaQVA\u002fkzXlbvIBkDQRUTnvjIHQJy0mrFN0\u002fE\u002fkyyi1A6IBUCkbt8rjD4HQDeIC8xRPglAtoIwtQcmBkCnnij2LqMCQLDH0ijnogdApGl+5ymtCUDPEBBWgFYFQJzQJ1yzuQZAfZZjR0X+A0CHBI+zguEEQDAcWMed7gZAnyOxpo\u002fTB0DSqPPevIYFQJ8sMwmq3wRA2akPM5sJBEAaQVjApL0HQFu4+WaPHAZADgZwd\u002fCUBkA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"jGM6nsJBAcCgighRwxoKwCT0+AY2LAXA"},"y":{"dtype":"f8","bdata":"GolYHMrl9T9Pr6Mw9RfxP3h8SfyHq9w\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2025"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"StfVHf+oCcA="},"y":{"dtype":"f8","bdata":"sXwh7Nx60L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2025"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"Ce2kZ8qHA8A="},"y":{"dtype":"f8","bdata":"nLSasU3T8T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2025","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2025"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"mCwsrc9dBcDjibY2SK\u002ftv82kZkHSBwjAFcuj+J3n0z9GvpeR5KIIwH89f6V2cQLAnw9RI+5tBsCoI59ZgBUGwEC8QrNqzJS\u002f"},"y":{"dtype":"f8","bdata":"3DI2BAwf6r+ujaZoVbn8vwSWCLf1Yvi\u002f2LOO7d1wzr9uIUy2QrLdv2b\u002ffhXaG\u002fe\u002fNiNv0DSB9L+\u002fLCBGElzsvwi0WbTeCvO\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2025","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2025","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2025"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"doddQUti5L8gC3LmZen\u002fvzJDUJFKDdo\u002f"},"y":{"dtype":"f8","bdata":"tZj4CmuUA8BZjGodmlL8v6KEnd5q+Nu\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2025"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"OLm3kior1z8="},"y":{"dtype":"f8","bdata":"YSIr4hbj3r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2025","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2025","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"joj7ibStzT8+L42Jrr7TP2vP2aETl+S\u002f2D59fTye5r8AuRcoYgSbv8CW7cPXSey\u002fjuptnjeZ7r\u002fG2RJ4jSLCv8C5\u002frOaMsK\u002fBPw0MUhX6r+0Zxxxl9u3v6obay4BV+e\u002fHYVuPG398r+ik7ytpsDEvwgtL2RFd7a\u002fkI6NzSiX6r8S9zaCrc\u002fjv7tnfs1jw9+\u002fwygtTavo2L9RuXH96ynyPw=="},"y":{"dtype":"f8","bdata":"+7VgZkj3B8Aobz7SD4Klvyd2e9jYLAjAVmmW2cHpAsAOoX29Fu0GwGJKwQN9xQXAWXiAq+zSB8AvAmoY5Q8LwAn15w6J7AXAhuVuv+kjB8As6c627RAGwJGvS0nV3wbAhUjZRnUmCMA\u002f2HJm78wHwNQI8LRLOwnAZ5ZYihQRBcBAo3V9LiwIwLX2A6XCLQTAvCcLmaW7B8DsUh5gi3nNvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2025","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2025","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2025","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2025","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2025","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"44m2Nkiv7b92h11BS2Lkv46I+4m0rc0\u002fD82\u002fnPUT7z+6ViBMR63uPyOQW77hVPw\u002f3qfk3Jfa+T+AJbeP6CPjP3tGu+HnE+E\u002fYgGuK1aX8T8z2kxCDzj2P2xGMLCPwe4\u002f4eMyh2Qb6j8ola9EIbTpP+WMfZaoJ+4\u002fy\u002fQDCqpB6j\u002f0sD2CwGL9P2rL1DjIDvA\u002fEr\u002fqjX8q5z9tWApOeGHnP9OPZ3M8eeY\u002fSyJmSb1H8j9gP0i4D3brP8wtI1ek+\u002fw\u002feB8oit517z9zzrjRxj3tPw=="},"y":{"dtype":"f8","bdata":"ro2maFW5\u002fL+1mPgKa5QDwPu1YGZI9wfAybloGP58BMCVnii3GS20vzicsGMWvf2\u002fsVOnISwA878W+YqufDgHwFoebKGedAjAONc2zITOA8DkaeoJ6fwFwPrcUSewOwrAAkyw5WveBcAFRWPc1OEGwCpq0BScbQnAuQ+chZ5rBsDbtrV9Nyj8v3P\u002ft\u002ffhJQXA3mjw2\u002fhdBcCUzqNspJMJwCldAXUEtALAKcH0SaKWC8AhfSxzlIsFwDrz6AUqdv2\u002f51QerL9FCcBDUI2\u002firMGwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2025","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"jqU6zNfHAEAKRPvCGuX+P\u002fcJk537qQRAmauuMhOGAEAEa5dPuuYAQF6qRMGyXwJABcrf2l1oA0BhkJptiOwBQDxzdLlNegBAUblx\u002fesp8j8="},"y":{"dtype":"f8","bdata":"8lY37WW++79B1Mqhma8AwAxmAtpNB\u002fy\u002fa8l5mRuzAMDlTqCtIIkDwEnzg7mLqALAOeMKrDkIAsDV6AAs\u002f9y8P31IBMDlkQPA7FIeYIt5zb8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2025"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"I5BbvuFU\u002fD8="},"y":{"dtype":"f8","bdata":"OJywYxa9\u002fb8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2025","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"cZ5kU3jkA0CZjS7V54gHQB3z5oOajAZAWSAJCCcYCED6wqaaOicKQKkec38cvglA9LA9gsBi\u002fT8SGyw9eVEDQEC8QrNqzJS\u002fhFU+l6hRC0DEcpvotS0IQMwtI1ek+\u002fw\u002fucCzdCmJDUA="},"y":{"dtype":"f8","bdata":"Rz5zJrZ57L\u002fwyaBZWPbpv2rHWiafS\u002fC\u002fBQeu425057+CpveH2aTZv4TyCTmClu6\u002f27a1fTco\u002fL9MTquV1\u002fnwvwi0WbTeCvO\u002fk2u9v4oh3b8cWSMtS1Tpvzrz6AUqdv2\u002fYN+Tz\u002f7Y5L8="},"type":"scatter"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scattermap":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermap"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"font":{"size":16},"text":"Multi-label Clusters for each Year"},"xaxis":{"range":[-4.5,4.5],"title":{"text":""},"showgrid":true,"gridcolor":"lightgray"},"yaxis":{"range":[-4.5,4.5],"title":{"text":""},"showgrid":true,"gridcolor":"lightgray","scaleanchor":"x","scaleratio":1},"height":700,"width":900,"hovermode":"closest","sliders":[{"active":0,"currentvalue":{"prefix":"Year: ","visible":true,"xanchor":"center"},"len":0.9,"pad":{"b":10,"t":50},"steps":[{"args":[{"visible":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false]}],"label":"2022","method":"update"},{"args":[{"visible":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false]}],"label":"2023","method":"update"},{"args":[{"visible":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false]}],"label":"2024","method":"update"},{"args":[{"visible":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true]}],"label":"2025","method":"update"}],"x":0.0,"xanchor":"left","y":-0.1,"yanchor":"top"}],"showlegend":true},                        {"responsive": true}                    )                };            </script>        </div>
<br>
<br>
<h2>All papers</h2>
<div>                        <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.3.1.min.js" integrity="sha256-4rD3fugVb/nVJYUv5Ky3v+fYXoouHaBSP20WIJuEiWg=" crossorigin="anonymous"></script>                <div id="716413ca-57de-470c-8a9e-6fdd52b5ecdc" class="plotly-graph-div" style="height:800px; width:1000px;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("716413ca-57de-470c-8a9e-6fdd52b5ecdc")) {                    Plotly.newPlot(                        "716413ca-57de-470c-8a9e-6fdd52b5ecdc",                        [{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2022","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2022","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2022","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2022","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2022","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2022","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2022","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2022","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2022","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2022","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2022","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2022","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2022"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias (19)","showlegend":true,"x":{"dtype":"f8","bdata":"8hCaJ2WQB0CxHurTF6UGQOqJU7gYGeU\u002fbRf8OZWs\u002fT88Gj92NO\u002f1P+c\u002fYPVhCQFAYV28RFpI6z\u002fC0U8dfToFQA2s23Ca0wJAWDUEwc079z+4GNbjzZz7P7ndvC9B0vs\u002f4BKZlkqrAUCWuoY\u002f72rxPw33eNBFPwZAUrML20USAkDwAhQr\u002fGeyv4C9r3XhPeQ\u002ftt0sl3GzB0A="},"y":{"dtype":"f8","bdata":"\u002fkFWUZcT5z\u002fLFB3mW+jUv8wA16bVj9m\u002fU8BBp7qP9r8ZruNV6MbYvwgfBcmrw7u\u002fAPuRpmILVL8CmRn+cpSNv79Ma\u002fZzLra\u002fJWDj8mGZyj+rzfGBW7H3v3xflH0+Fvy\u002ffXNJhz3F6T9bmzHYC9vBP+Q+qgLLmtA\u002fPRX8uamK+j8W3tp5GpH7v+Yd\u002fHacq+2\u002fj3KmUa7X7D8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2022","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2022","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2022","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2022","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2022","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2022","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2022","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2022","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2022","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2022","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2022","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2022","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2022","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2022"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural (30)","showlegend":true,"x":{"dtype":"f8","bdata":"Fcuj+J3n0z8yQ1CRSg3aP8oCTKdVzQhA3qfk3Jfa+T\u002fyEJonZZAHQGPDTxgw7AhAi6v2DxCxBkAq7HpvM0oKQOczCGLP0wJA61kBy\u002fKYB0CGxfEkP+gMQJXpBvusJQZAsR7q0xelBkDqiVO4GBnlP9i72JGhcPQ\u002fWyaXpyZUA0BhXbxEWkjrPw33eNBFPwZA1HUckhhr2T8YxRRvZneHP\u002fBqp4IU5+I\u002fBiJiX2lJC0ABgx4PeTMLQC7VOnMVbAdAXS1il263BkBg2Rg3mM\u002f7P1G5cf3rKfI\u002f+Amld5f5BkCN8VT1fOgJQLg9iB4awpM\u002f"},"y":{"dtype":"f8","bdata":"2LOO7d1wzr+ihJ3eavjbv1sx+9NWQO4\u002fsVOnISwA87\u002f+QVZRlxPnP0\u002fT4UlNnuQ\u002fb+OaTTJ55D\u002f44tej4VXuP3SB46IAX84\u002fwvvl1byQ7z\u002fiaCoxleLyP8iBh4u16d8\u002fyxQd5lvo1L\u002fMANem1Y\u002fZv5nhZ8suy\u002fK\u002foEzvh3DD678A+5GmYgtUv+Q+qgLLmtA\u002fVrTqhU1h8b\u002f0tPwo4zbWv4U6EPFkfO0\u002fjGwDwWt43j\u002fqvvj8iXfePyp4e8kkGeM\u002f5HrkFN025j+jEerm8wT+P+xSHmCLec2\u002fzusB0Yss5T+pcnrC5oHmP55pODuXTuk\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2022","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2022","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2022"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture (3)","showlegend":true,"x":{"dtype":"f8","bdata":"hB6DXHK7B0BivzRIxoAGQGHbLUF7jwFA"},"y":{"dtype":"f8","bdata":"nl0Ov9tg6j\u002fvwWSvAxsBQJhXCHuKYvo\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2022","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2022","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2022","Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2022","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2022","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2022","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2022","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2022","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2022","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2022"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics (14)","showlegend":true,"x":{"dtype":"f8","bdata":"OLm3kior1z9DAqaQZeICQMMyr0suPvw\u002fMk0YyRqZAkA8Gj92NO\u002f1P+c\u002fYPVhCQFAwtFPHX06BUANrNtwmtMCQFg1BMHNO\u002fc\u002feu7sHEfb\u002fz\u002fgEpmWSqsBQLbdLJdxswdAhya9pXctA0BhkJptiOwBQA=="},"y":{"dtype":"f8","bdata":"YSIr4hbj3r9md7oCx4kAQMXLtC86yQFAuRQYyVFDAUAZruNV6MbYvwgfBcmrw7u\u002fApkZ\u002fnKUjb+\u002fTGv2cy62vyVg4\u002fJhmco\u002fLbNBpCBLBEB9c0mHPcXpP49yplGu1+w\u002fEvzdgIPR+T\u002fV6AAs\u002f9y8Pw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2022","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2022","Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2022","Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2022","Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2022","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2022","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2022","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2022","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2022","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2022"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity (10)","showlegend":true,"x":{"dtype":"f8","bdata":"ulYgTEet7j8+L42Jrr7TP8zx1cQXQfI\u002f70jOcXSE8z\u002flsAfFg+oAQP\u002ffbk60u\u002fs\u002fQIo56SIx1D967uwcR9v\u002fP1KzC9tFEgJA8GqnghTn4j8="},"y":{"dtype":"f8","bdata":"lZ4otxkttL8obz7SD4Klv\u002fyW7xdSrARAoqlSvu1hCEBClkXTnAgHQNwL4bVHkc2\u002ffKixZ\u002f+uv78ts0GkIEsEQD0V\u002fLmpivo\u002fhToQ8WR87T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2022","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2022","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2022","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2022","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2022","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2022"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical (6)","showlegend":true,"x":{"dtype":"f8","bdata":"0AdLiHG79T\u002fYpsivs5DlP6B1bY5NHfY\u002fx6QtP4Pi6T9RuXH96ynyP9OvvlnBz+o\u002f"},"y":{"dtype":"f8","bdata":"LGjTEsuACEDAabtzbk8GQI954RIhJgRAVPH4CzGe6r\u002fsUh5gi3nNvxk4c8UoiQhA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2022","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2022","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2022","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2022","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality (21)","showlegend":true,"x":{"dtype":"f8","bdata":"5nQ9BTPz4D9svJ8eVZzJP45FX1XjkuO\u002fnNerP67f3D+sOUwTEHvCv6Qmdy7hiOw\u002foNLjgp+6wT\u002fX\u002ffkqZirMP1MrJwyl9cM\u002f8F2Z97t23j8aKciOcx3OPwpyhkJor8g\u002flrqGP+9q8T9wihg8yqXGP261ihJPG90\u002fQoFHQ\u002fQZ7T+sCFxvODrmP26Ed4h1wcy\u002fICYLHQbqyb9g2Rg3mM\u002f7Pz\u002fXdaisQ+E\u002f"},"y":{"dtype":"f8","bdata":"RPyP2F8ZBUCuu9\u002f7LWUFQI7XBD1T2wxA5EDsIjYBBEBGguezHQUJQOCtPb1HJ7e\u002fBqbQpc1GCEDpCJwAaigHQHTGh2RPpQdAOCjV+ENoDUBgO3CZS4t7P3tGIHvISgVAW5sx2AvbwT+bK4yvMhMGQALEWtPuoQtAGVHIOYRwCkBvF+cJ+VgIQLd0qXCiJwlA4wt2urb\u002fB0CjEerm8wT+PyvVzfIxeAdA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2022"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness (1)","showlegend":true,"x":{"dtype":"f8","bdata":"Rqr5FIP92r8="},"y":{"dtype":"f8","bdata":"XlgBf3e1C0A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2022","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2022","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general (69)","showlegend":true,"x":{"dtype":"f8","bdata":"DZ4S9YsY7L9cuBLLEVH1v6jwzMZ3oPO\u002fyQzqcPWB979y0FGPirf1v3kA2zQaYPS\u002f3DR4RbMP8L\u002fcac5U6mzzv+IZgmvY0\u002fW\u002f4zNI9wb19r8YGYByEtz6vzmUSDOLrvG\u002fm6DPHPhg8r\u002fwGd9b6Urxv5ETcspiBPW\u002fU7dw3p8n9L+wjyuczuT2vzS2fX9st\u002fG\u002ffoW7png69b81\u002fnjv7K7zv6plOytptOO\u002f2jOup4ig779OCSPFi\u002frwv+9hWefxHPK\u002fIDygWi+D878WUvciw+30v3Ny6qxKtPa\u002fomEvebSO9b8I9ANipCrzv6j+N3aUOfu\u002f6qhd\u002f+ie8L95j9PA85zwv1ceIJF6F+u\u002fvjWqdHXA87+NE1GPFEX3vxLSfL+p9\u002fW\u002fmwFi1hon+b852bxSYGbyv65BqWfpp\u002fS\u002fM5bc83Yj97+n8VBcT6Dtv\u002fiAoAc3MP6\u002fHKkcHquw87+zXt+LDs\u002f0v72IDmtRpfK\u002fCe2kZ8qHA8Df+MMth28AwEi1yQMg+v6\u002fOF0MgAVgAsDYxqm\u002f4Xn+v1rilGhC9PC\u002fNEG0RaEB778zUv4sOxL2v9tPbOONROS\u002fcxNOX5Pq9L+ekeY046rSv2OiAOP4PPK\u002fJCrBg3D\u002f9b8yY7sNwSLyv8TyIc2eRfS\u002fzA9azLvh+78z\u002fkljCH74v\u002fCHjt2rCvK\u002fGTAasPwW+79u0zNsNi38vxF9spgiF+6\u002fAD6\u002f5+ew8r8iL7WzPoCsv82AyXgdb\u002fq\u002f"},"y":{"dtype":"f8","bdata":"L+pLnwvMBUA6i6Heu80CQMLWAebijgVALmmI\u002fFQOB0CWWiJ98vgEQNBYVg5CFwNAVKUzoCDeBkBqT7hYOzYMQP+0skxCAAhAKaOte7aRA0DjYPrKN4MFQLP3bTDmHwpA9iONfzxqB0D31GzZT+0EQJeDAXs2CwVABl0UsJw+B0CxScAlqGoIQOQt9tQy9gRAiP2CMYyeCECI0T6R+QMDQNs1Xqg8DAdAWM3C15pVBECQtjF4ysEGQN1w7NBF5gRAXKjSptQxBUDGMfz9SWQJQLylf3sN\u002fAZAVhm9QWBOBkCSI0vC7ZQLQNJkFT9NtwVAamgmmQpDCUCneU5X1PkDQDEVrbO6GAdARoFDqsI7A0DPwJJvq9AEQNzJl9qdoQVAkI0McAjkBUD1XLY76PkCQN1JFSxOgwNAnx0XD4C9B0AJXHtSYuAEQMt0lRInYAVA8BH45ldpBUD+TNeVu8gGQNBFROe+MgdAnLSasU3T8T+TLKLUDogFQKRu3yuMPgdAN4gLzFE+CUC2gjC1ByYGQKeeKPYuowJAsMfSKOeiB0CkaX7nKa0JQM8QEFaAVgVAnNAnXLO5BkB9lmNHRf4DQIcEj7OC4QRAMBxYx53uBkCfI7Gmj9MHQNKo8968hgVAnywzCarfBEDZqQ8zmwkEQBpBWMCkvQdAW7j5Zo8cBkAOBnB38JQGQNrF11XRJgZAtxOnTjfCB0AUUHnhlpLPPxVFvfN53gdA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2022"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate (1)","showlegend":true,"x":{"dtype":"f8","bdata":"o2HJU3Ci3L8="},"y":{"dtype":"f8","bdata":"hhMnrMXhu78="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2022"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor (1)","showlegend":true,"x":{"dtype":"f8","bdata":"hEsMsAk+B8A="},"y":{"dtype":"f8","bdata":"YK0mAt+e\u002fj8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2022","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2022","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2022","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2022"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language (4)","showlegend":true,"x":{"dtype":"f8","bdata":"jGM6nsJBAcCgighRwxoKwCT0+AY2LAXAuD2IHhrCkz8="},"y":{"dtype":"f8","bdata":"GolYHMrl9T9Pr6Mw9RfxP3h8SfyHq9w\u002fnmk4O5dO6T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2022"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal (1)","showlegend":true,"x":{"dtype":"f8","bdata":"StfVHf+oCcA="},"y":{"dtype":"f8","bdata":"sXwh7Nx60L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2022"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length (1)","showlegend":true,"x":{"dtype":"f8","bdata":"Ce2kZ8qHA8A="},"y":{"dtype":"f8","bdata":"nLSasU3T8T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2022","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2022","Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2022","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2022","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2022","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2022","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2022","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral (20)","showlegend":true,"x":{"dtype":"f8","bdata":"mCwsrc9dBcDjibY2SK\u002ftv82kZkHSBwjAFcuj+J3n0z+U\u002f7u+2QUHwO691oK2yQTA3zdB3EGXBcDqiVO4GBnlP2FdvERaSOs\u002fGMUUb2Z3hz\u002fwAhQr\u002fGeyv\u002fBqp4IU5+I\u002fgL2vdeE95D9GvpeR5KIIwH89f6V2cQLAnw9RI+5tBsCoI59ZgBUGwEC8QrNqzJS\u002fhd9QKCQtBsDVxU2GXcAJwA=="},"y":{"dtype":"f8","bdata":"3DI2BAwf6r+ujaZoVbn8vwSWCLf1Yvi\u002f2LOO7d1wzr86SNfA4yvzvxiO9eS7kOW\u002fdoAO\u002fuaC9b\u002fMANem1Y\u002fZvwD7kaZiC1S\u002f9LT8KOM21r8W3tp5GpH7v4U6EPFkfO0\u002f5h38dpyr7b9uIUy2QrLdv2b\u002ffhXaG\u002fe\u002fNiNv0DSB9L+\u002fLCBGElzsvwi0WbTeCvO\u002f5fOuf10b8L9AF\u002fU1TwTpvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2022","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2022","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2022","Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2022","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2022","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2022"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual (6)","showlegend":true,"x":{"dtype":"f8","bdata":"doddQUti5L8gC3LmZen\u002fvzJDUJFKDdo\u002fpMU6jo5xAcDUdRySGGvZP5B2vvLQYATA"},"y":{"dtype":"f8","bdata":"tZj4CmuUA8BZjGodmlL8v6KEnd5q+Nu\u002fUfIWiLg4\u002fb9WtOqFTWHxv7D75u0Puve\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2022"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness (1)","showlegend":true,"x":{"dtype":"f8","bdata":"q6K4gaNi+r8="},"y":{"dtype":"f8","bdata":"UVAfaaRTAsA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2022","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2022","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions (4)","showlegend":true,"x":{"dtype":"f8","bdata":"OLm3kior1z88Gj92NO\u002f1P+C3dSImlK2\u002fWDUEwc079z8="},"y":{"dtype":"f8","bdata":"YSIr4hbj3r8ZruNV6MbYv9in4yWPZf+\u002fJWDj8mGZyj8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2022","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2022","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2022","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2022","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2022","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2022","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization (31)","showlegend":true,"x":{"dtype":"f8","bdata":"joj7ibStzT8+L42Jrr7TP2vP2aETl+S\u002fmqNwD2GIxL+Im3VXGJ\u002fjvyUwWr5IZ96\u002f2LvYkaFw9D9NmTu0NcLov+P9aQMFvuK\u002fQIo56SIx1D\u002fHpC0\u002fg+LpP+aWl0pPqOW\u002fVK1HroRz1r\u002fYPn19PJ7mvwC5FyhiBJu\u002fwJbtw9dJ7L+O6m2eN5nuv8bZEniNIsK\u002fwLn+s5oywr8E\u002fDQxSFfqv7RnHHGX27e\u002fqhtrLgFX578dhW48bf3yv6KTvK2mwMS\u002fCC0vZEV3tr+Qjo3NKJfqvxL3NoKtz+O\u002fu2d+zWPD37\u002fDKC1Nq+jYv1G5cf3rKfI\u002fKCrdBz573r8="},"y":{"dtype":"f8","bdata":"+7VgZkj3B8Aobz7SD4Klvyd2e9jYLAjA1uTuAxpiBcBR5xvSSZkFwKSNIT2ZtQfAmeFnyy7L8r+a4iuxYxEHwG9qTXeGLAfAfKixZ\u002f+uv79U8fgLMZ7qv++Yj0rqlgPAqCWeZ8\u002foCMBWaZbZwekCwA6hfb0W7QbAYkrBA33FBcBZeICr7NIHwC8CahjlDwvACfXnDonsBcCG5W6\u002f6SMHwCzpzrbtEAbAka9LSdXfBsCFSNlGdSYIwD\u002fYcmbvzAfA1AjwtEs7CcBnlliKFBEFwECjdX0uLAjAtfYDpcItBMC8JwuZpbsHwOxSHmCLec2\u002fiaYtpdjQBcA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2022","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2022","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2022","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2022","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2022","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2022"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political (6)","showlegend":true,"x":{"dtype":"f8","bdata":"bRf8OZWs\u002fT+4GNbjzZz7P7ndvC9B0vs\u002flrqGP+9q8T\u002fwAhQr\u002fGeyv7gT6Vyaw5o\u002f"},"y":{"dtype":"f8","bdata":"U8BBp7qP9r+rzfGBW7H3v3xflH0+Fvy\u002fW5sx2AvbwT8W3tp5GpH7v9l3CwRCEwnA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2022","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2022","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2022","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2022","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2022","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2022","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2022","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2022","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2022","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2022","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2022","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2022","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2022","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2022","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2022","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2022","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2022","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety (62)","showlegend":true,"x":{"dtype":"f8","bdata":"44m2Nkiv7b92h11BS2Lkv46I+4m0rc0\u002fD82\u002fnPUT7z+6ViBMR63uPyOQW77hVPw\u002f3qfk3Jfa+T+AJbeP6CPjP3tGu+HnE+E\u002fm66zrxL56z9WLCqGWAn5P+XBZuCbM\u002fk\u002fc9lQfuju8z\u002fMoa1uh0fqP6pZzklXMdQ\u002f+OjwitsP4D+jYclTcKLcv6Qmdy7hiOw\u002ffK1N7YK86D8yBM8d8RT0P5pjhQSkAvQ\u002fE6pJdGnD7D\u002f\u002f325OtLv7P\u002fHzGdz8B+g\u002fQCayFvkZ4D\u002fnP2D1YQkBQNk7UcxQePA\u002fs+CucAf04z8\u002fSoVBpRDzP6I+pKbOgOc\u002fKd1cBOLc8T9SBAd18JPiP2D5QxjFQ\u002fM\u002fGinIjnMdzj88ED5T+QTzP9R1HJIYa9k\u002fg0YFjc7p3j\u002fgWyx0xOL2P2IBritWl\u002fE\u002fM9pMQg849j9sRjCwj8HuP+HjModkG+o\u002fKJWvRCG06T\u002fljH2WqCfuP8v0AwqqQeo\u002f9LA9gsBi\u002fT9qy9Q4yA7wPxK\u002f6o1\u002fKuc\u002fbVgKTnhh5z\u002fTj2dzPHnmP0siZkm9R\u002fI\u002fYD9IuA926z\u002fMLSNXpPv8P3gfKIrede8\u002fc8640cY97T8A3SFgOeDXP4rlWFi7lPM\u002fiEXsVG3eAEDIZUmC\u002fSX+P7+R88+fWOY\u002fIi+1sz6ArL+TZ0pMZsTfPw=="},"y":{"dtype":"f8","bdata":"ro2maFW5\u002fL+1mPgKa5QDwPu1YGZI9wfAybloGP58BMCVnii3GS20vzicsGMWvf2\u002fsVOnISwA878W+YqufDgHwFoebKGedAjAKjj3BEzvCcDAvbg5GOkIwLDykrgnqgjAlJEsx5aTCMD0mGhoYgUIwOxgD2UCNgrAcXoGpOfMCcCGEyesxeG7v+CtPb1HJ7e\u002fG+ZyXdcQBsCN0oktpSwJwNc\u002feziKWQXArRzsJgWEB8DcC+G1R5HNv7sU2UImCQbAua5fOdLsB8AIHwXJq8O7v3M9pNd\u002ftQbA6vt3Sz0ECMAgEPQIVoYDwMJk6nW0AAvAmX4palv6BMB3tx7JKBwGwCAPISxq\u002fgTAYDtwmUuLez++UXnFPOQGwFa06oVNYfG\u002fA9OkM7GPBcDG+G7\u002fSswKwDjXNsyEzgPA5GnqCen8BcD63FEnsDsKwAJMsOVr3gXABUVj3NThBsAqatAUnG0JwLkPnIWeawbA27a1fTco\u002fL9z\u002f7f34SUFwN5o8Nv4XQXAlM6jbKSTCcApXQF1BLQCwCnB9EmilgvAIX0sc5SLBcA68+gFKnb9v+dUHqy\u002fRQnAQ1CNv4qzBsCvBU4W75sIwLeElHhPkwfAhTkyolBu97+8nGO9wpX8v9e\u002fG4989QfAFFB54ZaSzz\u002fKkxZiv08FwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2022"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism (1)","showlegend":true,"x":{"dtype":"f8","bdata":"gL2vdeE95D8="},"y":{"dtype":"f8","bdata":"5h38dpyr7b8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2022","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2022","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2022","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2022","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2022","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2022","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2022"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social (18)","showlegend":true,"x":{"dtype":"f8","bdata":"jqU6zNfHAEAKRPvCGuX+P\u002fcJk537qQRAmauuMhOGAEAEa5dPuuYAQLEe6tMXpQZAtE7dge4HAkBbJpenJlQDQMLRTx19OgVA4Ld1IiaUrb\u002fHpC0\u002fg+LpPw2s23Ca0wJAuBjW482c+z9eqkTBsl8CQAXK39pdaANAYZCabYjsAUA8c3S5TXoAQFG5cf3rKfI\u002f"},"y":{"dtype":"f8","bdata":"8lY37WW++79B1Mqhma8AwAxmAtpNB\u002fy\u002fa8l5mRuzAMDlTqCtIIkDwMsUHeZb6NS\u002fayQaqAHXAcCgTO+HcMPrvwKZGf5ylI2\u002f2KfjJY9l\u002f79U8fgLMZ7qv79Ma\u002fZzLra\u002fq83xgVux979J84O5i6gCwDnjCqw5CALA1egALP\u002fcvD99SATA5ZEDwOxSHmCLec2\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2022","Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2022","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2022","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2022","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2022","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2022"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity (6)","showlegend":true,"x":{"dtype":"f8","bdata":"I5BbvuFU\u002fD96BzkIy50FQF0I3psSjwJAiV4MvB0OBUDIZUmC\u002fSX+PzV4bzje2wRA"},"y":{"dtype":"f8","bdata":"OJywYxa9\u002fb8hHdrMspD4v65AjVExZvK\u002fvu4D\u002fby19L+8nGO9wpX8vzVuxdyd3vW\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2022","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2022","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2022","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2022","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value (15)","showlegend":true,"x":{"dtype":"f8","bdata":"cZ5kU3jkA0CZjS7V54gHQB3z5oOajAZAWSAJCCcYCED6wqaaOicKQKkec38cvglA9LA9gsBi\u002fT8SGyw9eVEDQEC8QrNqzJS\u002fhFU+l6hRC0DEcpvotS0IQMwtI1ek+\u002fw\u002fucCzdCmJDUCIRexUbd4AQFui+NOsiAZA"},"y":{"dtype":"f8","bdata":"Rz5zJrZ57L\u002fwyaBZWPbpv2rHWiafS\u002fC\u002fBQeu425057+CpveH2aTZv4TyCTmClu6\u002f27a1fTco\u002fL9MTquV1\u002fnwvwi0WbTeCvO\u002fk2u9v4oh3b8cWSMtS1Tpvzrz6AUqdv2\u002fYN+Tz\u002f7Y5L+FOTKiUG73v8PsNfuR0\u002fK\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2023","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2023","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2023","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2023","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2023","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2023","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2023","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2023","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2023","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2023","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2023","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2023"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias (19)","showlegend":false,"x":{"dtype":"f8","bdata":"8hCaJ2WQB0CxHurTF6UGQOqJU7gYGeU\u002fbRf8OZWs\u002fT88Gj92NO\u002f1P+c\u002fYPVhCQFAYV28RFpI6z\u002fC0U8dfToFQA2s23Ca0wJAWDUEwc079z+4GNbjzZz7P7ndvC9B0vs\u002f4BKZlkqrAUCWuoY\u002f72rxPw33eNBFPwZAUrML20USAkDwAhQr\u002fGeyv4C9r3XhPeQ\u002ftt0sl3GzB0A="},"y":{"dtype":"f8","bdata":"\u002fkFWUZcT5z\u002fLFB3mW+jUv8wA16bVj9m\u002fU8BBp7qP9r8ZruNV6MbYvwgfBcmrw7u\u002fAPuRpmILVL8CmRn+cpSNv79Ma\u002fZzLra\u002fJWDj8mGZyj+rzfGBW7H3v3xflH0+Fvy\u002ffXNJhz3F6T9bmzHYC9vBP+Q+qgLLmtA\u002fPRX8uamK+j8W3tp5GpH7v+Yd\u002fHacq+2\u002fj3KmUa7X7D8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2023","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2023","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2023","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2023","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2023","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2023","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2023","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2023","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2023","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2023","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2023","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2023","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2023"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural (30)","showlegend":false,"x":{"dtype":"f8","bdata":"Fcuj+J3n0z8yQ1CRSg3aP8oCTKdVzQhA3qfk3Jfa+T\u002fyEJonZZAHQGPDTxgw7AhAi6v2DxCxBkAq7HpvM0oKQOczCGLP0wJA61kBy\u002fKYB0CGxfEkP+gMQJXpBvusJQZAsR7q0xelBkDqiVO4GBnlP9i72JGhcPQ\u002fWyaXpyZUA0BhXbxEWkjrPw33eNBFPwZA1HUckhhr2T8YxRRvZneHP\u002fBqp4IU5+I\u002fBiJiX2lJC0ABgx4PeTMLQC7VOnMVbAdAXS1il263BkBg2Rg3mM\u002f7P1G5cf3rKfI\u002f+Amld5f5BkCN8VT1fOgJQLg9iB4awpM\u002f"},"y":{"dtype":"f8","bdata":"2LOO7d1wzr+ihJ3eavjbv1sx+9NWQO4\u002fsVOnISwA87\u002f+QVZRlxPnP0\u002fT4UlNnuQ\u002fb+OaTTJ55D\u002f44tej4VXuP3SB46IAX84\u002fwvvl1byQ7z\u002fiaCoxleLyP8iBh4u16d8\u002fyxQd5lvo1L\u002fMANem1Y\u002fZv5nhZ8suy\u002fK\u002foEzvh3DD678A+5GmYgtUv+Q+qgLLmtA\u002fVrTqhU1h8b\u002f0tPwo4zbWv4U6EPFkfO0\u002fjGwDwWt43j\u002fqvvj8iXfePyp4e8kkGeM\u002f5HrkFN025j+jEerm8wT+P+xSHmCLec2\u002fzusB0Yss5T+pcnrC5oHmP55pODuXTuk\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2023","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2023","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2023"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture (3)","showlegend":false,"x":{"dtype":"f8","bdata":"hB6DXHK7B0BivzRIxoAGQGHbLUF7jwFA"},"y":{"dtype":"f8","bdata":"nl0Ov9tg6j\u002fvwWSvAxsBQJhXCHuKYvo\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2023","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2023","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2023","Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2023","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2023","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2023","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2023","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2023","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2023","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2023"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics (14)","showlegend":false,"x":{"dtype":"f8","bdata":"OLm3kior1z9DAqaQZeICQMMyr0suPvw\u002fMk0YyRqZAkA8Gj92NO\u002f1P+c\u002fYPVhCQFAwtFPHX06BUANrNtwmtMCQFg1BMHNO\u002fc\u002feu7sHEfb\u002fz\u002fgEpmWSqsBQLbdLJdxswdAhya9pXctA0BhkJptiOwBQA=="},"y":{"dtype":"f8","bdata":"YSIr4hbj3r9md7oCx4kAQMXLtC86yQFAuRQYyVFDAUAZruNV6MbYvwgfBcmrw7u\u002fApkZ\u002fnKUjb+\u002fTGv2cy62vyVg4\u002fJhmco\u002fLbNBpCBLBEB9c0mHPcXpP49yplGu1+w\u002fEvzdgIPR+T\u002fV6AAs\u002f9y8Pw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2023","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2023","Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2023","Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2023","Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2023","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2023","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2023","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2023","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2023","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2023"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity (10)","showlegend":false,"x":{"dtype":"f8","bdata":"ulYgTEet7j8+L42Jrr7TP8zx1cQXQfI\u002f70jOcXSE8z\u002flsAfFg+oAQP\u002ffbk60u\u002fs\u002fQIo56SIx1D967uwcR9v\u002fP1KzC9tFEgJA8GqnghTn4j8="},"y":{"dtype":"f8","bdata":"lZ4otxkttL8obz7SD4Klv\u002fyW7xdSrARAoqlSvu1hCEBClkXTnAgHQNwL4bVHkc2\u002ffKixZ\u002f+uv78ts0GkIEsEQD0V\u002fLmpivo\u002fhToQ8WR87T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2023","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2023","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2023","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2023","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2023","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2023"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical (6)","showlegend":false,"x":{"dtype":"f8","bdata":"0AdLiHG79T\u002fYpsivs5DlP6B1bY5NHfY\u002fx6QtP4Pi6T9RuXH96ynyP9OvvlnBz+o\u002f"},"y":{"dtype":"f8","bdata":"LGjTEsuACEDAabtzbk8GQI954RIhJgRAVPH4CzGe6r\u002fsUh5gi3nNvxk4c8UoiQhA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2023","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2023","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2023","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2023","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality (21)","showlegend":false,"x":{"dtype":"f8","bdata":"5nQ9BTPz4D9svJ8eVZzJP45FX1XjkuO\u002fnNerP67f3D+sOUwTEHvCv6Qmdy7hiOw\u002foNLjgp+6wT\u002fX\u002ffkqZirMP1MrJwyl9cM\u002f8F2Z97t23j8aKciOcx3OPwpyhkJor8g\u002flrqGP+9q8T9wihg8yqXGP261ihJPG90\u002fQoFHQ\u002fQZ7T+sCFxvODrmP26Ed4h1wcy\u002fICYLHQbqyb9g2Rg3mM\u002f7Pz\u002fXdaisQ+E\u002f"},"y":{"dtype":"f8","bdata":"RPyP2F8ZBUCuu9\u002f7LWUFQI7XBD1T2wxA5EDsIjYBBEBGguezHQUJQOCtPb1HJ7e\u002fBqbQpc1GCEDpCJwAaigHQHTGh2RPpQdAOCjV+ENoDUBgO3CZS4t7P3tGIHvISgVAW5sx2AvbwT+bK4yvMhMGQALEWtPuoQtAGVHIOYRwCkBvF+cJ+VgIQLd0qXCiJwlA4wt2urb\u002fB0CjEerm8wT+PyvVzfIxeAdA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2023"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"Rqr5FIP92r8="},"y":{"dtype":"f8","bdata":"XlgBf3e1C0A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2023","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2023","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general (69)","showlegend":false,"x":{"dtype":"f8","bdata":"DZ4S9YsY7L9cuBLLEVH1v6jwzMZ3oPO\u002fyQzqcPWB979y0FGPirf1v3kA2zQaYPS\u002f3DR4RbMP8L\u002fcac5U6mzzv+IZgmvY0\u002fW\u002f4zNI9wb19r8YGYByEtz6vzmUSDOLrvG\u002fm6DPHPhg8r\u002fwGd9b6Urxv5ETcspiBPW\u002fU7dw3p8n9L+wjyuczuT2vzS2fX9st\u002fG\u002ffoW7png69b81\u002fnjv7K7zv6plOytptOO\u002f2jOup4ig779OCSPFi\u002frwv+9hWefxHPK\u002fIDygWi+D878WUvciw+30v3Ny6qxKtPa\u002fomEvebSO9b8I9ANipCrzv6j+N3aUOfu\u002f6qhd\u002f+ie8L95j9PA85zwv1ceIJF6F+u\u002fvjWqdHXA87+NE1GPFEX3vxLSfL+p9\u002fW\u002fmwFi1hon+b852bxSYGbyv65BqWfpp\u002fS\u002fM5bc83Yj97+n8VBcT6Dtv\u002fiAoAc3MP6\u002fHKkcHquw87+zXt+LDs\u002f0v72IDmtRpfK\u002fCe2kZ8qHA8Df+MMth28AwEi1yQMg+v6\u002fOF0MgAVgAsDYxqm\u002f4Xn+v1rilGhC9PC\u002fNEG0RaEB778zUv4sOxL2v9tPbOONROS\u002fcxNOX5Pq9L+ekeY046rSv2OiAOP4PPK\u002fJCrBg3D\u002f9b8yY7sNwSLyv8TyIc2eRfS\u002fzA9azLvh+78z\u002fkljCH74v\u002fCHjt2rCvK\u002fGTAasPwW+79u0zNsNi38vxF9spgiF+6\u002fAD6\u002f5+ew8r8iL7WzPoCsv82AyXgdb\u002fq\u002f"},"y":{"dtype":"f8","bdata":"L+pLnwvMBUA6i6Heu80CQMLWAebijgVALmmI\u002fFQOB0CWWiJ98vgEQNBYVg5CFwNAVKUzoCDeBkBqT7hYOzYMQP+0skxCAAhAKaOte7aRA0DjYPrKN4MFQLP3bTDmHwpA9iONfzxqB0D31GzZT+0EQJeDAXs2CwVABl0UsJw+B0CxScAlqGoIQOQt9tQy9gRAiP2CMYyeCECI0T6R+QMDQNs1Xqg8DAdAWM3C15pVBECQtjF4ysEGQN1w7NBF5gRAXKjSptQxBUDGMfz9SWQJQLylf3sN\u002fAZAVhm9QWBOBkCSI0vC7ZQLQNJkFT9NtwVAamgmmQpDCUCneU5X1PkDQDEVrbO6GAdARoFDqsI7A0DPwJJvq9AEQNzJl9qdoQVAkI0McAjkBUD1XLY76PkCQN1JFSxOgwNAnx0XD4C9B0AJXHtSYuAEQMt0lRInYAVA8BH45ldpBUD+TNeVu8gGQNBFROe+MgdAnLSasU3T8T+TLKLUDogFQKRu3yuMPgdAN4gLzFE+CUC2gjC1ByYGQKeeKPYuowJAsMfSKOeiB0CkaX7nKa0JQM8QEFaAVgVAnNAnXLO5BkB9lmNHRf4DQIcEj7OC4QRAMBxYx53uBkCfI7Gmj9MHQNKo8968hgVAnywzCarfBEDZqQ8zmwkEQBpBWMCkvQdAW7j5Zo8cBkAOBnB38JQGQNrF11XRJgZAtxOnTjfCB0AUUHnhlpLPPxVFvfN53gdA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2023"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate (1)","showlegend":false,"x":{"dtype":"f8","bdata":"o2HJU3Ci3L8="},"y":{"dtype":"f8","bdata":"hhMnrMXhu78="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2023"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor (1)","showlegend":false,"x":{"dtype":"f8","bdata":"hEsMsAk+B8A="},"y":{"dtype":"f8","bdata":"YK0mAt+e\u002fj8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2023","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2023","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2023","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2023"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language (4)","showlegend":false,"x":{"dtype":"f8","bdata":"jGM6nsJBAcCgighRwxoKwCT0+AY2LAXAuD2IHhrCkz8="},"y":{"dtype":"f8","bdata":"GolYHMrl9T9Pr6Mw9RfxP3h8SfyHq9w\u002fnmk4O5dO6T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2023"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal (1)","showlegend":false,"x":{"dtype":"f8","bdata":"StfVHf+oCcA="},"y":{"dtype":"f8","bdata":"sXwh7Nx60L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2023"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length (1)","showlegend":false,"x":{"dtype":"f8","bdata":"Ce2kZ8qHA8A="},"y":{"dtype":"f8","bdata":"nLSasU3T8T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2023","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2023","Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2023","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2023","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2023","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2023","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2023","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral (20)","showlegend":false,"x":{"dtype":"f8","bdata":"mCwsrc9dBcDjibY2SK\u002ftv82kZkHSBwjAFcuj+J3n0z+U\u002f7u+2QUHwO691oK2yQTA3zdB3EGXBcDqiVO4GBnlP2FdvERaSOs\u002fGMUUb2Z3hz\u002fwAhQr\u002fGeyv\u002fBqp4IU5+I\u002fgL2vdeE95D9GvpeR5KIIwH89f6V2cQLAnw9RI+5tBsCoI59ZgBUGwEC8QrNqzJS\u002fhd9QKCQtBsDVxU2GXcAJwA=="},"y":{"dtype":"f8","bdata":"3DI2BAwf6r+ujaZoVbn8vwSWCLf1Yvi\u002f2LOO7d1wzr86SNfA4yvzvxiO9eS7kOW\u002fdoAO\u002fuaC9b\u002fMANem1Y\u002fZvwD7kaZiC1S\u002f9LT8KOM21r8W3tp5GpH7v4U6EPFkfO0\u002f5h38dpyr7b9uIUy2QrLdv2b\u002ffhXaG\u002fe\u002fNiNv0DSB9L+\u002fLCBGElzsvwi0WbTeCvO\u002f5fOuf10b8L9AF\u002fU1TwTpvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2023","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2023","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2023","Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2023","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2023","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2023"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual (6)","showlegend":false,"x":{"dtype":"f8","bdata":"doddQUti5L8gC3LmZen\u002fvzJDUJFKDdo\u002fpMU6jo5xAcDUdRySGGvZP5B2vvLQYATA"},"y":{"dtype":"f8","bdata":"tZj4CmuUA8BZjGodmlL8v6KEnd5q+Nu\u002fUfIWiLg4\u002fb9WtOqFTWHxv7D75u0Puve\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2023"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"q6K4gaNi+r8="},"y":{"dtype":"f8","bdata":"UVAfaaRTAsA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2023","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2023","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions (4)","showlegend":false,"x":{"dtype":"f8","bdata":"OLm3kior1z88Gj92NO\u002f1P+C3dSImlK2\u002fWDUEwc079z8="},"y":{"dtype":"f8","bdata":"YSIr4hbj3r8ZruNV6MbYv9in4yWPZf+\u002fJWDj8mGZyj8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2023","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2023","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2023","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2023","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2023","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2023","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization (31)","showlegend":false,"x":{"dtype":"f8","bdata":"joj7ibStzT8+L42Jrr7TP2vP2aETl+S\u002fmqNwD2GIxL+Im3VXGJ\u002fjvyUwWr5IZ96\u002f2LvYkaFw9D9NmTu0NcLov+P9aQMFvuK\u002fQIo56SIx1D\u002fHpC0\u002fg+LpP+aWl0pPqOW\u002fVK1HroRz1r\u002fYPn19PJ7mvwC5FyhiBJu\u002fwJbtw9dJ7L+O6m2eN5nuv8bZEniNIsK\u002fwLn+s5oywr8E\u002fDQxSFfqv7RnHHGX27e\u002fqhtrLgFX578dhW48bf3yv6KTvK2mwMS\u002fCC0vZEV3tr+Qjo3NKJfqvxL3NoKtz+O\u002fu2d+zWPD37\u002fDKC1Nq+jYv1G5cf3rKfI\u002fKCrdBz573r8="},"y":{"dtype":"f8","bdata":"+7VgZkj3B8Aobz7SD4Klvyd2e9jYLAjA1uTuAxpiBcBR5xvSSZkFwKSNIT2ZtQfAmeFnyy7L8r+a4iuxYxEHwG9qTXeGLAfAfKixZ\u002f+uv79U8fgLMZ7qv++Yj0rqlgPAqCWeZ8\u002foCMBWaZbZwekCwA6hfb0W7QbAYkrBA33FBcBZeICr7NIHwC8CahjlDwvACfXnDonsBcCG5W6\u002f6SMHwCzpzrbtEAbAka9LSdXfBsCFSNlGdSYIwD\u002fYcmbvzAfA1AjwtEs7CcBnlliKFBEFwECjdX0uLAjAtfYDpcItBMC8JwuZpbsHwOxSHmCLec2\u002fiaYtpdjQBcA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2023","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2023","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2023","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2023","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2023","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2023"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political (6)","showlegend":false,"x":{"dtype":"f8","bdata":"bRf8OZWs\u002fT+4GNbjzZz7P7ndvC9B0vs\u002flrqGP+9q8T\u002fwAhQr\u002fGeyv7gT6Vyaw5o\u002f"},"y":{"dtype":"f8","bdata":"U8BBp7qP9r+rzfGBW7H3v3xflH0+Fvy\u002fW5sx2AvbwT8W3tp5GpH7v9l3CwRCEwnA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2023","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2023","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2023","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2023","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2023","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2023","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2023","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2023","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2023","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2023","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2023","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2023","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2023","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2023","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2023","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2023","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2023","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety (62)","showlegend":false,"x":{"dtype":"f8","bdata":"44m2Nkiv7b92h11BS2Lkv46I+4m0rc0\u002fD82\u002fnPUT7z+6ViBMR63uPyOQW77hVPw\u002f3qfk3Jfa+T+AJbeP6CPjP3tGu+HnE+E\u002fm66zrxL56z9WLCqGWAn5P+XBZuCbM\u002fk\u002fc9lQfuju8z\u002fMoa1uh0fqP6pZzklXMdQ\u002f+OjwitsP4D+jYclTcKLcv6Qmdy7hiOw\u002ffK1N7YK86D8yBM8d8RT0P5pjhQSkAvQ\u002fE6pJdGnD7D\u002f\u002f325OtLv7P\u002fHzGdz8B+g\u002fQCayFvkZ4D\u002fnP2D1YQkBQNk7UcxQePA\u002fs+CucAf04z8\u002fSoVBpRDzP6I+pKbOgOc\u002fKd1cBOLc8T9SBAd18JPiP2D5QxjFQ\u002fM\u002fGinIjnMdzj88ED5T+QTzP9R1HJIYa9k\u002fg0YFjc7p3j\u002fgWyx0xOL2P2IBritWl\u002fE\u002fM9pMQg849j9sRjCwj8HuP+HjModkG+o\u002fKJWvRCG06T\u002fljH2WqCfuP8v0AwqqQeo\u002f9LA9gsBi\u002fT9qy9Q4yA7wPxK\u002f6o1\u002fKuc\u002fbVgKTnhh5z\u002fTj2dzPHnmP0siZkm9R\u002fI\u002fYD9IuA926z\u002fMLSNXpPv8P3gfKIrede8\u002fc8640cY97T8A3SFgOeDXP4rlWFi7lPM\u002fiEXsVG3eAEDIZUmC\u002fSX+P7+R88+fWOY\u002fIi+1sz6ArL+TZ0pMZsTfPw=="},"y":{"dtype":"f8","bdata":"ro2maFW5\u002fL+1mPgKa5QDwPu1YGZI9wfAybloGP58BMCVnii3GS20vzicsGMWvf2\u002fsVOnISwA878W+YqufDgHwFoebKGedAjAKjj3BEzvCcDAvbg5GOkIwLDykrgnqgjAlJEsx5aTCMD0mGhoYgUIwOxgD2UCNgrAcXoGpOfMCcCGEyesxeG7v+CtPb1HJ7e\u002fG+ZyXdcQBsCN0oktpSwJwNc\u002feziKWQXArRzsJgWEB8DcC+G1R5HNv7sU2UImCQbAua5fOdLsB8AIHwXJq8O7v3M9pNd\u002ftQbA6vt3Sz0ECMAgEPQIVoYDwMJk6nW0AAvAmX4palv6BMB3tx7JKBwGwCAPISxq\u002fgTAYDtwmUuLez++UXnFPOQGwFa06oVNYfG\u002fA9OkM7GPBcDG+G7\u002fSswKwDjXNsyEzgPA5GnqCen8BcD63FEnsDsKwAJMsOVr3gXABUVj3NThBsAqatAUnG0JwLkPnIWeawbA27a1fTco\u002fL9z\u002f7f34SUFwN5o8Nv4XQXAlM6jbKSTCcApXQF1BLQCwCnB9EmilgvAIX0sc5SLBcA68+gFKnb9v+dUHqy\u002fRQnAQ1CNv4qzBsCvBU4W75sIwLeElHhPkwfAhTkyolBu97+8nGO9wpX8v9e\u002fG4989QfAFFB54ZaSzz\u002fKkxZiv08FwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2023"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism (1)","showlegend":false,"x":{"dtype":"f8","bdata":"gL2vdeE95D8="},"y":{"dtype":"f8","bdata":"5h38dpyr7b8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2023","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2023","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2023","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2023","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2023","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2023","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2023"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social (18)","showlegend":false,"x":{"dtype":"f8","bdata":"jqU6zNfHAEAKRPvCGuX+P\u002fcJk537qQRAmauuMhOGAEAEa5dPuuYAQLEe6tMXpQZAtE7dge4HAkBbJpenJlQDQMLRTx19OgVA4Ld1IiaUrb\u002fHpC0\u002fg+LpPw2s23Ca0wJAuBjW482c+z9eqkTBsl8CQAXK39pdaANAYZCabYjsAUA8c3S5TXoAQFG5cf3rKfI\u002f"},"y":{"dtype":"f8","bdata":"8lY37WW++79B1Mqhma8AwAxmAtpNB\u002fy\u002fa8l5mRuzAMDlTqCtIIkDwMsUHeZb6NS\u002fayQaqAHXAcCgTO+HcMPrvwKZGf5ylI2\u002f2KfjJY9l\u002f79U8fgLMZ7qv79Ma\u002fZzLra\u002fq83xgVux979J84O5i6gCwDnjCqw5CALA1egALP\u002fcvD99SATA5ZEDwOxSHmCLec2\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2023","Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2023","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2023","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2023","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2023","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2023"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity (6)","showlegend":false,"x":{"dtype":"f8","bdata":"I5BbvuFU\u002fD96BzkIy50FQF0I3psSjwJAiV4MvB0OBUDIZUmC\u002fSX+PzV4bzje2wRA"},"y":{"dtype":"f8","bdata":"OJywYxa9\u002fb8hHdrMspD4v65AjVExZvK\u002fvu4D\u002fby19L+8nGO9wpX8vzVuxdyd3vW\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2023","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2023","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2023","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2023","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value (15)","showlegend":false,"x":{"dtype":"f8","bdata":"cZ5kU3jkA0CZjS7V54gHQB3z5oOajAZAWSAJCCcYCED6wqaaOicKQKkec38cvglA9LA9gsBi\u002fT8SGyw9eVEDQEC8QrNqzJS\u002fhFU+l6hRC0DEcpvotS0IQMwtI1ek+\u002fw\u002fucCzdCmJDUCIRexUbd4AQFui+NOsiAZA"},"y":{"dtype":"f8","bdata":"Rz5zJrZ57L\u002fwyaBZWPbpv2rHWiafS\u002fC\u002fBQeu425057+CpveH2aTZv4TyCTmClu6\u002f27a1fTco\u002fL9MTquV1\u002fnwvwi0WbTeCvO\u002fk2u9v4oh3b8cWSMtS1Tpvzrz6AUqdv2\u002fYN+Tz\u002f7Y5L+FOTKiUG73v8PsNfuR0\u002fK\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias (19)","showlegend":false,"x":{"dtype":"f8","bdata":"8hCaJ2WQB0CxHurTF6UGQOqJU7gYGeU\u002fbRf8OZWs\u002fT88Gj92NO\u002f1P+c\u002fYPVhCQFAYV28RFpI6z\u002fC0U8dfToFQA2s23Ca0wJAWDUEwc079z+4GNbjzZz7P7ndvC9B0vs\u002f4BKZlkqrAUCWuoY\u002f72rxPw33eNBFPwZAUrML20USAkDwAhQr\u002fGeyv4C9r3XhPeQ\u002ftt0sl3GzB0A="},"y":{"dtype":"f8","bdata":"\u002fkFWUZcT5z\u002fLFB3mW+jUv8wA16bVj9m\u002fU8BBp7qP9r8ZruNV6MbYvwgfBcmrw7u\u002fAPuRpmILVL8CmRn+cpSNv79Ma\u002fZzLra\u002fJWDj8mGZyj+rzfGBW7H3v3xflH0+Fvy\u002ffXNJhz3F6T9bmzHYC9vBP+Q+qgLLmtA\u002fPRX8uamK+j8W3tp5GpH7v+Yd\u002fHacq+2\u002fj3KmUa7X7D8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2024","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2024","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2024","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2024","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2024"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural (30)","showlegend":false,"x":{"dtype":"f8","bdata":"Fcuj+J3n0z8yQ1CRSg3aP8oCTKdVzQhA3qfk3Jfa+T\u002fyEJonZZAHQGPDTxgw7AhAi6v2DxCxBkAq7HpvM0oKQOczCGLP0wJA61kBy\u002fKYB0CGxfEkP+gMQJXpBvusJQZAsR7q0xelBkDqiVO4GBnlP9i72JGhcPQ\u002fWyaXpyZUA0BhXbxEWkjrPw33eNBFPwZA1HUckhhr2T8YxRRvZneHP\u002fBqp4IU5+I\u002fBiJiX2lJC0ABgx4PeTMLQC7VOnMVbAdAXS1il263BkBg2Rg3mM\u002f7P1G5cf3rKfI\u002f+Amld5f5BkCN8VT1fOgJQLg9iB4awpM\u002f"},"y":{"dtype":"f8","bdata":"2LOO7d1wzr+ihJ3eavjbv1sx+9NWQO4\u002fsVOnISwA87\u002f+QVZRlxPnP0\u002fT4UlNnuQ\u002fb+OaTTJ55D\u002f44tej4VXuP3SB46IAX84\u002fwvvl1byQ7z\u002fiaCoxleLyP8iBh4u16d8\u002fyxQd5lvo1L\u002fMANem1Y\u002fZv5nhZ8suy\u002fK\u002foEzvh3DD678A+5GmYgtUv+Q+qgLLmtA\u002fVrTqhU1h8b\u002f0tPwo4zbWv4U6EPFkfO0\u002fjGwDwWt43j\u002fqvvj8iXfePyp4e8kkGeM\u002f5HrkFN025j+jEerm8wT+P+xSHmCLec2\u002fzusB0Yss5T+pcnrC5oHmP55pODuXTuk\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2024","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2024","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2024"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture (3)","showlegend":false,"x":{"dtype":"f8","bdata":"hB6DXHK7B0BivzRIxoAGQGHbLUF7jwFA"},"y":{"dtype":"f8","bdata":"nl0Ov9tg6j\u002fvwWSvAxsBQJhXCHuKYvo\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2024","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2024","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2024"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics (14)","showlegend":false,"x":{"dtype":"f8","bdata":"OLm3kior1z9DAqaQZeICQMMyr0suPvw\u002fMk0YyRqZAkA8Gj92NO\u002f1P+c\u002fYPVhCQFAwtFPHX06BUANrNtwmtMCQFg1BMHNO\u002fc\u002feu7sHEfb\u002fz\u002fgEpmWSqsBQLbdLJdxswdAhya9pXctA0BhkJptiOwBQA=="},"y":{"dtype":"f8","bdata":"YSIr4hbj3r9md7oCx4kAQMXLtC86yQFAuRQYyVFDAUAZruNV6MbYvwgfBcmrw7u\u002fApkZ\u002fnKUjb+\u002fTGv2cy62vyVg4\u002fJhmco\u002fLbNBpCBLBEB9c0mHPcXpP49yplGu1+w\u002fEvzdgIPR+T\u002fV6AAs\u002f9y8Pw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2024","Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2024","Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2024","Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2024","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2024","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2024","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity (10)","showlegend":false,"x":{"dtype":"f8","bdata":"ulYgTEet7j8+L42Jrr7TP8zx1cQXQfI\u002f70jOcXSE8z\u002flsAfFg+oAQP\u002ffbk60u\u002fs\u002fQIo56SIx1D967uwcR9v\u002fP1KzC9tFEgJA8GqnghTn4j8="},"y":{"dtype":"f8","bdata":"lZ4otxkttL8obz7SD4Klv\u002fyW7xdSrARAoqlSvu1hCEBClkXTnAgHQNwL4bVHkc2\u002ffKixZ\u002f+uv78ts0GkIEsEQD0V\u002fLmpivo\u002fhToQ8WR87T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical (6)","showlegend":false,"x":{"dtype":"f8","bdata":"0AdLiHG79T\u002fYpsivs5DlP6B1bY5NHfY\u002fx6QtP4Pi6T9RuXH96ynyP9OvvlnBz+o\u002f"},"y":{"dtype":"f8","bdata":"LGjTEsuACEDAabtzbk8GQI954RIhJgRAVPH4CzGe6r\u002fsUh5gi3nNvxk4c8UoiQhA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2024","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality (21)","showlegend":false,"x":{"dtype":"f8","bdata":"5nQ9BTPz4D9svJ8eVZzJP45FX1XjkuO\u002fnNerP67f3D+sOUwTEHvCv6Qmdy7hiOw\u002foNLjgp+6wT\u002fX\u002ffkqZirMP1MrJwyl9cM\u002f8F2Z97t23j8aKciOcx3OPwpyhkJor8g\u002flrqGP+9q8T9wihg8yqXGP261ihJPG90\u002fQoFHQ\u002fQZ7T+sCFxvODrmP26Ed4h1wcy\u002fICYLHQbqyb9g2Rg3mM\u002f7Pz\u002fXdaisQ+E\u002f"},"y":{"dtype":"f8","bdata":"RPyP2F8ZBUCuu9\u002f7LWUFQI7XBD1T2wxA5EDsIjYBBEBGguezHQUJQOCtPb1HJ7e\u002fBqbQpc1GCEDpCJwAaigHQHTGh2RPpQdAOCjV+ENoDUBgO3CZS4t7P3tGIHvISgVAW5sx2AvbwT+bK4yvMhMGQALEWtPuoQtAGVHIOYRwCkBvF+cJ+VgIQLd0qXCiJwlA4wt2urb\u002fB0CjEerm8wT+PyvVzfIxeAdA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2024"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"Rqr5FIP92r8="},"y":{"dtype":"f8","bdata":"XlgBf3e1C0A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2024","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2024","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general (69)","showlegend":false,"x":{"dtype":"f8","bdata":"DZ4S9YsY7L9cuBLLEVH1v6jwzMZ3oPO\u002fyQzqcPWB979y0FGPirf1v3kA2zQaYPS\u002f3DR4RbMP8L\u002fcac5U6mzzv+IZgmvY0\u002fW\u002f4zNI9wb19r8YGYByEtz6vzmUSDOLrvG\u002fm6DPHPhg8r\u002fwGd9b6Urxv5ETcspiBPW\u002fU7dw3p8n9L+wjyuczuT2vzS2fX9st\u002fG\u002ffoW7png69b81\u002fnjv7K7zv6plOytptOO\u002f2jOup4ig779OCSPFi\u002frwv+9hWefxHPK\u002fIDygWi+D878WUvciw+30v3Ny6qxKtPa\u002fomEvebSO9b8I9ANipCrzv6j+N3aUOfu\u002f6qhd\u002f+ie8L95j9PA85zwv1ceIJF6F+u\u002fvjWqdHXA87+NE1GPFEX3vxLSfL+p9\u002fW\u002fmwFi1hon+b852bxSYGbyv65BqWfpp\u002fS\u002fM5bc83Yj97+n8VBcT6Dtv\u002fiAoAc3MP6\u002fHKkcHquw87+zXt+LDs\u002f0v72IDmtRpfK\u002fCe2kZ8qHA8Df+MMth28AwEi1yQMg+v6\u002fOF0MgAVgAsDYxqm\u002f4Xn+v1rilGhC9PC\u002fNEG0RaEB778zUv4sOxL2v9tPbOONROS\u002fcxNOX5Pq9L+ekeY046rSv2OiAOP4PPK\u002fJCrBg3D\u002f9b8yY7sNwSLyv8TyIc2eRfS\u002fzA9azLvh+78z\u002fkljCH74v\u002fCHjt2rCvK\u002fGTAasPwW+79u0zNsNi38vxF9spgiF+6\u002fAD6\u002f5+ew8r8iL7WzPoCsv82AyXgdb\u002fq\u002f"},"y":{"dtype":"f8","bdata":"L+pLnwvMBUA6i6Heu80CQMLWAebijgVALmmI\u002fFQOB0CWWiJ98vgEQNBYVg5CFwNAVKUzoCDeBkBqT7hYOzYMQP+0skxCAAhAKaOte7aRA0DjYPrKN4MFQLP3bTDmHwpA9iONfzxqB0D31GzZT+0EQJeDAXs2CwVABl0UsJw+B0CxScAlqGoIQOQt9tQy9gRAiP2CMYyeCECI0T6R+QMDQNs1Xqg8DAdAWM3C15pVBECQtjF4ysEGQN1w7NBF5gRAXKjSptQxBUDGMfz9SWQJQLylf3sN\u002fAZAVhm9QWBOBkCSI0vC7ZQLQNJkFT9NtwVAamgmmQpDCUCneU5X1PkDQDEVrbO6GAdARoFDqsI7A0DPwJJvq9AEQNzJl9qdoQVAkI0McAjkBUD1XLY76PkCQN1JFSxOgwNAnx0XD4C9B0AJXHtSYuAEQMt0lRInYAVA8BH45ldpBUD+TNeVu8gGQNBFROe+MgdAnLSasU3T8T+TLKLUDogFQKRu3yuMPgdAN4gLzFE+CUC2gjC1ByYGQKeeKPYuowJAsMfSKOeiB0CkaX7nKa0JQM8QEFaAVgVAnNAnXLO5BkB9lmNHRf4DQIcEj7OC4QRAMBxYx53uBkCfI7Gmj9MHQNKo8968hgVAnywzCarfBEDZqQ8zmwkEQBpBWMCkvQdAW7j5Zo8cBkAOBnB38JQGQNrF11XRJgZAtxOnTjfCB0AUUHnhlpLPPxVFvfN53gdA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2024"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate (1)","showlegend":false,"x":{"dtype":"f8","bdata":"o2HJU3Ci3L8="},"y":{"dtype":"f8","bdata":"hhMnrMXhu78="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2024"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor (1)","showlegend":false,"x":{"dtype":"f8","bdata":"hEsMsAk+B8A="},"y":{"dtype":"f8","bdata":"YK0mAt+e\u002fj8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2024","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2024","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2024","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2024"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language (4)","showlegend":false,"x":{"dtype":"f8","bdata":"jGM6nsJBAcCgighRwxoKwCT0+AY2LAXAuD2IHhrCkz8="},"y":{"dtype":"f8","bdata":"GolYHMrl9T9Pr6Mw9RfxP3h8SfyHq9w\u002fnmk4O5dO6T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2024"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal (1)","showlegend":false,"x":{"dtype":"f8","bdata":"StfVHf+oCcA="},"y":{"dtype":"f8","bdata":"sXwh7Nx60L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2024"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length (1)","showlegend":false,"x":{"dtype":"f8","bdata":"Ce2kZ8qHA8A="},"y":{"dtype":"f8","bdata":"nLSasU3T8T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2024","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2024","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral (20)","showlegend":false,"x":{"dtype":"f8","bdata":"mCwsrc9dBcDjibY2SK\u002ftv82kZkHSBwjAFcuj+J3n0z+U\u002f7u+2QUHwO691oK2yQTA3zdB3EGXBcDqiVO4GBnlP2FdvERaSOs\u002fGMUUb2Z3hz\u002fwAhQr\u002fGeyv\u002fBqp4IU5+I\u002fgL2vdeE95D9GvpeR5KIIwH89f6V2cQLAnw9RI+5tBsCoI59ZgBUGwEC8QrNqzJS\u002fhd9QKCQtBsDVxU2GXcAJwA=="},"y":{"dtype":"f8","bdata":"3DI2BAwf6r+ujaZoVbn8vwSWCLf1Yvi\u002f2LOO7d1wzr86SNfA4yvzvxiO9eS7kOW\u002fdoAO\u002fuaC9b\u002fMANem1Y\u002fZvwD7kaZiC1S\u002f9LT8KOM21r8W3tp5GpH7v4U6EPFkfO0\u002f5h38dpyr7b9uIUy2QrLdv2b\u002ffhXaG\u002fe\u002fNiNv0DSB9L+\u002fLCBGElzsvwi0WbTeCvO\u002f5fOuf10b8L9AF\u002fU1TwTpvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2024","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2024","Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual (6)","showlegend":false,"x":{"dtype":"f8","bdata":"doddQUti5L8gC3LmZen\u002fvzJDUJFKDdo\u002fpMU6jo5xAcDUdRySGGvZP5B2vvLQYATA"},"y":{"dtype":"f8","bdata":"tZj4CmuUA8BZjGodmlL8v6KEnd5q+Nu\u002fUfIWiLg4\u002fb9WtOqFTWHxv7D75u0Puve\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2024"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"q6K4gaNi+r8="},"y":{"dtype":"f8","bdata":"UVAfaaRTAsA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions (4)","showlegend":false,"x":{"dtype":"f8","bdata":"OLm3kior1z88Gj92NO\u002f1P+C3dSImlK2\u002fWDUEwc079z8="},"y":{"dtype":"f8","bdata":"YSIr4hbj3r8ZruNV6MbYv9in4yWPZf+\u002fJWDj8mGZyj8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2024","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2024","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2024","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization (31)","showlegend":false,"x":{"dtype":"f8","bdata":"joj7ibStzT8+L42Jrr7TP2vP2aETl+S\u002fmqNwD2GIxL+Im3VXGJ\u002fjvyUwWr5IZ96\u002f2LvYkaFw9D9NmTu0NcLov+P9aQMFvuK\u002fQIo56SIx1D\u002fHpC0\u002fg+LpP+aWl0pPqOW\u002fVK1HroRz1r\u002fYPn19PJ7mvwC5FyhiBJu\u002fwJbtw9dJ7L+O6m2eN5nuv8bZEniNIsK\u002fwLn+s5oywr8E\u002fDQxSFfqv7RnHHGX27e\u002fqhtrLgFX578dhW48bf3yv6KTvK2mwMS\u002fCC0vZEV3tr+Qjo3NKJfqvxL3NoKtz+O\u002fu2d+zWPD37\u002fDKC1Nq+jYv1G5cf3rKfI\u002fKCrdBz573r8="},"y":{"dtype":"f8","bdata":"+7VgZkj3B8Aobz7SD4Klvyd2e9jYLAjA1uTuAxpiBcBR5xvSSZkFwKSNIT2ZtQfAmeFnyy7L8r+a4iuxYxEHwG9qTXeGLAfAfKixZ\u002f+uv79U8fgLMZ7qv++Yj0rqlgPAqCWeZ8\u002foCMBWaZbZwekCwA6hfb0W7QbAYkrBA33FBcBZeICr7NIHwC8CahjlDwvACfXnDonsBcCG5W6\u002f6SMHwCzpzrbtEAbAka9LSdXfBsCFSNlGdSYIwD\u002fYcmbvzAfA1AjwtEs7CcBnlliKFBEFwECjdX0uLAjAtfYDpcItBMC8JwuZpbsHwOxSHmCLec2\u002fiaYtpdjQBcA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2024"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political (6)","showlegend":false,"x":{"dtype":"f8","bdata":"bRf8OZWs\u002fT+4GNbjzZz7P7ndvC9B0vs\u002flrqGP+9q8T\u002fwAhQr\u002fGeyv7gT6Vyaw5o\u002f"},"y":{"dtype":"f8","bdata":"U8BBp7qP9r+rzfGBW7H3v3xflH0+Fvy\u002fW5sx2AvbwT8W3tp5GpH7v9l3CwRCEwnA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2024","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2024","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2024","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2024","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2024","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2024","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2024","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2024","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2024","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2024","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2024","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety (62)","showlegend":false,"x":{"dtype":"f8","bdata":"44m2Nkiv7b92h11BS2Lkv46I+4m0rc0\u002fD82\u002fnPUT7z+6ViBMR63uPyOQW77hVPw\u002f3qfk3Jfa+T+AJbeP6CPjP3tGu+HnE+E\u002fm66zrxL56z9WLCqGWAn5P+XBZuCbM\u002fk\u002fc9lQfuju8z\u002fMoa1uh0fqP6pZzklXMdQ\u002f+OjwitsP4D+jYclTcKLcv6Qmdy7hiOw\u002ffK1N7YK86D8yBM8d8RT0P5pjhQSkAvQ\u002fE6pJdGnD7D\u002f\u002f325OtLv7P\u002fHzGdz8B+g\u002fQCayFvkZ4D\u002fnP2D1YQkBQNk7UcxQePA\u002fs+CucAf04z8\u002fSoVBpRDzP6I+pKbOgOc\u002fKd1cBOLc8T9SBAd18JPiP2D5QxjFQ\u002fM\u002fGinIjnMdzj88ED5T+QTzP9R1HJIYa9k\u002fg0YFjc7p3j\u002fgWyx0xOL2P2IBritWl\u002fE\u002fM9pMQg849j9sRjCwj8HuP+HjModkG+o\u002fKJWvRCG06T\u002fljH2WqCfuP8v0AwqqQeo\u002f9LA9gsBi\u002fT9qy9Q4yA7wPxK\u002f6o1\u002fKuc\u002fbVgKTnhh5z\u002fTj2dzPHnmP0siZkm9R\u002fI\u002fYD9IuA926z\u002fMLSNXpPv8P3gfKIrede8\u002fc8640cY97T8A3SFgOeDXP4rlWFi7lPM\u002fiEXsVG3eAEDIZUmC\u002fSX+P7+R88+fWOY\u002fIi+1sz6ArL+TZ0pMZsTfPw=="},"y":{"dtype":"f8","bdata":"ro2maFW5\u002fL+1mPgKa5QDwPu1YGZI9wfAybloGP58BMCVnii3GS20vzicsGMWvf2\u002fsVOnISwA878W+YqufDgHwFoebKGedAjAKjj3BEzvCcDAvbg5GOkIwLDykrgnqgjAlJEsx5aTCMD0mGhoYgUIwOxgD2UCNgrAcXoGpOfMCcCGEyesxeG7v+CtPb1HJ7e\u002fG+ZyXdcQBsCN0oktpSwJwNc\u002feziKWQXArRzsJgWEB8DcC+G1R5HNv7sU2UImCQbAua5fOdLsB8AIHwXJq8O7v3M9pNd\u002ftQbA6vt3Sz0ECMAgEPQIVoYDwMJk6nW0AAvAmX4palv6BMB3tx7JKBwGwCAPISxq\u002fgTAYDtwmUuLez++UXnFPOQGwFa06oVNYfG\u002fA9OkM7GPBcDG+G7\u002fSswKwDjXNsyEzgPA5GnqCen8BcD63FEnsDsKwAJMsOVr3gXABUVj3NThBsAqatAUnG0JwLkPnIWeawbA27a1fTco\u002fL9z\u002f7f34SUFwN5o8Nv4XQXAlM6jbKSTCcApXQF1BLQCwCnB9EmilgvAIX0sc5SLBcA68+gFKnb9v+dUHqy\u002fRQnAQ1CNv4qzBsCvBU4W75sIwLeElHhPkwfAhTkyolBu97+8nGO9wpX8v9e\u002fG4989QfAFFB54ZaSzz\u002fKkxZiv08FwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism (1)","showlegend":false,"x":{"dtype":"f8","bdata":"gL2vdeE95D8="},"y":{"dtype":"f8","bdata":"5h38dpyr7b8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2024","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2024"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social (18)","showlegend":false,"x":{"dtype":"f8","bdata":"jqU6zNfHAEAKRPvCGuX+P\u002fcJk537qQRAmauuMhOGAEAEa5dPuuYAQLEe6tMXpQZAtE7dge4HAkBbJpenJlQDQMLRTx19OgVA4Ld1IiaUrb\u002fHpC0\u002fg+LpPw2s23Ca0wJAuBjW482c+z9eqkTBsl8CQAXK39pdaANAYZCabYjsAUA8c3S5TXoAQFG5cf3rKfI\u002f"},"y":{"dtype":"f8","bdata":"8lY37WW++79B1Mqhma8AwAxmAtpNB\u002fy\u002fa8l5mRuzAMDlTqCtIIkDwMsUHeZb6NS\u002fayQaqAHXAcCgTO+HcMPrvwKZGf5ylI2\u002f2KfjJY9l\u002f79U8fgLMZ7qv79Ma\u002fZzLra\u002fq83xgVux979J84O5i6gCwDnjCqw5CALA1egALP\u002fcvD99SATA5ZEDwOxSHmCLec2\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2024","Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2024","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity (6)","showlegend":false,"x":{"dtype":"f8","bdata":"I5BbvuFU\u002fD96BzkIy50FQF0I3psSjwJAiV4MvB0OBUDIZUmC\u002fSX+PzV4bzje2wRA"},"y":{"dtype":"f8","bdata":"OJywYxa9\u002fb8hHdrMspD4v65AjVExZvK\u002fvu4D\u002fby19L+8nGO9wpX8vzVuxdyd3vW\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2024","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2024","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2024","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2024","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value (15)","showlegend":false,"x":{"dtype":"f8","bdata":"cZ5kU3jkA0CZjS7V54gHQB3z5oOajAZAWSAJCCcYCED6wqaaOicKQKkec38cvglA9LA9gsBi\u002fT8SGyw9eVEDQEC8QrNqzJS\u002fhFU+l6hRC0DEcpvotS0IQMwtI1ek+\u002fw\u002fucCzdCmJDUCIRexUbd4AQFui+NOsiAZA"},"y":{"dtype":"f8","bdata":"Rz5zJrZ57L\u002fwyaBZWPbpv2rHWiafS\u002fC\u002fBQeu425057+CpveH2aTZv4TyCTmClu6\u002f27a1fTco\u002fL9MTquV1\u002fnwvwi0WbTeCvO\u002fk2u9v4oh3b8cWSMtS1Tpvzrz6AUqdv2\u002fYN+Tz\u002f7Y5L+FOTKiUG73v8PsNfuR0\u002fK\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2025","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2025","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2025","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2025","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2025","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2025","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2025","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2025","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2025","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2025","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2025"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias (19)","showlegend":false,"x":{"dtype":"f8","bdata":"8hCaJ2WQB0CxHurTF6UGQOqJU7gYGeU\u002fbRf8OZWs\u002fT88Gj92NO\u002f1P+c\u002fYPVhCQFAYV28RFpI6z\u002fC0U8dfToFQA2s23Ca0wJAWDUEwc079z+4GNbjzZz7P7ndvC9B0vs\u002f4BKZlkqrAUCWuoY\u002f72rxPw33eNBFPwZAUrML20USAkDwAhQr\u002fGeyv4C9r3XhPeQ\u002ftt0sl3GzB0A="},"y":{"dtype":"f8","bdata":"\u002fkFWUZcT5z\u002fLFB3mW+jUv8wA16bVj9m\u002fU8BBp7qP9r8ZruNV6MbYvwgfBcmrw7u\u002fAPuRpmILVL8CmRn+cpSNv79Ma\u002fZzLra\u002fJWDj8mGZyj+rzfGBW7H3v3xflH0+Fvy\u002ffXNJhz3F6T9bmzHYC9vBP+Q+qgLLmtA\u002fPRX8uamK+j8W3tp5GpH7v+Yd\u002fHacq+2\u002fj3KmUa7X7D8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2025","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2025","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2025","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2025","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2025","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2025","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2025","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2025"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural (30)","showlegend":false,"x":{"dtype":"f8","bdata":"Fcuj+J3n0z8yQ1CRSg3aP8oCTKdVzQhA3qfk3Jfa+T\u002fyEJonZZAHQGPDTxgw7AhAi6v2DxCxBkAq7HpvM0oKQOczCGLP0wJA61kBy\u002fKYB0CGxfEkP+gMQJXpBvusJQZAsR7q0xelBkDqiVO4GBnlP9i72JGhcPQ\u002fWyaXpyZUA0BhXbxEWkjrPw33eNBFPwZA1HUckhhr2T8YxRRvZneHP\u002fBqp4IU5+I\u002fBiJiX2lJC0ABgx4PeTMLQC7VOnMVbAdAXS1il263BkBg2Rg3mM\u002f7P1G5cf3rKfI\u002f+Amld5f5BkCN8VT1fOgJQLg9iB4awpM\u002f"},"y":{"dtype":"f8","bdata":"2LOO7d1wzr+ihJ3eavjbv1sx+9NWQO4\u002fsVOnISwA87\u002f+QVZRlxPnP0\u002fT4UlNnuQ\u002fb+OaTTJ55D\u002f44tej4VXuP3SB46IAX84\u002fwvvl1byQ7z\u002fiaCoxleLyP8iBh4u16d8\u002fyxQd5lvo1L\u002fMANem1Y\u002fZv5nhZ8suy\u002fK\u002foEzvh3DD678A+5GmYgtUv+Q+qgLLmtA\u002fVrTqhU1h8b\u002f0tPwo4zbWv4U6EPFkfO0\u002fjGwDwWt43j\u002fqvvj8iXfePyp4e8kkGeM\u002f5HrkFN025j+jEerm8wT+P+xSHmCLec2\u002fzusB0Yss5T+pcnrC5oHmP55pODuXTuk\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture (3)","showlegend":false,"x":{"dtype":"f8","bdata":"hB6DXHK7B0BivzRIxoAGQGHbLUF7jwFA"},"y":{"dtype":"f8","bdata":"nl0Ov9tg6j\u002fvwWSvAxsBQJhXCHuKYvo\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2025","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2025","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2025","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2025","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2025","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2025"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics (14)","showlegend":false,"x":{"dtype":"f8","bdata":"OLm3kior1z9DAqaQZeICQMMyr0suPvw\u002fMk0YyRqZAkA8Gj92NO\u002f1P+c\u002fYPVhCQFAwtFPHX06BUANrNtwmtMCQFg1BMHNO\u002fc\u002feu7sHEfb\u002fz\u002fgEpmWSqsBQLbdLJdxswdAhya9pXctA0BhkJptiOwBQA=="},"y":{"dtype":"f8","bdata":"YSIr4hbj3r9md7oCx4kAQMXLtC86yQFAuRQYyVFDAUAZruNV6MbYvwgfBcmrw7u\u002fApkZ\u002fnKUjb+\u002fTGv2cy62vyVg4\u002fJhmco\u002fLbNBpCBLBEB9c0mHPcXpP49yplGu1+w\u002fEvzdgIPR+T\u002fV6AAs\u002f9y8Pw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2025","Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2025","Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2025","Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2025","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2025","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2025","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2025","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2025"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity (10)","showlegend":false,"x":{"dtype":"f8","bdata":"ulYgTEet7j8+L42Jrr7TP8zx1cQXQfI\u002f70jOcXSE8z\u002flsAfFg+oAQP\u002ffbk60u\u002fs\u002fQIo56SIx1D967uwcR9v\u002fP1KzC9tFEgJA8GqnghTn4j8="},"y":{"dtype":"f8","bdata":"lZ4otxkttL8obz7SD4Klv\u002fyW7xdSrARAoqlSvu1hCEBClkXTnAgHQNwL4bVHkc2\u002ffKixZ\u002f+uv78ts0GkIEsEQD0V\u002fLmpivo\u002fhToQ8WR87T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical (6)","showlegend":false,"x":{"dtype":"f8","bdata":"0AdLiHG79T\u002fYpsivs5DlP6B1bY5NHfY\u002fx6QtP4Pi6T9RuXH96ynyP9OvvlnBz+o\u002f"},"y":{"dtype":"f8","bdata":"LGjTEsuACEDAabtzbk8GQI954RIhJgRAVPH4CzGe6r\u002fsUh5gi3nNvxk4c8UoiQhA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2025","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2025","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2025","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2025","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality (21)","showlegend":false,"x":{"dtype":"f8","bdata":"5nQ9BTPz4D9svJ8eVZzJP45FX1XjkuO\u002fnNerP67f3D+sOUwTEHvCv6Qmdy7hiOw\u002foNLjgp+6wT\u002fX\u002ffkqZirMP1MrJwyl9cM\u002f8F2Z97t23j8aKciOcx3OPwpyhkJor8g\u002flrqGP+9q8T9wihg8yqXGP261ihJPG90\u002fQoFHQ\u002fQZ7T+sCFxvODrmP26Ed4h1wcy\u002fICYLHQbqyb9g2Rg3mM\u002f7Pz\u002fXdaisQ+E\u002f"},"y":{"dtype":"f8","bdata":"RPyP2F8ZBUCuu9\u002f7LWUFQI7XBD1T2wxA5EDsIjYBBEBGguezHQUJQOCtPb1HJ7e\u002fBqbQpc1GCEDpCJwAaigHQHTGh2RPpQdAOCjV+ENoDUBgO3CZS4t7P3tGIHvISgVAW5sx2AvbwT+bK4yvMhMGQALEWtPuoQtAGVHIOYRwCkBvF+cJ+VgIQLd0qXCiJwlA4wt2urb\u002fB0CjEerm8wT+PyvVzfIxeAdA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2025"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"Rqr5FIP92r8="},"y":{"dtype":"f8","bdata":"XlgBf3e1C0A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2025","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2025","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general (69)","showlegend":false,"x":{"dtype":"f8","bdata":"DZ4S9YsY7L9cuBLLEVH1v6jwzMZ3oPO\u002fyQzqcPWB979y0FGPirf1v3kA2zQaYPS\u002f3DR4RbMP8L\u002fcac5U6mzzv+IZgmvY0\u002fW\u002f4zNI9wb19r8YGYByEtz6vzmUSDOLrvG\u002fm6DPHPhg8r\u002fwGd9b6Urxv5ETcspiBPW\u002fU7dw3p8n9L+wjyuczuT2vzS2fX9st\u002fG\u002ffoW7png69b81\u002fnjv7K7zv6plOytptOO\u002f2jOup4ig779OCSPFi\u002frwv+9hWefxHPK\u002fIDygWi+D878WUvciw+30v3Ny6qxKtPa\u002fomEvebSO9b8I9ANipCrzv6j+N3aUOfu\u002f6qhd\u002f+ie8L95j9PA85zwv1ceIJF6F+u\u002fvjWqdHXA87+NE1GPFEX3vxLSfL+p9\u002fW\u002fmwFi1hon+b852bxSYGbyv65BqWfpp\u002fS\u002fM5bc83Yj97+n8VBcT6Dtv\u002fiAoAc3MP6\u002fHKkcHquw87+zXt+LDs\u002f0v72IDmtRpfK\u002fCe2kZ8qHA8Df+MMth28AwEi1yQMg+v6\u002fOF0MgAVgAsDYxqm\u002f4Xn+v1rilGhC9PC\u002fNEG0RaEB778zUv4sOxL2v9tPbOONROS\u002fcxNOX5Pq9L+ekeY046rSv2OiAOP4PPK\u002fJCrBg3D\u002f9b8yY7sNwSLyv8TyIc2eRfS\u002fzA9azLvh+78z\u002fkljCH74v\u002fCHjt2rCvK\u002fGTAasPwW+79u0zNsNi38vxF9spgiF+6\u002fAD6\u002f5+ew8r8iL7WzPoCsv82AyXgdb\u002fq\u002f"},"y":{"dtype":"f8","bdata":"L+pLnwvMBUA6i6Heu80CQMLWAebijgVALmmI\u002fFQOB0CWWiJ98vgEQNBYVg5CFwNAVKUzoCDeBkBqT7hYOzYMQP+0skxCAAhAKaOte7aRA0DjYPrKN4MFQLP3bTDmHwpA9iONfzxqB0D31GzZT+0EQJeDAXs2CwVABl0UsJw+B0CxScAlqGoIQOQt9tQy9gRAiP2CMYyeCECI0T6R+QMDQNs1Xqg8DAdAWM3C15pVBECQtjF4ysEGQN1w7NBF5gRAXKjSptQxBUDGMfz9SWQJQLylf3sN\u002fAZAVhm9QWBOBkCSI0vC7ZQLQNJkFT9NtwVAamgmmQpDCUCneU5X1PkDQDEVrbO6GAdARoFDqsI7A0DPwJJvq9AEQNzJl9qdoQVAkI0McAjkBUD1XLY76PkCQN1JFSxOgwNAnx0XD4C9B0AJXHtSYuAEQMt0lRInYAVA8BH45ldpBUD+TNeVu8gGQNBFROe+MgdAnLSasU3T8T+TLKLUDogFQKRu3yuMPgdAN4gLzFE+CUC2gjC1ByYGQKeeKPYuowJAsMfSKOeiB0CkaX7nKa0JQM8QEFaAVgVAnNAnXLO5BkB9lmNHRf4DQIcEj7OC4QRAMBxYx53uBkCfI7Gmj9MHQNKo8968hgVAnywzCarfBEDZqQ8zmwkEQBpBWMCkvQdAW7j5Zo8cBkAOBnB38JQGQNrF11XRJgZAtxOnTjfCB0AUUHnhlpLPPxVFvfN53gdA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2025"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate (1)","showlegend":false,"x":{"dtype":"f8","bdata":"o2HJU3Ci3L8="},"y":{"dtype":"f8","bdata":"hhMnrMXhu78="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2025"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor (1)","showlegend":false,"x":{"dtype":"f8","bdata":"hEsMsAk+B8A="},"y":{"dtype":"f8","bdata":"YK0mAt+e\u002fj8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2025"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language (4)","showlegend":false,"x":{"dtype":"f8","bdata":"jGM6nsJBAcCgighRwxoKwCT0+AY2LAXAuD2IHhrCkz8="},"y":{"dtype":"f8","bdata":"GolYHMrl9T9Pr6Mw9RfxP3h8SfyHq9w\u002fnmk4O5dO6T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2025"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal (1)","showlegend":false,"x":{"dtype":"f8","bdata":"StfVHf+oCcA="},"y":{"dtype":"f8","bdata":"sXwh7Nx60L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2025"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length (1)","showlegend":false,"x":{"dtype":"f8","bdata":"Ce2kZ8qHA8A="},"y":{"dtype":"f8","bdata":"nLSasU3T8T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2025","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2025","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2025","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2025","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2025","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral (20)","showlegend":false,"x":{"dtype":"f8","bdata":"mCwsrc9dBcDjibY2SK\u002ftv82kZkHSBwjAFcuj+J3n0z+U\u002f7u+2QUHwO691oK2yQTA3zdB3EGXBcDqiVO4GBnlP2FdvERaSOs\u002fGMUUb2Z3hz\u002fwAhQr\u002fGeyv\u002fBqp4IU5+I\u002fgL2vdeE95D9GvpeR5KIIwH89f6V2cQLAnw9RI+5tBsCoI59ZgBUGwEC8QrNqzJS\u002fhd9QKCQtBsDVxU2GXcAJwA=="},"y":{"dtype":"f8","bdata":"3DI2BAwf6r+ujaZoVbn8vwSWCLf1Yvi\u002f2LOO7d1wzr86SNfA4yvzvxiO9eS7kOW\u002fdoAO\u002fuaC9b\u002fMANem1Y\u002fZvwD7kaZiC1S\u002f9LT8KOM21r8W3tp5GpH7v4U6EPFkfO0\u002f5h38dpyr7b9uIUy2QrLdv2b\u002ffhXaG\u002fe\u002fNiNv0DSB9L+\u002fLCBGElzsvwi0WbTeCvO\u002f5fOuf10b8L9AF\u002fU1TwTpvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2025","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2025","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2025","Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2025","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2025","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2025"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual (6)","showlegend":false,"x":{"dtype":"f8","bdata":"doddQUti5L8gC3LmZen\u002fvzJDUJFKDdo\u002fpMU6jo5xAcDUdRySGGvZP5B2vvLQYATA"},"y":{"dtype":"f8","bdata":"tZj4CmuUA8BZjGodmlL8v6KEnd5q+Nu\u002fUfIWiLg4\u002fb9WtOqFTWHxv7D75u0Puve\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2025"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"q6K4gaNi+r8="},"y":{"dtype":"f8","bdata":"UVAfaaRTAsA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2025","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2025","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions (4)","showlegend":false,"x":{"dtype":"f8","bdata":"OLm3kior1z88Gj92NO\u002f1P+C3dSImlK2\u002fWDUEwc079z8="},"y":{"dtype":"f8","bdata":"YSIr4hbj3r8ZruNV6MbYv9in4yWPZf+\u002fJWDj8mGZyj8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2025","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2025","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2025","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2025","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2025","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization (31)","showlegend":false,"x":{"dtype":"f8","bdata":"joj7ibStzT8+L42Jrr7TP2vP2aETl+S\u002fmqNwD2GIxL+Im3VXGJ\u002fjvyUwWr5IZ96\u002f2LvYkaFw9D9NmTu0NcLov+P9aQMFvuK\u002fQIo56SIx1D\u002fHpC0\u002fg+LpP+aWl0pPqOW\u002fVK1HroRz1r\u002fYPn19PJ7mvwC5FyhiBJu\u002fwJbtw9dJ7L+O6m2eN5nuv8bZEniNIsK\u002fwLn+s5oywr8E\u002fDQxSFfqv7RnHHGX27e\u002fqhtrLgFX578dhW48bf3yv6KTvK2mwMS\u002fCC0vZEV3tr+Qjo3NKJfqvxL3NoKtz+O\u002fu2d+zWPD37\u002fDKC1Nq+jYv1G5cf3rKfI\u002fKCrdBz573r8="},"y":{"dtype":"f8","bdata":"+7VgZkj3B8Aobz7SD4Klvyd2e9jYLAjA1uTuAxpiBcBR5xvSSZkFwKSNIT2ZtQfAmeFnyy7L8r+a4iuxYxEHwG9qTXeGLAfAfKixZ\u002f+uv79U8fgLMZ7qv++Yj0rqlgPAqCWeZ8\u002foCMBWaZbZwekCwA6hfb0W7QbAYkrBA33FBcBZeICr7NIHwC8CahjlDwvACfXnDonsBcCG5W6\u002f6SMHwCzpzrbtEAbAka9LSdXfBsCFSNlGdSYIwD\u002fYcmbvzAfA1AjwtEs7CcBnlliKFBEFwECjdX0uLAjAtfYDpcItBMC8JwuZpbsHwOxSHmCLec2\u002fiaYtpdjQBcA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2025","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2025","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2025","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2025","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2025","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2025"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political (6)","showlegend":false,"x":{"dtype":"f8","bdata":"bRf8OZWs\u002fT+4GNbjzZz7P7ndvC9B0vs\u002flrqGP+9q8T\u002fwAhQr\u002fGeyv7gT6Vyaw5o\u002f"},"y":{"dtype":"f8","bdata":"U8BBp7qP9r+rzfGBW7H3v3xflH0+Fvy\u002fW5sx2AvbwT8W3tp5GpH7v9l3CwRCEwnA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2025","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2025","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2025","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2025","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2025","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2025","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2025","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2025","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2025","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2025","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2025","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2025","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2025","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety (62)","showlegend":false,"x":{"dtype":"f8","bdata":"44m2Nkiv7b92h11BS2Lkv46I+4m0rc0\u002fD82\u002fnPUT7z+6ViBMR63uPyOQW77hVPw\u002f3qfk3Jfa+T+AJbeP6CPjP3tGu+HnE+E\u002fm66zrxL56z9WLCqGWAn5P+XBZuCbM\u002fk\u002fc9lQfuju8z\u002fMoa1uh0fqP6pZzklXMdQ\u002f+OjwitsP4D+jYclTcKLcv6Qmdy7hiOw\u002ffK1N7YK86D8yBM8d8RT0P5pjhQSkAvQ\u002fE6pJdGnD7D\u002f\u002f325OtLv7P\u002fHzGdz8B+g\u002fQCayFvkZ4D\u002fnP2D1YQkBQNk7UcxQePA\u002fs+CucAf04z8\u002fSoVBpRDzP6I+pKbOgOc\u002fKd1cBOLc8T9SBAd18JPiP2D5QxjFQ\u002fM\u002fGinIjnMdzj88ED5T+QTzP9R1HJIYa9k\u002fg0YFjc7p3j\u002fgWyx0xOL2P2IBritWl\u002fE\u002fM9pMQg849j9sRjCwj8HuP+HjModkG+o\u002fKJWvRCG06T\u002fljH2WqCfuP8v0AwqqQeo\u002f9LA9gsBi\u002fT9qy9Q4yA7wPxK\u002f6o1\u002fKuc\u002fbVgKTnhh5z\u002fTj2dzPHnmP0siZkm9R\u002fI\u002fYD9IuA926z\u002fMLSNXpPv8P3gfKIrede8\u002fc8640cY97T8A3SFgOeDXP4rlWFi7lPM\u002fiEXsVG3eAEDIZUmC\u002fSX+P7+R88+fWOY\u002fIi+1sz6ArL+TZ0pMZsTfPw=="},"y":{"dtype":"f8","bdata":"ro2maFW5\u002fL+1mPgKa5QDwPu1YGZI9wfAybloGP58BMCVnii3GS20vzicsGMWvf2\u002fsVOnISwA878W+YqufDgHwFoebKGedAjAKjj3BEzvCcDAvbg5GOkIwLDykrgnqgjAlJEsx5aTCMD0mGhoYgUIwOxgD2UCNgrAcXoGpOfMCcCGEyesxeG7v+CtPb1HJ7e\u002fG+ZyXdcQBsCN0oktpSwJwNc\u002feziKWQXArRzsJgWEB8DcC+G1R5HNv7sU2UImCQbAua5fOdLsB8AIHwXJq8O7v3M9pNd\u002ftQbA6vt3Sz0ECMAgEPQIVoYDwMJk6nW0AAvAmX4palv6BMB3tx7JKBwGwCAPISxq\u002fgTAYDtwmUuLez++UXnFPOQGwFa06oVNYfG\u002fA9OkM7GPBcDG+G7\u002fSswKwDjXNsyEzgPA5GnqCen8BcD63FEnsDsKwAJMsOVr3gXABUVj3NThBsAqatAUnG0JwLkPnIWeawbA27a1fTco\u002fL9z\u002f7f34SUFwN5o8Nv4XQXAlM6jbKSTCcApXQF1BLQCwCnB9EmilgvAIX0sc5SLBcA68+gFKnb9v+dUHqy\u002fRQnAQ1CNv4qzBsCvBU4W75sIwLeElHhPkwfAhTkyolBu97+8nGO9wpX8v9e\u002fG4989QfAFFB54ZaSzz\u002fKkxZiv08FwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2025"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism (1)","showlegend":false,"x":{"dtype":"f8","bdata":"gL2vdeE95D8="},"y":{"dtype":"f8","bdata":"5h38dpyr7b8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2025","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2025","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2025","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2025","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2025","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2025","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social (18)","showlegend":false,"x":{"dtype":"f8","bdata":"jqU6zNfHAEAKRPvCGuX+P\u002fcJk537qQRAmauuMhOGAEAEa5dPuuYAQLEe6tMXpQZAtE7dge4HAkBbJpenJlQDQMLRTx19OgVA4Ld1IiaUrb\u002fHpC0\u002fg+LpPw2s23Ca0wJAuBjW482c+z9eqkTBsl8CQAXK39pdaANAYZCabYjsAUA8c3S5TXoAQFG5cf3rKfI\u002f"},"y":{"dtype":"f8","bdata":"8lY37WW++79B1Mqhma8AwAxmAtpNB\u002fy\u002fa8l5mRuzAMDlTqCtIIkDwMsUHeZb6NS\u002fayQaqAHXAcCgTO+HcMPrvwKZGf5ylI2\u002f2KfjJY9l\u002f79U8fgLMZ7qv79Ma\u002fZzLra\u002fq83xgVux979J84O5i6gCwDnjCqw5CALA1egALP\u002fcvD99SATA5ZEDwOxSHmCLec2\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2025","Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2025","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2025","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2025","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2025","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2025"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity (6)","showlegend":false,"x":{"dtype":"f8","bdata":"I5BbvuFU\u002fD96BzkIy50FQF0I3psSjwJAiV4MvB0OBUDIZUmC\u002fSX+PzV4bzje2wRA"},"y":{"dtype":"f8","bdata":"OJywYxa9\u002fb8hHdrMspD4v65AjVExZvK\u002fvu4D\u002fby19L+8nGO9wpX8vzVuxdyd3vW\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2025","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2025","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value (15)","showlegend":false,"x":{"dtype":"f8","bdata":"cZ5kU3jkA0CZjS7V54gHQB3z5oOajAZAWSAJCCcYCED6wqaaOicKQKkec38cvglA9LA9gsBi\u002fT8SGyw9eVEDQEC8QrNqzJS\u002fhFU+l6hRC0DEcpvotS0IQMwtI1ek+\u002fw\u002fucCzdCmJDUCIRexUbd4AQFui+NOsiAZA"},"y":{"dtype":"f8","bdata":"Rz5zJrZ57L\u002fwyaBZWPbpv2rHWiafS\u002fC\u002fBQeu425057+CpveH2aTZv4TyCTmClu6\u002f27a1fTco\u002fL9MTquV1\u002fnwvwi0WbTeCvO\u002fk2u9v4oh3b8cWSMtS1Tpvzrz6AUqdv2\u002fYN+Tz\u002f7Y5L+FOTKiUG73v8PsNfuR0\u002fK\u002f"},"type":"scatter"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scattermap":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermap"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"font":{"size":16},"text":"Multi-label Clusters (All Years)"},"xaxis":{"range":[-4.5,4.5],"title":{"text":""},"showgrid":true,"gridcolor":"lightgray"},"yaxis":{"range":[-4.5,4.5],"title":{"text":""},"showgrid":true,"gridcolor":"lightgray","scaleanchor":"x","scaleratio":1},"height":800,"width":1000,"hovermode":"closest"},                        {"responsive": true}                    )                };            </script>        </div>
</body>
</html>