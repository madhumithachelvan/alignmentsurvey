<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />   <!--It is necessary to use the UTF-8 encoding with plotly graphics to get e.g. negative signs to render correctly -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Visualisation of Alignment Survey</title>
</head>

<body>
    <h1>Visualisation of Alignment Survey</h1>
    <h2>Papers from each year (2022-2025)</h2>
    <div>                            <div id="daab9034-7151-4eeb-bd1c-5ca2e88bdfcb" class="plotly-graph-div" style="height:700px; width:900px;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("daab9034-7151-4eeb-bd1c-5ca2e88bdfcb")) {                    Plotly.newPlot(                        "daab9034-7151-4eeb-bd1c-5ca2e88bdfcb",                        [{"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"bias","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"cultural","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"culture","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"demographics","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"diversity","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"ethical","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"factuality","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"faithfulness","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"general","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"hate","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"humor","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"language","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"legal","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"length","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"moral","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"multilingual","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"offensiveness","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"opinions","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"personalization","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"political","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"safety","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"sexism","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"social","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"toxicity","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"value","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"hoverinfo":"text","hovertext":["Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2022"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity","showlegend":false,"visible":true,"x":{"dtype":"f8","bdata":"ScuuNFmK\u002fj8="},"y":{"dtype":"f8","bdata":"IVNRFtbxBUA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general","showlegend":false,"visible":true,"x":{"dtype":"f8","bdata":"9939Dpzm8L8k+agVKTj5v99Fk9bQ\u002fvK\u002fScRx\u002fVc9+b8="},"y":{"dtype":"f8","bdata":"u57hMluYAkAlrecRCVIMQGZqXtEDlgFAxiGoBUFvAUA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral","showlegend":false,"visible":true,"x":{"dtype":"f8","bdata":"H1eDBP6QCcA="},"y":{"dtype":"f8","bdata":"GfK1DWVp7b8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization","showlegend":false,"visible":true,"x":{"dtype":"f8","bdata":"Q1rnGa8V4b8="},"y":{"dtype":"f8","bdata":"JAO2BhVsCMA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"JZolJffgCUA="},"y":{"dtype":"f8","bdata":"nD4PZ8K16z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2023"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"U7hAqdYBAEA="},"y":{"dtype":"f8","bdata":"vYHDxP0rBkA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"pOug2NITtL8="},"y":{"dtype":"f8","bdata":"jpJg8+I5BUA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"VrLqOZdM+b+rC8whJ1n0v9j1Jx23C\u002fm\u002fXL1MyaoL87\u002ffbmAY+Unyv5L5N25hKfe\u002fKg2QUAAp9b8aZCtzKjTsvx0hciZ2xeS\u002fE\u002fxRTwTM7b8yWX6uIdj1vw=="},"y":{"dtype":"f8","bdata":"1qXKyenSA0APJ8HRuXQJQHwm5VGm6QNAMAXgbuFhAkDee4oSAQoEQLSIost\u002fZgZAKwjHekl4BECKYU5uq4oFQP3EjuNGnQRAaMo\u002fGzeKBkCGbPmusd8HQA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"KliU4XdnAcA="},"y":{"dtype":"f8","bdata":"SQBmiVeF478="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"PE9ns6nk5L8="},"y":{"dtype":"f8","bdata":"RnPT\u002f0AgDMA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"VIDBbar\u002fBEDzV136o7LwPwgPP1C5Sfg\u002f5WXawT559z+NeaPI6PgAQMuruE9X5Oo\u002f+Fq3CiDo\u002fz8CRSAfzBcFQNyj89ilKfM\u002fav0NFe8n+j9qFzJWKbr4P5LUhUK1XgVAWDyTHkGD9T8DVvE+ag0IQM7mkeyADwVAEo\u002fQ8Xqw07+uHiJ\u002f4APhPx0CcuUHKQdA"},"y":{"dtype":"f8","bdata":"qEHb6kuH3L8IeSnrwCq8P3cEqzXUZ\u002fm\u002fECbqbaZb1r8i1RDNl7fGv64af\u002fpO3eK\u002fmpgeTSKKqr+QmmEj3gW2P+RgX3vMOq+\u002fPT\u002fWq4bm+7+AbKEj16P2v8ajAt+jWeg\u002fGcFGfcfUtT\u002f5M23ZzhrhPz2B3tVJ6PQ\u002fJnNVHDSK+L+KN13AusL5vzABxbNpNeM\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2024","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2024"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"9epaXnOtCUDUCyc9yw0HQNwF70CpsQVAVIDBbar\u002fBEDzV136o7LwP2lwpPfZxOY\u002fSc+gxE0kBkDLq7hPV+TqPwNW8T5qDQhAwDOEvFf63z8tLxFgH0u0PyVIJEI9h9Y\u002fHiOmImI6BkCy7YVU1cYGQNBu564Mu5e\u002f"},"y":{"dtype":"f8","bdata":"VFdOw1XM6D+TDgiApL\u002fbP0uf27heyts\u002fqEHb6kuH3L8IeSnrwCq8P4qnBTGTPNS\u002frmUHjn9r5L+uGn\u002f6Tt3iv\u002fkzbdnOGuE\u002fV102fgNy+b9IcgDu1WScP8jWG1xQJOk\u002f0Uu5XjnG0z8Vl376B0rzP9jyorgkze4\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2024","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"5n8tJMdXBUDlZdrBPnn3P415o8jo+ABA+Fq3CiDo\u002fz8CRSAfzBcFQNyj89ilKfM\u002fXjo0sUhC+z+S1IVCtV4FQB0CcuUHKQdA"},"y":{"dtype":"f8","bdata":"pXkTY3VXAUAQJuptplvWvyLVEM2Xt8a\u002fmpgeTSKKqr+QmmEj3gW2P+RgX3vMOq+\u002f3R4BewVBAEDGowLfo1noPzABxbNpNeM\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2024","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2024","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2024","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"NQLIX+ZA+j9\u002fM0kYoq33PwiGq5PooOo\u002fXjo0sUhC+z\u002fO5pHsgA8FQCVIJEI9h9Y\u002f"},"y":{"dtype":"f8","bdata":"FvjmND6lCEDo9d9FwZzBP0ISUFUbgeG\u002f3R4BewVBAEA9gd7VSej0P8jWG1xQJOk\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"19GxL0dJ2T\u002fTfyf0V7HyPw=="},"y":{"dtype":"f8","bdata":"HUEd6Qc+57\u002fG0utVWfUGQA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"SYY+FNuZ178t6N+RWRbRP1nvAFKdZ90\u002fdfBbI3+d1L\u002fqRcUqJuLBv05LwWcpQ9k\u002fQL\u002fA9Tpcdr+irPPsMfPeP3D6Sdv8Y+o\u002fWDyTHkGD9T+VGP9NYAThP4DIVjlQ+ZO\u002f0VlZm8LA1T9G5ak+dR\u002fpPzwDJWfXSdo\u002f"},"y":{"dtype":"f8","bdata":"NaG0U\u002f\u002fyB0A6D2bEFU4HQHZV4mvL9tA\u002fKuGYMhmUBkBbjJIfYlEEQAa9rbC9JAhA9NnLqTptB0B+SKk4Ht2kP7aDvMReqwpAGcFGfcfUtT+otEgkyTYJQI9eUDHYFghALaHXFx8xB0C2YVm+nYULQDFieNQL8wFA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2024","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"eK\u002fzbEkC9r8zf6chmbHvvyzumhcNm\u002fW\u002fwKFfvSy39r+Q1j3EYTD0v\u002fzB0BTxbfa\u002f1J6PrOXh87844+gl9nT6v7x1dZ7BLvC\u002fGtDTU\u002fK87r9oaNr1Fmv5v+f1kr4OyPe\u002fUbjVz4Y28799dNAcBFnxv+Q7mE7t0vG\u002fyjHpwNpP979\u002fpt3tT9vyv9h6nZOskO6\u002fAKPoecez+b9O1SwHyJb4v9W50oBLCfW\u002fv682mtg80r8fJ0TN1bnxvw=="},"y":{"dtype":"f8","bdata":"aqrQZyWUBkCyJdl3DSMDQOvcTNmc7wdA0JPAZ1CyBUBGTVKhnkgJQNAfgpoYMARAXfQkzzdlCECbwN+8kSoFQMtiYmeNGAlAL+f4P6meBkBj\u002fw1GtiMEQFDlEXh4BAdAYw6vxQ1WBEBYWapoypIIQGdN11AvOwpAO\u002fhqqtE1BUCy7d96XKEIQBhYzCAm\u002fANA\u002f8hlZJxUB0DAmDlx9jAGQLBU2BOTOAlAYwKCYjx5178o5YIEmCACQA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2024"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"jDu5tUVUtr8="},"y":{"dtype":"f8","bdata":"epbmhQnq3r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2024"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"v93xKZ18AsA="},"y":{"dtype":"f8","bdata":"YqmXuQVCAEA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2024"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"0G7nrgy7l78="},"y":{"dtype":"f8","bdata":"2PKiuCTN7j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"cm\u002fCZTPLCMDzV136o7LwP8uruE9X5Oo\u002fLS8RYB9LtD8Sj9DxerDTvyVIJEI9h9Y\u002frh4if+AD4T8UqEBY4fYFwKcBrh1buQXA"},"y":{"dtype":"f8","bdata":"IF6\u002f\u002ft\u002f+5L8IeSnrwCq8P64af\u002fpO3eK\u002fSHIA7tVknD8mc1UcNIr4v8jWG1xQJOk\u002fijddwLrC+b8cwfjneg7uv3EOP00Xa\u002fG\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"V5LDTLQcAcDAM4S8V\u002frfP0Yx9Wgp6QDA"},"y":{"dtype":"f8","bdata":"kPPs5qcN+b9XXTZ+A3L5v2kKvUJnLfS\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2024"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"cNT6QBgR+b8="},"y":{"dtype":"f8","bdata":"ubzF1WhCA8A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"5WXawT559z8ZUzDinvvgP9yj89ilKfM\u002f"},"y":{"dtype":"f8","bdata":"ECbqbaZb1r+CzS32b7sAwORgX3vMOq+\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2024","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"1pdps9bk8r9pcKT32cTmPxsPeKVYlN+\u002fXFQSN\u002f9A278IhquT6KDqP9fRsS9HSdk\u002fj0FFfM7P7L+mP9rpkhPvv9DDikhF7OS\u002f"},"y":{"dtype":"f8","bdata":"xtCizBrAC8CKpwUxkzzUv8yIPnlDOQbAHN0iGjykB8BCElBVG4Hhvx1BHekHPue\u002f5hS5CnHu\u002fb\u002fUkKAj7joIwA07+BADZQTA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2024"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"CA8\u002fULlJ+D9q\u002fQ0V7yf6P2oXMlYpuvg\u002fWDyTHkGD9T8Sj9DxerDTv7Ifcy9a5c0\u002f"},"y":{"dtype":"f8","bdata":"dwSrNdRn+b89P9arhub7v4BsoSPXo\u002fa\u002fGcFGfcfUtT8mc1UcNIr4v5q1uDz7Bw7A"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2024","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2024","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2024","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2024","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"2Ud\u002fVp8R7D9+qmTokUf0PyU3dT\u002fOOvE\u002fhoMKzl9Y8j\u002fgdlgwpe3NPxv+F1iLa+M\u002feJietk5L9D+MO7m1RVS2v1nvAFKdZ90\u002fPR2Vagxd8j+usBCAWnH0Px21+vzxT+U\u002fdpbas4v88j9\u002fM0kYoq33P9sK48JldO8\u002fiuCBvjab9j+NeaPI6PgAQEYG2QS0FPE\u002fGUzMzKa38j\u002fAx30HC8fxPzVit6A3uu0\u002fUw5\u002fnTyW3j\u002fUPppnC4\u002f2P+wfCipruOU\u002foqzz7DHz3j9uPND\u002fA7PqP8AzhLxX+t8\u002fJImldq7z8T\u002ftGVaZXvnxP+NgXZhZ9\u002fA\u002fCoyY+pst5j+nSv0hTgf\u002fP7u42iBF8Pc\u002f2wANMpME8T+\u002frzaa2DzSvxIJ9QHquPg\u002f"},"y":{"dtype":"f8","bdata":"iZHy+z+NCsCifXUn0DcFwHQTJsNq3gbA75ufZPkMBcDMdnJUVTcJwI+pYo5vFwbAeC+ssHjXCcB6luaFCerev3ZV4mvL9tA\u002fdRIe6wCHDcCLJp0JGjoIwOioyLiPRgXAjayHcwVvCsDo9d9FwZzBPxJRghHDmAPAlokD2BGCBcAi1RDNl7fGvxluJj6GhQjApos8uEeKCMDOLqpgwZMGwI6GafRyJQPAkFHRrzSNCcDVvo5yHn8KwOP0ybNGtwjAfkipOB7dpD+\u002fyh7XLuYFwFddNn4Dcvm\u002faAQUSFqkC8CiL046jjsFwE3HlIjiCgXAJMjvDWBKBsCoslblTvr\u002fv02+M8UTbgLA8gzGA0h9BsBjAoJiPHnXv1XTjNdfGgbA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"rh4if+AD4T8="},"y":{"dtype":"f8","bdata":"ijddwLrC+b8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"VIDBbar\u002fBEDixloUncEAQEnPoMRNJAZA+Fq3CiDo\u002fz8ZUzDinvvgP9fRsS9HSdk\u002fAkUgH8wXBUBq\u002fQ0V7yf6Pw=="},"y":{"dtype":"f8","bdata":"qEHb6kuH3L+v+zVuepMCwK5lB45\u002fa+S\u002fmpgeTSKKqr+CzS32b7sAwB1BHekHPue\u002fkJphI94Ftj89P9arhub7vw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2024","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"1G8ppDJgA0A6Hp+Nti0FQPnBAzEZdgRAu7jaIEXw9z+KyoPVJuoDQA=="},"y":{"dtype":"f8","bdata":"isWiTC8f+78sLV6H6XH4v3T2CILoh\u002fu\u002fTb4zxRNuAsA6g6Zd5UDuvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2024","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"p0r9IU4H\u002fz+aOxudvyYLQA=="},"y":{"dtype":"f8","bdata":"qLJW5U76\u002f78Omz7hx1P3vw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"bt3rfQsSB0A="},"y":{"dtype":"f8","bdata":"kGyHMSW7oL8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2025","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2025","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"K061Nm7fxz+UuwoAPgLTP5D+zYDuuglAHlVOuO0FAkBu3et9CxIHQJDsssdlWAJA68trbM2aBUAYBNRTDEEEQO0lA6LgugZA49p3ascZA0DogaUXiNgGQPqqQrHxlANAc5PczYQl+D\u002fyaDO24E\u002f4Pw=="},"y":{"dtype":"f8","bdata":"00BJosIvxb9O3WnuYjjgvwBoUFeM416\u002f2uMKaqBJ77+QbIcxJbugvwYGdLKAouY\u002fcPg9VKXV5z9Vx6YAZRPwP81RDGp2\u002fN8\u002fXas9k1U46T+sieJr\u002fi7MP+xNRq6t4\u002fI\u002f87zlSB4jAEAoxdqZusioPw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"FEm3i9eFCEChwEmX2jgIQEMChUrVMQRA"},"y":{"dtype":"f8","bdata":"KmO3qY9Y+T\u002fuaetzCRH7PwWXW5cpU\u002fw\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2025","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2025"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"daYAhnCJ2z\u002fQW10WR5AAQL1vxPvbjABA+52FXZafAEBt\u002fCE0rkIEQA=="},"y":{"dtype":"f8","bdata":"eBvK7Hdrtz+6KCBVAo4CQEcuchTXhAJA\u002ftH\u002ffcq6+j\u002fQPtriorTBPw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2025"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"ZCrBMkuP8j\u002f76eyx0+riPw=="},"y":{"dtype":"f8","bdata":"\u002fFLZkL+HqD+RPAapxii5vw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"8OixbNRD8D+nfAFqcA\u002fwPxy0WobHmfg\u002f8mgztuBP+D8="},"y":{"dtype":"f8","bdata":"IafSo4BtB0CaJ85gZhoJQC\u002fHisSYUghAKMXambrIqD8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2025"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"PPPkseeU6z+2eirCzvPXP0l9VmCFxMk\u002fOIC5w6GIob9zk9zNhCX4Pw=="},"y":{"dtype":"f8","bdata":"Ilk\u002fewjsCkAbzJ2ctFMLQOK3GU0lswVAbeirm02nCEDzvOVIHiMAQA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2025"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"zFyrwwv24L8="},"y":{"dtype":"f8","bdata":"iQW7hKqxBkA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2025","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"sXswhoCg8L89lW2beTb1v2YkFMGAhPG\u002foS6HeObw8b\u002f\u002fINhDmlXovykofOh0iPK\u002fsjMhlTTU9b88WjvxAdn4vzF0HxlGdvW\u002fZ7aOoewx8L\u002fKxyWWPbX2vzd0TycO9v6\u002fru8xp14o9r9a08PpGYf0v9rVzCi0U+6\u002fS1e2H\u002fj+979wXCEIpoX5v5Cypiu4i\u002fi\u002fjiCmcIav878rUxx9gyT0vzcEYknGCO6\u002f3ggB8GZJ\u002fr8NWVriXLb2v+yraBJ5qfu\u002fDFDep7x99r\u002fKXlYFfNn7v1QQpzjI6fu\u002fLV08+I8D7r8uRmkhNGb8v7qGAxmZzvi\u002fMIQzbKJm+78="},"y":{"dtype":"f8","bdata":"aS8G\u002fE3qA0DW0\u002f7sr60IQBDYlEhWywZAtWqJgi8pCEC76IR6sDsGQF9Z9cxB1QRAqfVqzmc1BUD1eA227koIQEm5p1s3sANA9\u002fx3S3XoCUBuGv9IAj4FQJE7udnRavM\u002fCyCnSzZkA0DqGjd5w+4IQN1AZFjUWAVADeUNS11xBkDc2sxd4l8DQDZleb1bMQhAONT+xkKrBkDUiYUs+p4FQNY9Hrd8HwdAi5sqZnd7BkBy7ZKOFRcDQPF6cBpoMwhA9FgP\u002fbw\u002fBUAxxbHzGZUDQDkFul\u002fysQlAY+8ub6JzA0DP+tbeN74GQDK3uFLPMwdAXJZ2B7GsCUA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"NnclkuhzCMBXD9inY8cCwFh\u002fgMexDQXA"},"y":{"dtype":"f8","bdata":"EERziKiq7j+CzYFlsoTwP\u002f7byXJu2\u002fY\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2025"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"lBzrFRl5BsA="},"y":{"dtype":"f8","bdata":"eCgjdWS42z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2025"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"N3RPJw72\u002fr8="},"y":{"dtype":"f8","bdata":"kTu52dFq8z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2025","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2025"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"MKdWg4OCCcCQu3GjqJHuvyUJ\u002f5\u002fvOwXAK061Nm7fxz9iVp5kdpYDwGXy0nkfdAjAeIx75yoTBsChiVSmvCkJwIPdnLS2BOA\u002f"},"y":{"dtype":"f8","bdata":"kSz3Be2l7b8G77rNVs38v8bMBeqg4fO\u002f00BJosIvxb\u002fAoKmANMPzv13YBlci8vG\u002f2uzP3pPc8r8SSREy7pPvvxCOFBK4+ey\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2025","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2025","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2025"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"N9Xj0Lu96r\u002fCTFSusaoFwJS7CgA+AtM\u002f"},"y":{"dtype":"f8","bdata":"d2J8gs\u002flA8DsZftRvqf+v07dae5iOOC\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2025"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"daYAhnCJ2z8="},"y":{"dtype":"f8","bdata":"eBvK7Hdrtz8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2025","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2025","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"WhYT1zbPyD\u002f76eyx0+riP0TYFgiVheW\u002fchI4OCo53r86Lg59MZ\u002fav6o4CQtMT+e\u002fJLZexDRc7r8UMqq6dh7VvzoLJQD+3ea\u002fInGg3in\u002f27\u002fA4Mahgdqpv0QzmsU6Dti\u002fPC9gwbd24L\u002fadq58V4HBvxYfFXusKua\u002fkp7mp2Vx7L\u002fkLdK5KiXLv2x8bFPbrMi\u002fabTkQZBc4r\u002fyaDO24E\u002f4Pw=="},"y":{"dtype":"f8","bdata":"rzh9cXs3BsCRPAapxii5v08en8w02QnAFhnDbbO7BsBzIjGZi\u002fgHwDvD6aRNSQjA\u002fPQ8rMCbCMAYXol7EsoIwD7PboMXwwTAEip2z8M9BsC9HddVQlcFwPlYuuzzjQjAB\u002fKGDdmVB8Ce0eaQIxUIwPHe2Dr4AQbAnnbwybktCsBaXFVD+uoDwMKdILoWxQfAlJmoyeVGB8AoxdqZusioPw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2025","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2025","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2025","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2025","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2025","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"kLtxo6iR7r831ePQu73qv1oWE9c2z8g\u002fMFZEXNrD2T9kKsEyS4\u002fyP3ZNjBxFGf4\u002fHlVOuO0FAkBj1YeDgJHzP5yhDRKTofE\u002fJPy10ZXX8j86L+zgPfPUP75PKiCIUvM\u002fgw4ksSTX7z\u002f3Kq2x\u002fdfvP7wkt3bIefM\u002fnsHb\u002fq1\u002f5D\u002f6KQqm9u\u002f9P63Sh+\u002fgQ+8\u002f2tRrLxmT6j+OA8+TccXtPyvCinq9z\u002fA\u002f\u002fWk79o5C5z8sed6Yer3iP6yn31FeegFAFIS9WILY5j9vOyA6bb\u002fmPw=="},"y":{"dtype":"f8","bdata":"Bu+6zVbN\u002fL93YnyCz+UDwK84fXF7NwbASvdzbJYCB8D8UtmQv4eoP8jKmdqx5QLA2uMKaqBJ779NKdEHQWIFwCDzMi+5YwnAZtk8ojUZC8Ao4CCOEmQFwAueHLVNTQfAeYaoE0FFCcC93lF+CjAGwJE3J9\u002f1JQfAr43Xt8aNBMDO7D3RkYf4v9huE589CAnAeEFt9kl1CsDTlmAdUmoFwEt8gSWuygfA6LXlnUBbBMBKEZL7iw0HwIUUHL2cGv2\u002fLJVwEw6rBcC9sj3ZZfEKwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2025","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"TY8vYpJvAkC\u002fLuPgaacCQIgvl++q2vo\u002faor1+0LwAECqzSBMzDsEQHCsbyr9ngFAwlsgl31q\u002fj9t\u002fCE0rkIEQA\u002fu82t70\u002f8\u002f8mgztuBP+D8="},"y":{"dtype":"f8","bdata":"BT1DS2oj\u002fL\u002fa913rQOn\u002fv3ESPQFbwP+\u002f3vQowuKH\u002f7\u002fXLk8whGUDwJXiooICFAHA2FFk2TI6\u002fb\u002fQPtriorTBP\u002fh7UT2rI\u002fy\u002fKMXambrIqD8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2025"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"dk2MHEUZ\u002fj8="},"y":{"dtype":"f8","bdata":"yMqZ2rHlAsA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2025","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"llWVR0s2DECQ9JdpjUcIQHTN04LkgwZAzMBIj45hBUB5VpXQHQYPQCZ7cJg8igRA+ikKpvbv\u002fT\u002fiinHCujIIQIPdnLS2BOA\u002fDCAeexfFB0BB64XOaysJQKyn31FeegFADAfTUkL3B0A="},"y":{"dtype":"f8","bdata":"KqJ3FkEy8L\u002f4kO+ZUcbjv2sYL9IG5Om\u002f5TiZdZm45b\u002faTua5Az7qvwePeiwrtuK\u002fzuw90ZGH+L9zkLOpEWzwvxCOFBK4+ey\u002fpwlp\u002fOX587\u002f5Pu8BXULtv4UUHL2cGv2\u002fgGWt\u002fHIK7r8="},"type":"scatter"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scattermap":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermap"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"font":{"size":16},"text":"Multi-label Clusters for each Year"},"xaxis":{"range":[-4.5,4.5],"title":{"text":""},"showgrid":true,"gridcolor":"lightgray"},"yaxis":{"range":[-4.5,4.5],"title":{"text":""},"showgrid":true,"gridcolor":"lightgray","scaleanchor":"x","scaleratio":1},"height":700,"width":900,"hovermode":"closest","sliders":[{"active":0,"currentvalue":{"prefix":"Year: ","visible":true,"xanchor":"center"},"len":0.9,"pad":{"b":10,"t":50},"steps":[{"args":[{"visible":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false]}],"label":"2022","method":"update"},{"args":[{"visible":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false]}],"label":"2023","method":"update"},{"args":[{"visible":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false]}],"label":"2024","method":"update"},{"args":[{"visible":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true]}],"label":"2025","method":"update"}],"x":0.0,"xanchor":"left","y":-0.1,"yanchor":"top"}],"showlegend":true},                        {"responsive": true}                    )                };            </script>        </div>
    <br>    
    <h2>All papers</h2>
    <div>                        <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.3.1.min.js" integrity="sha256-4rD3fugVb/nVJYUv5Ky3v+fYXoouHaBSP20WIJuEiWg=" crossorigin="anonymous"></script>                <div id="6a5447ee-7fa3-4a5f-9af9-4cacabf7cefe" class="plotly-graph-div" style="height:800px; width:1000px;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("6a5447ee-7fa3-4a5f-9af9-4cacabf7cefe")) {                    Plotly.newPlot(                        "6a5447ee-7fa3-4a5f-9af9-4cacabf7cefe",                        [{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2022","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2022","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2022","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2022","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2022","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2022","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2022","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2022","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2022","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2022","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2022","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2022","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2022"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias (19)","showlegend":true,"x":{"dtype":"f8","bdata":"bt3rfQsSB0BUgMFtqv8EQPNXXfqjsvA\u002fCA8\u002fULlJ+D\u002flZdrBPnn3P415o8jo+ABAy6u4T1fk6j\u002f4WrcKIOj\u002fPwJFIB\u002fMFwVA3KPz2KUp8z9q\u002fQ0V7yf6P2oXMlYpuvg\u002fktSFQrVeBUBYPJMeQYP1PwNW8T5qDQhAzuaR7IAPBUASj9DxerDTv64eIn\u002fgA+E\u002fHQJy5QcpB0A="},"y":{"dtype":"f8","bdata":"kGyHMSW7oL+oQdvqS4fcvwh5KevAKrw\u002fdwSrNdRn+b8QJuptplvWvyLVEM2Xt8a\u002frhp\u002f+k7d4r+amB5NIoqqv5CaYSPeBbY\u002f5GBfe8w6r789P9arhub7v4BsoSPXo\u002fa\u002fxqMC36NZ6D8ZwUZ9x9S1P\u002fkzbdnOGuE\u002fPYHe1Uno9D8mc1UcNIr4v4o3XcC6wvm\u002fMAHFs2k14z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2022","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2022","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2022","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2022","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2022","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2022","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2022","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2022","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2022","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2022","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2022","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2022","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2022","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2022"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural (30)","showlegend":true,"x":{"dtype":"f8","bdata":"K061Nm7fxz+UuwoAPgLTP5D+zYDuuglAHlVOuO0FAkBu3et9CxIHQJDsssdlWAJA68trbM2aBUAYBNRTDEEEQPXqWl5zrQlA1AsnPcsNB0DcBe9AqbEFQCWaJSX34AlAVIDBbar\u002fBEDzV136o7LwP2lwpPfZxOY\u002fSc+gxE0kBkDLq7hPV+TqPwNW8T5qDQhAwDOEvFf63z8tLxFgH0u0PyVIJEI9h9Y\u002f7SUDouC6BkDj2ndqxxkDQOiBpReI2AZA+qpCsfGUA0Bzk9zNhCX4P\u002fJoM7bgT\u002fg\u002fHiOmImI6BkCy7YVU1cYGQNBu564Mu5e\u002f"},"y":{"dtype":"f8","bdata":"00BJosIvxb9O3WnuYjjgvwBoUFeM416\u002f2uMKaqBJ77+QbIcxJbugvwYGdLKAouY\u002fcPg9VKXV5z9Vx6YAZRPwP1RXTsNVzOg\u002fkw4IgKS\u002f2z9Ln9u4XsrbP5w+D2fCtes\u002fqEHb6kuH3L8IeSnrwCq8P4qnBTGTPNS\u002frmUHjn9r5L+uGn\u002f6Tt3iv\u002fkzbdnOGuE\u002fV102fgNy+b9IcgDu1WScP8jWG1xQJOk\u002fzVEManb83z9dqz2TVTjpP6yJ4mv+Lsw\u002f7E1Grq3j8j\u002fzvOVIHiMAQCjF2pm6yKg\u002f0Uu5XjnG0z8Vl376B0rzP9jyorgkze4\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2022","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2022","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2022"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture (3)","showlegend":true,"x":{"dtype":"f8","bdata":"FEm3i9eFCEChwEmX2jgIQEMChUrVMQRA"},"y":{"dtype":"f8","bdata":"KmO3qY9Y+T\u002fuaetzCRH7PwWXW5cpU\u002fw\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2022","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2022","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2022","Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2022","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2022","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2022","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2022","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2022","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2022","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2022"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics (14)","showlegend":true,"x":{"dtype":"f8","bdata":"daYAhnCJ2z\u002fQW10WR5AAQL1vxPvbjABA5n8tJMdXBUDlZdrBPnn3P415o8jo+ABA+Fq3CiDo\u002fz8CRSAfzBcFQNyj89ilKfM\u002fXjo0sUhC+z+S1IVCtV4FQB0CcuUHKQdA+52FXZafAEBt\u002fCE0rkIEQA=="},"y":{"dtype":"f8","bdata":"eBvK7Hdrtz+6KCBVAo4CQEcuchTXhAJApXkTY3VXAUAQJuptplvWvyLVEM2Xt8a\u002fmpgeTSKKqr+QmmEj3gW2P+RgX3vMOq+\u002f3R4BewVBAEDGowLfo1noPzABxbNpNeM\u002f\u002ftH\u002ffcq6+j\u002fQPtriorTBPw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2022","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2022","Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2022","Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2022","Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2022","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2022","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2022","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2022","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2022","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2022"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity (10)","showlegend":true,"x":{"dtype":"f8","bdata":"ZCrBMkuP8j\u002f76eyx0+riPzUCyF\u002fmQPo\u002fU7hAqdYBAEBJy640WYr+P38zSRiirfc\u002fCIark+ig6j9eOjSxSEL7P87mkeyADwVAJUgkQj2H1j8="},"y":{"dtype":"f8","bdata":"\u002fFLZkL+HqD+RPAapxii5vxb45jQ+pQhAvYHDxP0rBkAhU1EW1vEFQOj130XBnME\u002fQhJQVRuB4b\u002fdHgF7BUEAQD2B3tVJ6PQ\u002fyNYbXFAk6T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2022","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2022","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2022","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2022","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2022","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2022"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical (6)","showlegend":true,"x":{"dtype":"f8","bdata":"8OixbNRD8D+nfAFqcA\u002fwPxy0WobHmfg\u002f19GxL0dJ2T\u002fyaDO24E\u002f4P9N\u002fJ\u002fRXsfI\u002f"},"y":{"dtype":"f8","bdata":"IafSo4BtB0CaJ85gZhoJQC\u002fHisSYUghAHUEd6Qc+578oxdqZusioP8bS61VZ9QZA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2022","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2022","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2022","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2022","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality (21)","showlegend":true,"x":{"dtype":"f8","bdata":"PPPkseeU6z+2eirCzvPXP6TroNjSE7S\u002fSYY+FNuZ178t6N+RWRbRP1nvAFKdZ90\u002fdfBbI3+d1L\u002fqRcUqJuLBv05LwWcpQ9k\u002fQL\u002fA9Tpcdr+irPPsMfPeP3D6Sdv8Y+o\u002fWDyTHkGD9T+VGP9NYAThP4DIVjlQ+ZO\u002f0VlZm8LA1T9G5ak+dR\u002fpP0l9VmCFxMk\u002fOIC5w6GIob9zk9zNhCX4PzwDJWfXSdo\u002f"},"y":{"dtype":"f8","bdata":"Ilk\u002fewjsCkAbzJ2ctFMLQI6SYPPiOQVANaG0U\u002f\u002fyB0A6D2bEFU4HQHZV4mvL9tA\u002fKuGYMhmUBkBbjJIfYlEEQAa9rbC9JAhA9NnLqTptB0B+SKk4Ht2kP7aDvMReqwpAGcFGfcfUtT+otEgkyTYJQI9eUDHYFghALaHXFx8xB0C2YVm+nYULQOK3GU0lswVAbeirm02nCEDzvOVIHiMAQDFieNQL8wFA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2022"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness (1)","showlegend":true,"x":{"dtype":"f8","bdata":"zFyrwwv24L8="},"y":{"dtype":"f8","bdata":"iQW7hKqxBkA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2022","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2022","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general (69)","showlegend":true,"x":{"dtype":"f8","bdata":"sXswhoCg8L89lW2beTb1v2YkFMGAhPG\u002foS6HeObw8b\u002f\u002fINhDmlXovykofOh0iPK\u002fsjMhlTTU9b88WjvxAdn4v3iv82xJAva\u002fM3+nIZmx778s7poXDZv1v8ChX70st\u002fa\u002fkNY9xGEw9L\u002f8wdAU8W32v9Sej6zl4fO\u002fOOPoJfZ0+r+8dXWewS7wv1ay6jmXTPm\u002fqwvMISdZ9L\u002fY9Scdtwv5v1y9TMmqC\u002fO\u002f325gGPlJ8r+S+TduYSn3vyoNkFAAKfW\u002fGmQrcyo07L8dIXImdsXkvxP8UU8EzO2\u002fMll+riHY9b\u002f33f0OnObwvyT5qBUpOPm\u002f30WT1tD+8r9JxHH9Vz35vxrQ01PyvO6\u002faGja9RZr+b\u002fn9ZK+Dsj3v1G41c+GNvO\u002ffXTQHARZ8b\u002fkO5hO7dLxv8ox6cDaT\u002fe\u002ff6bd7U\u002fb8r\u002fYep2TrJDuvwCj6HnHs\u002fm\u002fMXQfGUZ29b9nto6h7DHwv8rHJZY9tfa\u002fN3RPJw72\u002fr+u7zGnXij2v1rTw+kZh\u002fS\u002f2tXMKLRT7r9LV7Yf+P73v3BcIQimhfm\u002fkLKmK7iL+L+OIKZwhq\u002fzvytTHH2DJPS\u002fNwRiScYI7r\u002feCAHwZkn+vw1ZWuJctva\u002f7KtoEnmp+78MUN6nvH32v8peVgV82fu\u002fVBCnOMjp+78tXTz4jwPuvy5GaSE0Zvy\u002fuoYDGZnO+L8whDNsomb7v07VLAfIlvi\u002f1bnSgEsJ9b+\u002frzaa2DzSvx8nRM3VufG\u002f"},"y":{"dtype":"f8","bdata":"aS8G\u002fE3qA0DW0\u002f7sr60IQBDYlEhWywZAtWqJgi8pCEC76IR6sDsGQF9Z9cxB1QRAqfVqzmc1BUD1eA227koIQGqq0GcllAZAsiXZdw0jA0Dr3EzZnO8HQNCTwGdQsgVARk1SoZ5ICUDQH4KaGDAEQF30JM83ZQhAm8DfvJEqBUDLYmJnjRgJQNalysnp0gNADyfB0bl0CUB8JuVRpukDQDAF4G7hYQJA3nuKEgEKBEC0iKLLf2YGQCsIx3pJeARAimFObquKBUD9xI7jRp0EQGjKPxs3igZAhmz5rrHfB0C7nuEyW5gCQCWt5xEJUgxAZmpe0QOWAUDGIagFQW8BQC\u002fn+D+pngZAY\u002f8NRrYjBEBQ5RF4eAQHQGMOr8UNVgRAWFmqaMqSCEBnTddQLzsKQDv4aqrRNQVAsu3felyhCEAYWMwgJvwDQP\u002fIZWScVAdASbmnWzewA0D3\u002fHdLdegJQG4a\u002f0gCPgVAkTu52dFq8z8LIKdLNmQDQOoaN3nD7ghA3UBkWNRYBUAN5Q1LXXEGQNzazF3iXwNANmV5vVsxCEA41P7GQqsGQNSJhSz6ngVA1j0et3wfB0CLmypmd3sGQHLtko4VFwNA8XpwGmgzCED0WA\u002f9vD8FQDHFsfMZlQNAOQW6X\u002fKxCUBj7y5vonMDQM\u002f61t43vgZAMre4Us8zB0BclnYHsawJQMCYOXH2MAZAsFTYE5M4CUBjAoJiPHnXvyjlggSYIAJA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2022"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate (1)","showlegend":true,"x":{"dtype":"f8","bdata":"jDu5tUVUtr8="},"y":{"dtype":"f8","bdata":"epbmhQnq3r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2022"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor (1)","showlegend":true,"x":{"dtype":"f8","bdata":"v93xKZ18AsA="},"y":{"dtype":"f8","bdata":"YqmXuQVCAEA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2022","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2022","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2022","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2022"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language (4)","showlegend":true,"x":{"dtype":"f8","bdata":"NnclkuhzCMBXD9inY8cCwFh\u002fgMexDQXA0G7nrgy7l78="},"y":{"dtype":"f8","bdata":"EERziKiq7j+CzYFlsoTwP\u002f7byXJu2\u002fY\u002f2PKiuCTN7j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2022"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal (1)","showlegend":true,"x":{"dtype":"f8","bdata":"lBzrFRl5BsA="},"y":{"dtype":"f8","bdata":"eCgjdWS42z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2022"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length (1)","showlegend":true,"x":{"dtype":"f8","bdata":"N3RPJw72\u002fr8="},"y":{"dtype":"f8","bdata":"kTu52dFq8z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2022","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2022","Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2022","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2022","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2022","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2022","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2022","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral (20)","showlegend":true,"x":{"dtype":"f8","bdata":"MKdWg4OCCcCQu3GjqJHuvyUJ\u002f5\u002fvOwXAK061Nm7fxz9yb8JlM8sIwCpYlOF3ZwHAH1eDBP6QCcDzV136o7LwP8uruE9X5Oo\u002fLS8RYB9LtD8Sj9DxerDTvyVIJEI9h9Y\u002frh4if+AD4T9iVp5kdpYDwGXy0nkfdAjAeIx75yoTBsChiVSmvCkJwIPdnLS2BOA\u002fFKhAWOH2BcCnAa4dW7kFwA=="},"y":{"dtype":"f8","bdata":"kSz3Be2l7b8G77rNVs38v8bMBeqg4fO\u002f00BJosIvxb8gXr\u002f+3\u002f7kv0kAZolXheO\u002fGfK1DWVp7b8IeSnrwCq8P64af\u002fpO3eK\u002fSHIA7tVknD8mc1UcNIr4v8jWG1xQJOk\u002fijddwLrC+b\u002fAoKmANMPzv13YBlci8vG\u002f2uzP3pPc8r8SSREy7pPvvxCOFBK4+ey\u002fHMH453oO7r9xDj9NF2vxvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2022","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2022","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2022","Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2022","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2022","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2022"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual (6)","showlegend":true,"x":{"dtype":"f8","bdata":"N9Xj0Lu96r\u002fCTFSusaoFwJS7CgA+AtM\u002fV5LDTLQcAcDAM4S8V\u002frfP0Yx9Wgp6QDA"},"y":{"dtype":"f8","bdata":"d2J8gs\u002flA8DsZftRvqf+v07dae5iOOC\u002fkPPs5qcN+b9XXTZ+A3L5v2kKvUJnLfS\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2022"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness (1)","showlegend":true,"x":{"dtype":"f8","bdata":"cNT6QBgR+b8="},"y":{"dtype":"f8","bdata":"ubzF1WhCA8A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2022","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2022","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions (4)","showlegend":true,"x":{"dtype":"f8","bdata":"daYAhnCJ2z\u002flZdrBPnn3PxlTMOKe++A\u002f3KPz2KUp8z8="},"y":{"dtype":"f8","bdata":"eBvK7Hdrtz8QJuptplvWv4LNLfZvuwDA5GBfe8w6r78="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2022","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2022","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2022","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2022","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2022","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2022","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization (31)","showlegend":true,"x":{"dtype":"f8","bdata":"WhYT1zbPyD\u002f76eyx0+riP0TYFgiVheW\u002f1pdps9bk8r88T2ezqeTkv0Na5xmvFeG\u002faXCk99nE5j8bD3ilWJTfv1xUEjf\u002fQNu\u002fCIark+ig6j\u002fX0bEvR0nZP49BRXzOz+y\u002fpj\u002fa6ZIT779yEjg4KjnevzouDn0xn9q\u002fqjgJC0xP578ktl7ENFzuvxQyqrp2HtW\u002fOgslAP7d5r8icaDeKf\u002fbv8DgxqGB2qm\u002fRDOaxToO2L88L2DBt3bgv9p2rnxXgcG\u002fFh8Ve6wq5r+SnuanZXHsv+Qt0rkqJcu\u002fbHxsU9usyL9ptORBkFziv\u002fJoM7bgT\u002fg\u002f0MOKSEXs5L8="},"y":{"dtype":"f8","bdata":"rzh9cXs3BsCRPAapxii5v08en8w02QnAxtCizBrAC8BGc9P\u002fQCAMwCQDtgYVbAjAiqcFMZM81L\u002fMiD55QzkGwBzdIho8pAfAQhJQVRuB4b8dQR3pBz7nv+YUuQpx7v2\u002f1JCgI+46CMAWGcNts7sGwHMiMZmL+AfAO8PppE1JCMD89DyswJsIwBheiXsSygjAPs9ugxfDBMASKnbPwz0GwL0d11VCVwXA+Vi67PONCMAH8oYN2ZUHwJ7R5pAjFQjA8d7YOvgBBsCedvDJuS0KwFpcVUP66gPAwp0guhbFB8CUmajJ5UYHwCjF2pm6yKg\u002fDTv4EANlBMA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2022","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2022","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2022","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2022","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2022","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2022"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political (6)","showlegend":true,"x":{"dtype":"f8","bdata":"CA8\u002fULlJ+D9q\u002fQ0V7yf6P2oXMlYpuvg\u002fWDyTHkGD9T8Sj9DxerDTv7Ifcy9a5c0\u002f"},"y":{"dtype":"f8","bdata":"dwSrNdRn+b89P9arhub7v4BsoSPXo\u002fa\u002fGcFGfcfUtT8mc1UcNIr4v5q1uDz7Bw7A"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2022","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2022","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2022","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2022","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2022","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2022","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2022","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2022","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2022","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2022","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2022","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2022","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2022","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2022","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2022","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2022","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2022","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety (62)","showlegend":true,"x":{"dtype":"f8","bdata":"kLtxo6iR7r831ePQu73qv1oWE9c2z8g\u002fMFZEXNrD2T9kKsEyS4\u002fyP3ZNjBxFGf4\u002fHlVOuO0FAkBj1YeDgJHzP5yhDRKTofE\u002f2Ud\u002fVp8R7D9+qmTokUf0PyU3dT\u002fOOvE\u002fhoMKzl9Y8j\u002fgdlgwpe3NPxv+F1iLa+M\u002feJietk5L9D+MO7m1RVS2v1nvAFKdZ90\u002fPR2Vagxd8j+usBCAWnH0Px21+vzxT+U\u002fdpbas4v88j9\u002fM0kYoq33P9sK48JldO8\u002fiuCBvjab9j+NeaPI6PgAQEYG2QS0FPE\u002fGUzMzKa38j\u002fAx30HC8fxPzVit6A3uu0\u002fUw5\u002fnTyW3j\u002fUPppnC4\u002f2P+wfCipruOU\u002foqzz7DHz3j9uPND\u002fA7PqP8AzhLxX+t8\u002fJImldq7z8T\u002ftGVaZXvnxPyT8tdGV1\u002fI\u002fOi\u002fs4D3z1D++TyogiFLzP4MOJLEk1+8\u002f9yqtsf3X7z+8JLd2yHnzP57B2\u002f6tf+Q\u002f+ikKpvbv\u002fT+t0ofv4EPvP9rUay8Zk+o\u002fjgPPk3HF7T8rwop6vc\u002fwP\u002f1pO\u002faOQuc\u002fLHnemHq94j+sp99RXnoBQBSEvViC2OY\u002fbzsgOm2\u002f5j\u002fjYF2YWffwPwqMmPqbLeY\u002fp0r9IU4H\u002fz+7uNogRfD3P9sADTKTBPE\u002fv682mtg80r8SCfUB6rj4Pw=="},"y":{"dtype":"f8","bdata":"Bu+6zVbN\u002fL93YnyCz+UDwK84fXF7NwbASvdzbJYCB8D8UtmQv4eoP8jKmdqx5QLA2uMKaqBJ779NKdEHQWIFwCDzMi+5YwnAiZHy+z+NCsCifXUn0DcFwHQTJsNq3gbA75ufZPkMBcDMdnJUVTcJwI+pYo5vFwbAeC+ssHjXCcB6luaFCerev3ZV4mvL9tA\u002fdRIe6wCHDcCLJp0JGjoIwOioyLiPRgXAjayHcwVvCsDo9d9FwZzBPxJRghHDmAPAlokD2BGCBcAi1RDNl7fGvxluJj6GhQjApos8uEeKCMDOLqpgwZMGwI6GafRyJQPAkFHRrzSNCcDVvo5yHn8KwOP0ybNGtwjAfkipOB7dpD+\u002fyh7XLuYFwFddNn4Dcvm\u002faAQUSFqkC8CiL046jjsFwGbZPKI1GQvAKOAgjhJkBcALnhy1TU0HwHmGqBNBRQnAvd5RfgowBsCRNyff9SUHwK+N17fGjQTAzuw90ZGH+L\u002fYbhOfPQgJwHhBbfZJdQrA05ZgHVJqBcBLfIElrsoHwOi15Z1AWwTAShGS+4sNB8CFFBy9nBr9vyyVcBMOqwXAvbI92WXxCsBNx5SI4goFwCTI7w1gSgbAqLJW5U76\u002f79NvjPFE24CwPIMxgNIfQbAYwKCYjx5179V04zXXxoGwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2022"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism (1)","showlegend":true,"x":{"dtype":"f8","bdata":"rh4if+AD4T8="},"y":{"dtype":"f8","bdata":"ijddwLrC+b8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2022","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2022","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2022","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2022","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2022","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2022","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2022"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social (18)","showlegend":true,"x":{"dtype":"f8","bdata":"TY8vYpJvAkC\u002fLuPgaacCQIgvl++q2vo\u002faor1+0LwAECqzSBMzDsEQFSAwW2q\u002fwRA4sZaFJ3BAEBJz6DETSQGQPhatwog6P8\u002fGVMw4p774D\u002fX0bEvR0nZPwJFIB\u002fMFwVAav0NFe8n+j9wrG8q\u002fZ4BQMJbIJd9av4\u002fbfwhNK5CBEAP7vNre9P\u002fP\u002fJoM7bgT\u002fg\u002f"},"y":{"dtype":"f8","bdata":"BT1DS2oj\u002fL\u002fa913rQOn\u002fv3ESPQFbwP+\u002f3vQowuKH\u002f7\u002fXLk8whGUDwKhB2+pLh9y\u002fr\u002fs1bnqTAsCuZQeOf2vkv5qYHk0iiqq\u002fgs0t9m+7AMAdQR3pBz7nv5CaYSPeBbY\u002fPT\u002fWq4bm+7+V4qKCAhQBwNhRZNkyOv2\u002f0D7a4qK0wT\u002f4e1E9qyP8vyjF2pm6yKg\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2022","Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2022","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2022","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2022","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2022","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2022"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity (6)","showlegend":true,"x":{"dtype":"f8","bdata":"dk2MHEUZ\u002fj\u002fUbymkMmADQDoen422LQVA+cEDMRl2BEC7uNogRfD3P4rKg9Um6gNA"},"y":{"dtype":"f8","bdata":"yMqZ2rHlAsCKxaJMLx\u002f7vywtXofpcfi\u002fdPYIguiH+79NvjPFE24CwDqDpl3lQO6\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2022","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2022","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2022","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2022","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value (15)","showlegend":true,"x":{"dtype":"f8","bdata":"llWVR0s2DECQ9JdpjUcIQHTN04LkgwZAzMBIj45hBUB5VpXQHQYPQCZ7cJg8igRA+ikKpvbv\u002fT\u002fiinHCujIIQIPdnLS2BOA\u002fDCAeexfFB0BB64XOaysJQKyn31FeegFADAfTUkL3B0CnSv0hTgf\u002fP5o7G52\u002fJgtA"},"y":{"dtype":"f8","bdata":"KqJ3FkEy8L\u002f4kO+ZUcbjv2sYL9IG5Om\u002f5TiZdZm45b\u002faTua5Az7qvwePeiwrtuK\u002fzuw90ZGH+L9zkLOpEWzwvxCOFBK4+ey\u002fpwlp\u002fOX587\u002f5Pu8BXULtv4UUHL2cGv2\u002fgGWt\u002fHIK7r+oslblTvr\u002fvw6bPuHHU\u002fe\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2023","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2023","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2023","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2023","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2023","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2023","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2023","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2023","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2023","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2023","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2023","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2023"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias (19)","showlegend":false,"x":{"dtype":"f8","bdata":"bt3rfQsSB0BUgMFtqv8EQPNXXfqjsvA\u002fCA8\u002fULlJ+D\u002flZdrBPnn3P415o8jo+ABAy6u4T1fk6j\u002f4WrcKIOj\u002fPwJFIB\u002fMFwVA3KPz2KUp8z9q\u002fQ0V7yf6P2oXMlYpuvg\u002fktSFQrVeBUBYPJMeQYP1PwNW8T5qDQhAzuaR7IAPBUASj9DxerDTv64eIn\u002fgA+E\u002fHQJy5QcpB0A="},"y":{"dtype":"f8","bdata":"kGyHMSW7oL+oQdvqS4fcvwh5KevAKrw\u002fdwSrNdRn+b8QJuptplvWvyLVEM2Xt8a\u002frhp\u002f+k7d4r+amB5NIoqqv5CaYSPeBbY\u002f5GBfe8w6r789P9arhub7v4BsoSPXo\u002fa\u002fxqMC36NZ6D8ZwUZ9x9S1P\u002fkzbdnOGuE\u002fPYHe1Uno9D8mc1UcNIr4v4o3XcC6wvm\u002fMAHFs2k14z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2023","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2023","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2023","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2023","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2023","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2023","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2023","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2023","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2023","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2023","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2023","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2023","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2023"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural (30)","showlegend":false,"x":{"dtype":"f8","bdata":"K061Nm7fxz+UuwoAPgLTP5D+zYDuuglAHlVOuO0FAkBu3et9CxIHQJDsssdlWAJA68trbM2aBUAYBNRTDEEEQPXqWl5zrQlA1AsnPcsNB0DcBe9AqbEFQCWaJSX34AlAVIDBbar\u002fBEDzV136o7LwP2lwpPfZxOY\u002fSc+gxE0kBkDLq7hPV+TqPwNW8T5qDQhAwDOEvFf63z8tLxFgH0u0PyVIJEI9h9Y\u002f7SUDouC6BkDj2ndqxxkDQOiBpReI2AZA+qpCsfGUA0Bzk9zNhCX4P\u002fJoM7bgT\u002fg\u002fHiOmImI6BkCy7YVU1cYGQNBu564Mu5e\u002f"},"y":{"dtype":"f8","bdata":"00BJosIvxb9O3WnuYjjgvwBoUFeM416\u002f2uMKaqBJ77+QbIcxJbugvwYGdLKAouY\u002fcPg9VKXV5z9Vx6YAZRPwP1RXTsNVzOg\u002fkw4IgKS\u002f2z9Ln9u4XsrbP5w+D2fCtes\u002fqEHb6kuH3L8IeSnrwCq8P4qnBTGTPNS\u002frmUHjn9r5L+uGn\u002f6Tt3iv\u002fkzbdnOGuE\u002fV102fgNy+b9IcgDu1WScP8jWG1xQJOk\u002fzVEManb83z9dqz2TVTjpP6yJ4mv+Lsw\u002f7E1Grq3j8j\u002fzvOVIHiMAQCjF2pm6yKg\u002f0Uu5XjnG0z8Vl376B0rzP9jyorgkze4\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2023","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2023","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2023"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture (3)","showlegend":false,"x":{"dtype":"f8","bdata":"FEm3i9eFCEChwEmX2jgIQEMChUrVMQRA"},"y":{"dtype":"f8","bdata":"KmO3qY9Y+T\u002fuaetzCRH7PwWXW5cpU\u002fw\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2023","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2023","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2023","Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2023","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2023","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2023","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2023","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2023","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2023","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2023"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics (14)","showlegend":false,"x":{"dtype":"f8","bdata":"daYAhnCJ2z\u002fQW10WR5AAQL1vxPvbjABA5n8tJMdXBUDlZdrBPnn3P415o8jo+ABA+Fq3CiDo\u002fz8CRSAfzBcFQNyj89ilKfM\u002fXjo0sUhC+z+S1IVCtV4FQB0CcuUHKQdA+52FXZafAEBt\u002fCE0rkIEQA=="},"y":{"dtype":"f8","bdata":"eBvK7Hdrtz+6KCBVAo4CQEcuchTXhAJApXkTY3VXAUAQJuptplvWvyLVEM2Xt8a\u002fmpgeTSKKqr+QmmEj3gW2P+RgX3vMOq+\u002f3R4BewVBAEDGowLfo1noPzABxbNpNeM\u002f\u002ftH\u002ffcq6+j\u002fQPtriorTBPw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2023","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2023","Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2023","Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2023","Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2023","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2023","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2023","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2023","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2023","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2023"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity (10)","showlegend":false,"x":{"dtype":"f8","bdata":"ZCrBMkuP8j\u002f76eyx0+riPzUCyF\u002fmQPo\u002fU7hAqdYBAEBJy640WYr+P38zSRiirfc\u002fCIark+ig6j9eOjSxSEL7P87mkeyADwVAJUgkQj2H1j8="},"y":{"dtype":"f8","bdata":"\u002fFLZkL+HqD+RPAapxii5vxb45jQ+pQhAvYHDxP0rBkAhU1EW1vEFQOj130XBnME\u002fQhJQVRuB4b\u002fdHgF7BUEAQD2B3tVJ6PQ\u002fyNYbXFAk6T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2023","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2023","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2023","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2023","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2023","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2023"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical (6)","showlegend":false,"x":{"dtype":"f8","bdata":"8OixbNRD8D+nfAFqcA\u002fwPxy0WobHmfg\u002f19GxL0dJ2T\u002fyaDO24E\u002f4P9N\u002fJ\u002fRXsfI\u002f"},"y":{"dtype":"f8","bdata":"IafSo4BtB0CaJ85gZhoJQC\u002fHisSYUghAHUEd6Qc+578oxdqZusioP8bS61VZ9QZA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2023","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2023","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2023","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2023","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality (21)","showlegend":false,"x":{"dtype":"f8","bdata":"PPPkseeU6z+2eirCzvPXP6TroNjSE7S\u002fSYY+FNuZ178t6N+RWRbRP1nvAFKdZ90\u002fdfBbI3+d1L\u002fqRcUqJuLBv05LwWcpQ9k\u002fQL\u002fA9Tpcdr+irPPsMfPeP3D6Sdv8Y+o\u002fWDyTHkGD9T+VGP9NYAThP4DIVjlQ+ZO\u002f0VlZm8LA1T9G5ak+dR\u002fpP0l9VmCFxMk\u002fOIC5w6GIob9zk9zNhCX4PzwDJWfXSdo\u002f"},"y":{"dtype":"f8","bdata":"Ilk\u002fewjsCkAbzJ2ctFMLQI6SYPPiOQVANaG0U\u002f\u002fyB0A6D2bEFU4HQHZV4mvL9tA\u002fKuGYMhmUBkBbjJIfYlEEQAa9rbC9JAhA9NnLqTptB0B+SKk4Ht2kP7aDvMReqwpAGcFGfcfUtT+otEgkyTYJQI9eUDHYFghALaHXFx8xB0C2YVm+nYULQOK3GU0lswVAbeirm02nCEDzvOVIHiMAQDFieNQL8wFA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2023"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"zFyrwwv24L8="},"y":{"dtype":"f8","bdata":"iQW7hKqxBkA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2023","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2023","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general (69)","showlegend":false,"x":{"dtype":"f8","bdata":"sXswhoCg8L89lW2beTb1v2YkFMGAhPG\u002foS6HeObw8b\u002f\u002fINhDmlXovykofOh0iPK\u002fsjMhlTTU9b88WjvxAdn4v3iv82xJAva\u002fM3+nIZmx778s7poXDZv1v8ChX70st\u002fa\u002fkNY9xGEw9L\u002f8wdAU8W32v9Sej6zl4fO\u002fOOPoJfZ0+r+8dXWewS7wv1ay6jmXTPm\u002fqwvMISdZ9L\u002fY9Scdtwv5v1y9TMmqC\u002fO\u002f325gGPlJ8r+S+TduYSn3vyoNkFAAKfW\u002fGmQrcyo07L8dIXImdsXkvxP8UU8EzO2\u002fMll+riHY9b\u002f33f0OnObwvyT5qBUpOPm\u002f30WT1tD+8r9JxHH9Vz35vxrQ01PyvO6\u002faGja9RZr+b\u002fn9ZK+Dsj3v1G41c+GNvO\u002ffXTQHARZ8b\u002fkO5hO7dLxv8ox6cDaT\u002fe\u002ff6bd7U\u002fb8r\u002fYep2TrJDuvwCj6HnHs\u002fm\u002fMXQfGUZ29b9nto6h7DHwv8rHJZY9tfa\u002fN3RPJw72\u002fr+u7zGnXij2v1rTw+kZh\u002fS\u002f2tXMKLRT7r9LV7Yf+P73v3BcIQimhfm\u002fkLKmK7iL+L+OIKZwhq\u002fzvytTHH2DJPS\u002fNwRiScYI7r\u002feCAHwZkn+vw1ZWuJctva\u002f7KtoEnmp+78MUN6nvH32v8peVgV82fu\u002fVBCnOMjp+78tXTz4jwPuvy5GaSE0Zvy\u002fuoYDGZnO+L8whDNsomb7v07VLAfIlvi\u002f1bnSgEsJ9b+\u002frzaa2DzSvx8nRM3VufG\u002f"},"y":{"dtype":"f8","bdata":"aS8G\u002fE3qA0DW0\u002f7sr60IQBDYlEhWywZAtWqJgi8pCEC76IR6sDsGQF9Z9cxB1QRAqfVqzmc1BUD1eA227koIQGqq0GcllAZAsiXZdw0jA0Dr3EzZnO8HQNCTwGdQsgVARk1SoZ5ICUDQH4KaGDAEQF30JM83ZQhAm8DfvJEqBUDLYmJnjRgJQNalysnp0gNADyfB0bl0CUB8JuVRpukDQDAF4G7hYQJA3nuKEgEKBEC0iKLLf2YGQCsIx3pJeARAimFObquKBUD9xI7jRp0EQGjKPxs3igZAhmz5rrHfB0C7nuEyW5gCQCWt5xEJUgxAZmpe0QOWAUDGIagFQW8BQC\u002fn+D+pngZAY\u002f8NRrYjBEBQ5RF4eAQHQGMOr8UNVgRAWFmqaMqSCEBnTddQLzsKQDv4aqrRNQVAsu3felyhCEAYWMwgJvwDQP\u002fIZWScVAdASbmnWzewA0D3\u002fHdLdegJQG4a\u002f0gCPgVAkTu52dFq8z8LIKdLNmQDQOoaN3nD7ghA3UBkWNRYBUAN5Q1LXXEGQNzazF3iXwNANmV5vVsxCEA41P7GQqsGQNSJhSz6ngVA1j0et3wfB0CLmypmd3sGQHLtko4VFwNA8XpwGmgzCED0WA\u002f9vD8FQDHFsfMZlQNAOQW6X\u002fKxCUBj7y5vonMDQM\u002f61t43vgZAMre4Us8zB0BclnYHsawJQMCYOXH2MAZAsFTYE5M4CUBjAoJiPHnXvyjlggSYIAJA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2023"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate (1)","showlegend":false,"x":{"dtype":"f8","bdata":"jDu5tUVUtr8="},"y":{"dtype":"f8","bdata":"epbmhQnq3r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2023"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor (1)","showlegend":false,"x":{"dtype":"f8","bdata":"v93xKZ18AsA="},"y":{"dtype":"f8","bdata":"YqmXuQVCAEA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2023","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2023","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2023","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2023"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language (4)","showlegend":false,"x":{"dtype":"f8","bdata":"NnclkuhzCMBXD9inY8cCwFh\u002fgMexDQXA0G7nrgy7l78="},"y":{"dtype":"f8","bdata":"EERziKiq7j+CzYFlsoTwP\u002f7byXJu2\u002fY\u002f2PKiuCTN7j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2023"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal (1)","showlegend":false,"x":{"dtype":"f8","bdata":"lBzrFRl5BsA="},"y":{"dtype":"f8","bdata":"eCgjdWS42z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2023"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length (1)","showlegend":false,"x":{"dtype":"f8","bdata":"N3RPJw72\u002fr8="},"y":{"dtype":"f8","bdata":"kTu52dFq8z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2023","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2023","Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2023","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2023","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2023","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2023","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2023","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral (20)","showlegend":false,"x":{"dtype":"f8","bdata":"MKdWg4OCCcCQu3GjqJHuvyUJ\u002f5\u002fvOwXAK061Nm7fxz9yb8JlM8sIwCpYlOF3ZwHAH1eDBP6QCcDzV136o7LwP8uruE9X5Oo\u002fLS8RYB9LtD8Sj9DxerDTvyVIJEI9h9Y\u002frh4if+AD4T9iVp5kdpYDwGXy0nkfdAjAeIx75yoTBsChiVSmvCkJwIPdnLS2BOA\u002fFKhAWOH2BcCnAa4dW7kFwA=="},"y":{"dtype":"f8","bdata":"kSz3Be2l7b8G77rNVs38v8bMBeqg4fO\u002f00BJosIvxb8gXr\u002f+3\u002f7kv0kAZolXheO\u002fGfK1DWVp7b8IeSnrwCq8P64af\u002fpO3eK\u002fSHIA7tVknD8mc1UcNIr4v8jWG1xQJOk\u002fijddwLrC+b\u002fAoKmANMPzv13YBlci8vG\u002f2uzP3pPc8r8SSREy7pPvvxCOFBK4+ey\u002fHMH453oO7r9xDj9NF2vxvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2023","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2023","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2023","Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2023","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2023","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2023"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual (6)","showlegend":false,"x":{"dtype":"f8","bdata":"N9Xj0Lu96r\u002fCTFSusaoFwJS7CgA+AtM\u002fV5LDTLQcAcDAM4S8V\u002frfP0Yx9Wgp6QDA"},"y":{"dtype":"f8","bdata":"d2J8gs\u002flA8DsZftRvqf+v07dae5iOOC\u002fkPPs5qcN+b9XXTZ+A3L5v2kKvUJnLfS\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2023"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"cNT6QBgR+b8="},"y":{"dtype":"f8","bdata":"ubzF1WhCA8A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2023","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2023","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions (4)","showlegend":false,"x":{"dtype":"f8","bdata":"daYAhnCJ2z\u002flZdrBPnn3PxlTMOKe++A\u002f3KPz2KUp8z8="},"y":{"dtype":"f8","bdata":"eBvK7Hdrtz8QJuptplvWv4LNLfZvuwDA5GBfe8w6r78="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2023","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2023","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2023","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2023","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2023","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2023","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization (31)","showlegend":false,"x":{"dtype":"f8","bdata":"WhYT1zbPyD\u002f76eyx0+riP0TYFgiVheW\u002f1pdps9bk8r88T2ezqeTkv0Na5xmvFeG\u002faXCk99nE5j8bD3ilWJTfv1xUEjf\u002fQNu\u002fCIark+ig6j\u002fX0bEvR0nZP49BRXzOz+y\u002fpj\u002fa6ZIT779yEjg4KjnevzouDn0xn9q\u002fqjgJC0xP578ktl7ENFzuvxQyqrp2HtW\u002fOgslAP7d5r8icaDeKf\u002fbv8DgxqGB2qm\u002fRDOaxToO2L88L2DBt3bgv9p2rnxXgcG\u002fFh8Ve6wq5r+SnuanZXHsv+Qt0rkqJcu\u002fbHxsU9usyL9ptORBkFziv\u002fJoM7bgT\u002fg\u002f0MOKSEXs5L8="},"y":{"dtype":"f8","bdata":"rzh9cXs3BsCRPAapxii5v08en8w02QnAxtCizBrAC8BGc9P\u002fQCAMwCQDtgYVbAjAiqcFMZM81L\u002fMiD55QzkGwBzdIho8pAfAQhJQVRuB4b8dQR3pBz7nv+YUuQpx7v2\u002f1JCgI+46CMAWGcNts7sGwHMiMZmL+AfAO8PppE1JCMD89DyswJsIwBheiXsSygjAPs9ugxfDBMASKnbPwz0GwL0d11VCVwXA+Vi67PONCMAH8oYN2ZUHwJ7R5pAjFQjA8d7YOvgBBsCedvDJuS0KwFpcVUP66gPAwp0guhbFB8CUmajJ5UYHwCjF2pm6yKg\u002fDTv4EANlBMA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2023","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2023","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2023","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2023","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2023","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2023"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political (6)","showlegend":false,"x":{"dtype":"f8","bdata":"CA8\u002fULlJ+D9q\u002fQ0V7yf6P2oXMlYpuvg\u002fWDyTHkGD9T8Sj9DxerDTv7Ifcy9a5c0\u002f"},"y":{"dtype":"f8","bdata":"dwSrNdRn+b89P9arhub7v4BsoSPXo\u002fa\u002fGcFGfcfUtT8mc1UcNIr4v5q1uDz7Bw7A"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2023","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2023","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2023","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2023","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2023","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2023","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2023","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2023","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2023","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2023","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2023","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2023","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2023","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2023","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2023","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2023","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2023","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety (62)","showlegend":false,"x":{"dtype":"f8","bdata":"kLtxo6iR7r831ePQu73qv1oWE9c2z8g\u002fMFZEXNrD2T9kKsEyS4\u002fyP3ZNjBxFGf4\u002fHlVOuO0FAkBj1YeDgJHzP5yhDRKTofE\u002f2Ud\u002fVp8R7D9+qmTokUf0PyU3dT\u002fOOvE\u002fhoMKzl9Y8j\u002fgdlgwpe3NPxv+F1iLa+M\u002feJietk5L9D+MO7m1RVS2v1nvAFKdZ90\u002fPR2Vagxd8j+usBCAWnH0Px21+vzxT+U\u002fdpbas4v88j9\u002fM0kYoq33P9sK48JldO8\u002fiuCBvjab9j+NeaPI6PgAQEYG2QS0FPE\u002fGUzMzKa38j\u002fAx30HC8fxPzVit6A3uu0\u002fUw5\u002fnTyW3j\u002fUPppnC4\u002f2P+wfCipruOU\u002foqzz7DHz3j9uPND\u002fA7PqP8AzhLxX+t8\u002fJImldq7z8T\u002ftGVaZXvnxPyT8tdGV1\u002fI\u002fOi\u002fs4D3z1D++TyogiFLzP4MOJLEk1+8\u002f9yqtsf3X7z+8JLd2yHnzP57B2\u002f6tf+Q\u002f+ikKpvbv\u002fT+t0ofv4EPvP9rUay8Zk+o\u002fjgPPk3HF7T8rwop6vc\u002fwP\u002f1pO\u002faOQuc\u002fLHnemHq94j+sp99RXnoBQBSEvViC2OY\u002fbzsgOm2\u002f5j\u002fjYF2YWffwPwqMmPqbLeY\u002fp0r9IU4H\u002fz+7uNogRfD3P9sADTKTBPE\u002fv682mtg80r8SCfUB6rj4Pw=="},"y":{"dtype":"f8","bdata":"Bu+6zVbN\u002fL93YnyCz+UDwK84fXF7NwbASvdzbJYCB8D8UtmQv4eoP8jKmdqx5QLA2uMKaqBJ779NKdEHQWIFwCDzMi+5YwnAiZHy+z+NCsCifXUn0DcFwHQTJsNq3gbA75ufZPkMBcDMdnJUVTcJwI+pYo5vFwbAeC+ssHjXCcB6luaFCerev3ZV4mvL9tA\u002fdRIe6wCHDcCLJp0JGjoIwOioyLiPRgXAjayHcwVvCsDo9d9FwZzBPxJRghHDmAPAlokD2BGCBcAi1RDNl7fGvxluJj6GhQjApos8uEeKCMDOLqpgwZMGwI6GafRyJQPAkFHRrzSNCcDVvo5yHn8KwOP0ybNGtwjAfkipOB7dpD+\u002fyh7XLuYFwFddNn4Dcvm\u002faAQUSFqkC8CiL046jjsFwGbZPKI1GQvAKOAgjhJkBcALnhy1TU0HwHmGqBNBRQnAvd5RfgowBsCRNyff9SUHwK+N17fGjQTAzuw90ZGH+L\u002fYbhOfPQgJwHhBbfZJdQrA05ZgHVJqBcBLfIElrsoHwOi15Z1AWwTAShGS+4sNB8CFFBy9nBr9vyyVcBMOqwXAvbI92WXxCsBNx5SI4goFwCTI7w1gSgbAqLJW5U76\u002f79NvjPFE24CwPIMxgNIfQbAYwKCYjx5179V04zXXxoGwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2023"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism (1)","showlegend":false,"x":{"dtype":"f8","bdata":"rh4if+AD4T8="},"y":{"dtype":"f8","bdata":"ijddwLrC+b8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2023","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2023","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2023","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2023","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2023","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2023","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2023"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social (18)","showlegend":false,"x":{"dtype":"f8","bdata":"TY8vYpJvAkC\u002fLuPgaacCQIgvl++q2vo\u002faor1+0LwAECqzSBMzDsEQFSAwW2q\u002fwRA4sZaFJ3BAEBJz6DETSQGQPhatwog6P8\u002fGVMw4p774D\u002fX0bEvR0nZPwJFIB\u002fMFwVAav0NFe8n+j9wrG8q\u002fZ4BQMJbIJd9av4\u002fbfwhNK5CBEAP7vNre9P\u002fP\u002fJoM7bgT\u002fg\u002f"},"y":{"dtype":"f8","bdata":"BT1DS2oj\u002fL\u002fa913rQOn\u002fv3ESPQFbwP+\u002f3vQowuKH\u002f7\u002fXLk8whGUDwKhB2+pLh9y\u002fr\u002fs1bnqTAsCuZQeOf2vkv5qYHk0iiqq\u002fgs0t9m+7AMAdQR3pBz7nv5CaYSPeBbY\u002fPT\u002fWq4bm+7+V4qKCAhQBwNhRZNkyOv2\u002f0D7a4qK0wT\u002f4e1E9qyP8vyjF2pm6yKg\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2023","Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2023","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2023","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2023","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2023","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2023"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity (6)","showlegend":false,"x":{"dtype":"f8","bdata":"dk2MHEUZ\u002fj\u002fUbymkMmADQDoen422LQVA+cEDMRl2BEC7uNogRfD3P4rKg9Um6gNA"},"y":{"dtype":"f8","bdata":"yMqZ2rHlAsCKxaJMLx\u002f7vywtXofpcfi\u002fdPYIguiH+79NvjPFE24CwDqDpl3lQO6\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2023","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2023","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2023","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2023","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value (15)","showlegend":false,"x":{"dtype":"f8","bdata":"llWVR0s2DECQ9JdpjUcIQHTN04LkgwZAzMBIj45hBUB5VpXQHQYPQCZ7cJg8igRA+ikKpvbv\u002fT\u002fiinHCujIIQIPdnLS2BOA\u002fDCAeexfFB0BB64XOaysJQKyn31FeegFADAfTUkL3B0CnSv0hTgf\u002fP5o7G52\u002fJgtA"},"y":{"dtype":"f8","bdata":"KqJ3FkEy8L\u002f4kO+ZUcbjv2sYL9IG5Om\u002f5TiZdZm45b\u002faTua5Az7qvwePeiwrtuK\u002fzuw90ZGH+L9zkLOpEWzwvxCOFBK4+ey\u002fpwlp\u002fOX587\u002f5Pu8BXULtv4UUHL2cGv2\u002fgGWt\u002fHIK7r+oslblTvr\u002fvw6bPuHHU\u002fe\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias (19)","showlegend":false,"x":{"dtype":"f8","bdata":"bt3rfQsSB0BUgMFtqv8EQPNXXfqjsvA\u002fCA8\u002fULlJ+D\u002flZdrBPnn3P415o8jo+ABAy6u4T1fk6j\u002f4WrcKIOj\u002fPwJFIB\u002fMFwVA3KPz2KUp8z9q\u002fQ0V7yf6P2oXMlYpuvg\u002fktSFQrVeBUBYPJMeQYP1PwNW8T5qDQhAzuaR7IAPBUASj9DxerDTv64eIn\u002fgA+E\u002fHQJy5QcpB0A="},"y":{"dtype":"f8","bdata":"kGyHMSW7oL+oQdvqS4fcvwh5KevAKrw\u002fdwSrNdRn+b8QJuptplvWvyLVEM2Xt8a\u002frhp\u002f+k7d4r+amB5NIoqqv5CaYSPeBbY\u002f5GBfe8w6r789P9arhub7v4BsoSPXo\u002fa\u002fxqMC36NZ6D8ZwUZ9x9S1P\u002fkzbdnOGuE\u002fPYHe1Uno9D8mc1UcNIr4v4o3XcC6wvm\u002fMAHFs2k14z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2024","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2024","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2024","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2024","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2024"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural (30)","showlegend":false,"x":{"dtype":"f8","bdata":"K061Nm7fxz+UuwoAPgLTP5D+zYDuuglAHlVOuO0FAkBu3et9CxIHQJDsssdlWAJA68trbM2aBUAYBNRTDEEEQPXqWl5zrQlA1AsnPcsNB0DcBe9AqbEFQCWaJSX34AlAVIDBbar\u002fBEDzV136o7LwP2lwpPfZxOY\u002fSc+gxE0kBkDLq7hPV+TqPwNW8T5qDQhAwDOEvFf63z8tLxFgH0u0PyVIJEI9h9Y\u002f7SUDouC6BkDj2ndqxxkDQOiBpReI2AZA+qpCsfGUA0Bzk9zNhCX4P\u002fJoM7bgT\u002fg\u002fHiOmImI6BkCy7YVU1cYGQNBu564Mu5e\u002f"},"y":{"dtype":"f8","bdata":"00BJosIvxb9O3WnuYjjgvwBoUFeM416\u002f2uMKaqBJ77+QbIcxJbugvwYGdLKAouY\u002fcPg9VKXV5z9Vx6YAZRPwP1RXTsNVzOg\u002fkw4IgKS\u002f2z9Ln9u4XsrbP5w+D2fCtes\u002fqEHb6kuH3L8IeSnrwCq8P4qnBTGTPNS\u002frmUHjn9r5L+uGn\u002f6Tt3iv\u002fkzbdnOGuE\u002fV102fgNy+b9IcgDu1WScP8jWG1xQJOk\u002fzVEManb83z9dqz2TVTjpP6yJ4mv+Lsw\u002f7E1Grq3j8j\u002fzvOVIHiMAQCjF2pm6yKg\u002f0Uu5XjnG0z8Vl376B0rzP9jyorgkze4\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2024","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2024","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2024"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture (3)","showlegend":false,"x":{"dtype":"f8","bdata":"FEm3i9eFCEChwEmX2jgIQEMChUrVMQRA"},"y":{"dtype":"f8","bdata":"KmO3qY9Y+T\u002fuaetzCRH7PwWXW5cpU\u002fw\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2024","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2024","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2024"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics (14)","showlegend":false,"x":{"dtype":"f8","bdata":"daYAhnCJ2z\u002fQW10WR5AAQL1vxPvbjABA5n8tJMdXBUDlZdrBPnn3P415o8jo+ABA+Fq3CiDo\u002fz8CRSAfzBcFQNyj89ilKfM\u002fXjo0sUhC+z+S1IVCtV4FQB0CcuUHKQdA+52FXZafAEBt\u002fCE0rkIEQA=="},"y":{"dtype":"f8","bdata":"eBvK7Hdrtz+6KCBVAo4CQEcuchTXhAJApXkTY3VXAUAQJuptplvWvyLVEM2Xt8a\u002fmpgeTSKKqr+QmmEj3gW2P+RgX3vMOq+\u002f3R4BewVBAEDGowLfo1noPzABxbNpNeM\u002f\u002ftH\u002ffcq6+j\u002fQPtriorTBPw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2024","Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2024","Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2024","Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2024","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2024","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2024","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity (10)","showlegend":false,"x":{"dtype":"f8","bdata":"ZCrBMkuP8j\u002f76eyx0+riPzUCyF\u002fmQPo\u002fU7hAqdYBAEBJy640WYr+P38zSRiirfc\u002fCIark+ig6j9eOjSxSEL7P87mkeyADwVAJUgkQj2H1j8="},"y":{"dtype":"f8","bdata":"\u002fFLZkL+HqD+RPAapxii5vxb45jQ+pQhAvYHDxP0rBkAhU1EW1vEFQOj130XBnME\u002fQhJQVRuB4b\u002fdHgF7BUEAQD2B3tVJ6PQ\u002fyNYbXFAk6T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical (6)","showlegend":false,"x":{"dtype":"f8","bdata":"8OixbNRD8D+nfAFqcA\u002fwPxy0WobHmfg\u002f19GxL0dJ2T\u002fyaDO24E\u002f4P9N\u002fJ\u002fRXsfI\u002f"},"y":{"dtype":"f8","bdata":"IafSo4BtB0CaJ85gZhoJQC\u002fHisSYUghAHUEd6Qc+578oxdqZusioP8bS61VZ9QZA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2024","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality (21)","showlegend":false,"x":{"dtype":"f8","bdata":"PPPkseeU6z+2eirCzvPXP6TroNjSE7S\u002fSYY+FNuZ178t6N+RWRbRP1nvAFKdZ90\u002fdfBbI3+d1L\u002fqRcUqJuLBv05LwWcpQ9k\u002fQL\u002fA9Tpcdr+irPPsMfPeP3D6Sdv8Y+o\u002fWDyTHkGD9T+VGP9NYAThP4DIVjlQ+ZO\u002f0VlZm8LA1T9G5ak+dR\u002fpP0l9VmCFxMk\u002fOIC5w6GIob9zk9zNhCX4PzwDJWfXSdo\u002f"},"y":{"dtype":"f8","bdata":"Ilk\u002fewjsCkAbzJ2ctFMLQI6SYPPiOQVANaG0U\u002f\u002fyB0A6D2bEFU4HQHZV4mvL9tA\u002fKuGYMhmUBkBbjJIfYlEEQAa9rbC9JAhA9NnLqTptB0B+SKk4Ht2kP7aDvMReqwpAGcFGfcfUtT+otEgkyTYJQI9eUDHYFghALaHXFx8xB0C2YVm+nYULQOK3GU0lswVAbeirm02nCEDzvOVIHiMAQDFieNQL8wFA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2024"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"zFyrwwv24L8="},"y":{"dtype":"f8","bdata":"iQW7hKqxBkA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2024","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2024","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general (69)","showlegend":false,"x":{"dtype":"f8","bdata":"sXswhoCg8L89lW2beTb1v2YkFMGAhPG\u002foS6HeObw8b\u002f\u002fINhDmlXovykofOh0iPK\u002fsjMhlTTU9b88WjvxAdn4v3iv82xJAva\u002fM3+nIZmx778s7poXDZv1v8ChX70st\u002fa\u002fkNY9xGEw9L\u002f8wdAU8W32v9Sej6zl4fO\u002fOOPoJfZ0+r+8dXWewS7wv1ay6jmXTPm\u002fqwvMISdZ9L\u002fY9Scdtwv5v1y9TMmqC\u002fO\u002f325gGPlJ8r+S+TduYSn3vyoNkFAAKfW\u002fGmQrcyo07L8dIXImdsXkvxP8UU8EzO2\u002fMll+riHY9b\u002f33f0OnObwvyT5qBUpOPm\u002f30WT1tD+8r9JxHH9Vz35vxrQ01PyvO6\u002faGja9RZr+b\u002fn9ZK+Dsj3v1G41c+GNvO\u002ffXTQHARZ8b\u002fkO5hO7dLxv8ox6cDaT\u002fe\u002ff6bd7U\u002fb8r\u002fYep2TrJDuvwCj6HnHs\u002fm\u002fMXQfGUZ29b9nto6h7DHwv8rHJZY9tfa\u002fN3RPJw72\u002fr+u7zGnXij2v1rTw+kZh\u002fS\u002f2tXMKLRT7r9LV7Yf+P73v3BcIQimhfm\u002fkLKmK7iL+L+OIKZwhq\u002fzvytTHH2DJPS\u002fNwRiScYI7r\u002feCAHwZkn+vw1ZWuJctva\u002f7KtoEnmp+78MUN6nvH32v8peVgV82fu\u002fVBCnOMjp+78tXTz4jwPuvy5GaSE0Zvy\u002fuoYDGZnO+L8whDNsomb7v07VLAfIlvi\u002f1bnSgEsJ9b+\u002frzaa2DzSvx8nRM3VufG\u002f"},"y":{"dtype":"f8","bdata":"aS8G\u002fE3qA0DW0\u002f7sr60IQBDYlEhWywZAtWqJgi8pCEC76IR6sDsGQF9Z9cxB1QRAqfVqzmc1BUD1eA227koIQGqq0GcllAZAsiXZdw0jA0Dr3EzZnO8HQNCTwGdQsgVARk1SoZ5ICUDQH4KaGDAEQF30JM83ZQhAm8DfvJEqBUDLYmJnjRgJQNalysnp0gNADyfB0bl0CUB8JuVRpukDQDAF4G7hYQJA3nuKEgEKBEC0iKLLf2YGQCsIx3pJeARAimFObquKBUD9xI7jRp0EQGjKPxs3igZAhmz5rrHfB0C7nuEyW5gCQCWt5xEJUgxAZmpe0QOWAUDGIagFQW8BQC\u002fn+D+pngZAY\u002f8NRrYjBEBQ5RF4eAQHQGMOr8UNVgRAWFmqaMqSCEBnTddQLzsKQDv4aqrRNQVAsu3felyhCEAYWMwgJvwDQP\u002fIZWScVAdASbmnWzewA0D3\u002fHdLdegJQG4a\u002f0gCPgVAkTu52dFq8z8LIKdLNmQDQOoaN3nD7ghA3UBkWNRYBUAN5Q1LXXEGQNzazF3iXwNANmV5vVsxCEA41P7GQqsGQNSJhSz6ngVA1j0et3wfB0CLmypmd3sGQHLtko4VFwNA8XpwGmgzCED0WA\u002f9vD8FQDHFsfMZlQNAOQW6X\u002fKxCUBj7y5vonMDQM\u002f61t43vgZAMre4Us8zB0BclnYHsawJQMCYOXH2MAZAsFTYE5M4CUBjAoJiPHnXvyjlggSYIAJA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2024"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate (1)","showlegend":false,"x":{"dtype":"f8","bdata":"jDu5tUVUtr8="},"y":{"dtype":"f8","bdata":"epbmhQnq3r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2024"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor (1)","showlegend":false,"x":{"dtype":"f8","bdata":"v93xKZ18AsA="},"y":{"dtype":"f8","bdata":"YqmXuQVCAEA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2024","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2024","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2024","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2024"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language (4)","showlegend":false,"x":{"dtype":"f8","bdata":"NnclkuhzCMBXD9inY8cCwFh\u002fgMexDQXA0G7nrgy7l78="},"y":{"dtype":"f8","bdata":"EERziKiq7j+CzYFlsoTwP\u002f7byXJu2\u002fY\u002f2PKiuCTN7j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2024"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal (1)","showlegend":false,"x":{"dtype":"f8","bdata":"lBzrFRl5BsA="},"y":{"dtype":"f8","bdata":"eCgjdWS42z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2024"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length (1)","showlegend":false,"x":{"dtype":"f8","bdata":"N3RPJw72\u002fr8="},"y":{"dtype":"f8","bdata":"kTu52dFq8z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2024","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2024","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral (20)","showlegend":false,"x":{"dtype":"f8","bdata":"MKdWg4OCCcCQu3GjqJHuvyUJ\u002f5\u002fvOwXAK061Nm7fxz9yb8JlM8sIwCpYlOF3ZwHAH1eDBP6QCcDzV136o7LwP8uruE9X5Oo\u002fLS8RYB9LtD8Sj9DxerDTvyVIJEI9h9Y\u002frh4if+AD4T9iVp5kdpYDwGXy0nkfdAjAeIx75yoTBsChiVSmvCkJwIPdnLS2BOA\u002fFKhAWOH2BcCnAa4dW7kFwA=="},"y":{"dtype":"f8","bdata":"kSz3Be2l7b8G77rNVs38v8bMBeqg4fO\u002f00BJosIvxb8gXr\u002f+3\u002f7kv0kAZolXheO\u002fGfK1DWVp7b8IeSnrwCq8P64af\u002fpO3eK\u002fSHIA7tVknD8mc1UcNIr4v8jWG1xQJOk\u002fijddwLrC+b\u002fAoKmANMPzv13YBlci8vG\u002f2uzP3pPc8r8SSREy7pPvvxCOFBK4+ey\u002fHMH453oO7r9xDj9NF2vxvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2024","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2024","Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual (6)","showlegend":false,"x":{"dtype":"f8","bdata":"N9Xj0Lu96r\u002fCTFSusaoFwJS7CgA+AtM\u002fV5LDTLQcAcDAM4S8V\u002frfP0Yx9Wgp6QDA"},"y":{"dtype":"f8","bdata":"d2J8gs\u002flA8DsZftRvqf+v07dae5iOOC\u002fkPPs5qcN+b9XXTZ+A3L5v2kKvUJnLfS\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2024"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"cNT6QBgR+b8="},"y":{"dtype":"f8","bdata":"ubzF1WhCA8A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions (4)","showlegend":false,"x":{"dtype":"f8","bdata":"daYAhnCJ2z\u002flZdrBPnn3PxlTMOKe++A\u002f3KPz2KUp8z8="},"y":{"dtype":"f8","bdata":"eBvK7Hdrtz8QJuptplvWv4LNLfZvuwDA5GBfe8w6r78="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2024","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2024","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2024","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization (31)","showlegend":false,"x":{"dtype":"f8","bdata":"WhYT1zbPyD\u002f76eyx0+riP0TYFgiVheW\u002f1pdps9bk8r88T2ezqeTkv0Na5xmvFeG\u002faXCk99nE5j8bD3ilWJTfv1xUEjf\u002fQNu\u002fCIark+ig6j\u002fX0bEvR0nZP49BRXzOz+y\u002fpj\u002fa6ZIT779yEjg4KjnevzouDn0xn9q\u002fqjgJC0xP578ktl7ENFzuvxQyqrp2HtW\u002fOgslAP7d5r8icaDeKf\u002fbv8DgxqGB2qm\u002fRDOaxToO2L88L2DBt3bgv9p2rnxXgcG\u002fFh8Ve6wq5r+SnuanZXHsv+Qt0rkqJcu\u002fbHxsU9usyL9ptORBkFziv\u002fJoM7bgT\u002fg\u002f0MOKSEXs5L8="},"y":{"dtype":"f8","bdata":"rzh9cXs3BsCRPAapxii5v08en8w02QnAxtCizBrAC8BGc9P\u002fQCAMwCQDtgYVbAjAiqcFMZM81L\u002fMiD55QzkGwBzdIho8pAfAQhJQVRuB4b8dQR3pBz7nv+YUuQpx7v2\u002f1JCgI+46CMAWGcNts7sGwHMiMZmL+AfAO8PppE1JCMD89DyswJsIwBheiXsSygjAPs9ugxfDBMASKnbPwz0GwL0d11VCVwXA+Vi67PONCMAH8oYN2ZUHwJ7R5pAjFQjA8d7YOvgBBsCedvDJuS0KwFpcVUP66gPAwp0guhbFB8CUmajJ5UYHwCjF2pm6yKg\u002fDTv4EANlBMA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2024"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political (6)","showlegend":false,"x":{"dtype":"f8","bdata":"CA8\u002fULlJ+D9q\u002fQ0V7yf6P2oXMlYpuvg\u002fWDyTHkGD9T8Sj9DxerDTv7Ifcy9a5c0\u002f"},"y":{"dtype":"f8","bdata":"dwSrNdRn+b89P9arhub7v4BsoSPXo\u002fa\u002fGcFGfcfUtT8mc1UcNIr4v5q1uDz7Bw7A"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2024","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2024","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2024","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2024","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2024","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2024","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2024","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2024","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2024","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2024","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2024","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety (62)","showlegend":false,"x":{"dtype":"f8","bdata":"kLtxo6iR7r831ePQu73qv1oWE9c2z8g\u002fMFZEXNrD2T9kKsEyS4\u002fyP3ZNjBxFGf4\u002fHlVOuO0FAkBj1YeDgJHzP5yhDRKTofE\u002f2Ud\u002fVp8R7D9+qmTokUf0PyU3dT\u002fOOvE\u002fhoMKzl9Y8j\u002fgdlgwpe3NPxv+F1iLa+M\u002feJietk5L9D+MO7m1RVS2v1nvAFKdZ90\u002fPR2Vagxd8j+usBCAWnH0Px21+vzxT+U\u002fdpbas4v88j9\u002fM0kYoq33P9sK48JldO8\u002fiuCBvjab9j+NeaPI6PgAQEYG2QS0FPE\u002fGUzMzKa38j\u002fAx30HC8fxPzVit6A3uu0\u002fUw5\u002fnTyW3j\u002fUPppnC4\u002f2P+wfCipruOU\u002foqzz7DHz3j9uPND\u002fA7PqP8AzhLxX+t8\u002fJImldq7z8T\u002ftGVaZXvnxPyT8tdGV1\u002fI\u002fOi\u002fs4D3z1D++TyogiFLzP4MOJLEk1+8\u002f9yqtsf3X7z+8JLd2yHnzP57B2\u002f6tf+Q\u002f+ikKpvbv\u002fT+t0ofv4EPvP9rUay8Zk+o\u002fjgPPk3HF7T8rwop6vc\u002fwP\u002f1pO\u002faOQuc\u002fLHnemHq94j+sp99RXnoBQBSEvViC2OY\u002fbzsgOm2\u002f5j\u002fjYF2YWffwPwqMmPqbLeY\u002fp0r9IU4H\u002fz+7uNogRfD3P9sADTKTBPE\u002fv682mtg80r8SCfUB6rj4Pw=="},"y":{"dtype":"f8","bdata":"Bu+6zVbN\u002fL93YnyCz+UDwK84fXF7NwbASvdzbJYCB8D8UtmQv4eoP8jKmdqx5QLA2uMKaqBJ779NKdEHQWIFwCDzMi+5YwnAiZHy+z+NCsCifXUn0DcFwHQTJsNq3gbA75ufZPkMBcDMdnJUVTcJwI+pYo5vFwbAeC+ssHjXCcB6luaFCerev3ZV4mvL9tA\u002fdRIe6wCHDcCLJp0JGjoIwOioyLiPRgXAjayHcwVvCsDo9d9FwZzBPxJRghHDmAPAlokD2BGCBcAi1RDNl7fGvxluJj6GhQjApos8uEeKCMDOLqpgwZMGwI6GafRyJQPAkFHRrzSNCcDVvo5yHn8KwOP0ybNGtwjAfkipOB7dpD+\u002fyh7XLuYFwFddNn4Dcvm\u002faAQUSFqkC8CiL046jjsFwGbZPKI1GQvAKOAgjhJkBcALnhy1TU0HwHmGqBNBRQnAvd5RfgowBsCRNyff9SUHwK+N17fGjQTAzuw90ZGH+L\u002fYbhOfPQgJwHhBbfZJdQrA05ZgHVJqBcBLfIElrsoHwOi15Z1AWwTAShGS+4sNB8CFFBy9nBr9vyyVcBMOqwXAvbI92WXxCsBNx5SI4goFwCTI7w1gSgbAqLJW5U76\u002f79NvjPFE24CwPIMxgNIfQbAYwKCYjx5179V04zXXxoGwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism (1)","showlegend":false,"x":{"dtype":"f8","bdata":"rh4if+AD4T8="},"y":{"dtype":"f8","bdata":"ijddwLrC+b8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2024","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2024"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social (18)","showlegend":false,"x":{"dtype":"f8","bdata":"TY8vYpJvAkC\u002fLuPgaacCQIgvl++q2vo\u002faor1+0LwAECqzSBMzDsEQFSAwW2q\u002fwRA4sZaFJ3BAEBJz6DETSQGQPhatwog6P8\u002fGVMw4p774D\u002fX0bEvR0nZPwJFIB\u002fMFwVAav0NFe8n+j9wrG8q\u002fZ4BQMJbIJd9av4\u002fbfwhNK5CBEAP7vNre9P\u002fP\u002fJoM7bgT\u002fg\u002f"},"y":{"dtype":"f8","bdata":"BT1DS2oj\u002fL\u002fa913rQOn\u002fv3ESPQFbwP+\u002f3vQowuKH\u002f7\u002fXLk8whGUDwKhB2+pLh9y\u002fr\u002fs1bnqTAsCuZQeOf2vkv5qYHk0iiqq\u002fgs0t9m+7AMAdQR3pBz7nv5CaYSPeBbY\u002fPT\u002fWq4bm+7+V4qKCAhQBwNhRZNkyOv2\u002f0D7a4qK0wT\u002f4e1E9qyP8vyjF2pm6yKg\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2024","Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2024","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity (6)","showlegend":false,"x":{"dtype":"f8","bdata":"dk2MHEUZ\u002fj\u002fUbymkMmADQDoen422LQVA+cEDMRl2BEC7uNogRfD3P4rKg9Um6gNA"},"y":{"dtype":"f8","bdata":"yMqZ2rHlAsCKxaJMLx\u002f7vywtXofpcfi\u002fdPYIguiH+79NvjPFE24CwDqDpl3lQO6\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2024","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2024","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2024","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2024","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value (15)","showlegend":false,"x":{"dtype":"f8","bdata":"llWVR0s2DECQ9JdpjUcIQHTN04LkgwZAzMBIj45hBUB5VpXQHQYPQCZ7cJg8igRA+ikKpvbv\u002fT\u002fiinHCujIIQIPdnLS2BOA\u002fDCAeexfFB0BB64XOaysJQKyn31FeegFADAfTUkL3B0CnSv0hTgf\u002fP5o7G52\u002fJgtA"},"y":{"dtype":"f8","bdata":"KqJ3FkEy8L\u002f4kO+ZUcbjv2sYL9IG5Om\u002f5TiZdZm45b\u002faTua5Az7qvwePeiwrtuK\u002fzuw90ZGH+L9zkLOpEWzwvxCOFBK4+ey\u002fpwlp\u002fOX587\u002f5Pu8BXULtv4UUHL2cGv2\u002fgGWt\u002fHIK7r+oslblTvr\u002fvw6bPuHHU\u002fe\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2025","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2025","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2025","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2025","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2025","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2025","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2025","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2025","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2025","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2025","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2025"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias (19)","showlegend":false,"x":{"dtype":"f8","bdata":"bt3rfQsSB0BUgMFtqv8EQPNXXfqjsvA\u002fCA8\u002fULlJ+D\u002flZdrBPnn3P415o8jo+ABAy6u4T1fk6j\u002f4WrcKIOj\u002fPwJFIB\u002fMFwVA3KPz2KUp8z9q\u002fQ0V7yf6P2oXMlYpuvg\u002fktSFQrVeBUBYPJMeQYP1PwNW8T5qDQhAzuaR7IAPBUASj9DxerDTv64eIn\u002fgA+E\u002fHQJy5QcpB0A="},"y":{"dtype":"f8","bdata":"kGyHMSW7oL+oQdvqS4fcvwh5KevAKrw\u002fdwSrNdRn+b8QJuptplvWvyLVEM2Xt8a\u002frhp\u002f+k7d4r+amB5NIoqqv5CaYSPeBbY\u002f5GBfe8w6r789P9arhub7v4BsoSPXo\u002fa\u002fxqMC36NZ6D8ZwUZ9x9S1P\u002fkzbdnOGuE\u002fPYHe1Uno9D8mc1UcNIr4v4o3XcC6wvm\u002fMAHFs2k14z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2025","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2025","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2025","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2025","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2025","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2025","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2025","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2025"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural (30)","showlegend":false,"x":{"dtype":"f8","bdata":"K061Nm7fxz+UuwoAPgLTP5D+zYDuuglAHlVOuO0FAkBu3et9CxIHQJDsssdlWAJA68trbM2aBUAYBNRTDEEEQPXqWl5zrQlA1AsnPcsNB0DcBe9AqbEFQCWaJSX34AlAVIDBbar\u002fBEDzV136o7LwP2lwpPfZxOY\u002fSc+gxE0kBkDLq7hPV+TqPwNW8T5qDQhAwDOEvFf63z8tLxFgH0u0PyVIJEI9h9Y\u002f7SUDouC6BkDj2ndqxxkDQOiBpReI2AZA+qpCsfGUA0Bzk9zNhCX4P\u002fJoM7bgT\u002fg\u002fHiOmImI6BkCy7YVU1cYGQNBu564Mu5e\u002f"},"y":{"dtype":"f8","bdata":"00BJosIvxb9O3WnuYjjgvwBoUFeM416\u002f2uMKaqBJ77+QbIcxJbugvwYGdLKAouY\u002fcPg9VKXV5z9Vx6YAZRPwP1RXTsNVzOg\u002fkw4IgKS\u002f2z9Ln9u4XsrbP5w+D2fCtes\u002fqEHb6kuH3L8IeSnrwCq8P4qnBTGTPNS\u002frmUHjn9r5L+uGn\u002f6Tt3iv\u002fkzbdnOGuE\u002fV102fgNy+b9IcgDu1WScP8jWG1xQJOk\u002fzVEManb83z9dqz2TVTjpP6yJ4mv+Lsw\u002f7E1Grq3j8j\u002fzvOVIHiMAQCjF2pm6yKg\u002f0Uu5XjnG0z8Vl376B0rzP9jyorgkze4\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture (3)","showlegend":false,"x":{"dtype":"f8","bdata":"FEm3i9eFCEChwEmX2jgIQEMChUrVMQRA"},"y":{"dtype":"f8","bdata":"KmO3qY9Y+T\u002fuaetzCRH7PwWXW5cpU\u002fw\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2025","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2025","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2025","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2025","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2025","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2025"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics (14)","showlegend":false,"x":{"dtype":"f8","bdata":"daYAhnCJ2z\u002fQW10WR5AAQL1vxPvbjABA5n8tJMdXBUDlZdrBPnn3P415o8jo+ABA+Fq3CiDo\u002fz8CRSAfzBcFQNyj89ilKfM\u002fXjo0sUhC+z+S1IVCtV4FQB0CcuUHKQdA+52FXZafAEBt\u002fCE0rkIEQA=="},"y":{"dtype":"f8","bdata":"eBvK7Hdrtz+6KCBVAo4CQEcuchTXhAJApXkTY3VXAUAQJuptplvWvyLVEM2Xt8a\u002fmpgeTSKKqr+QmmEj3gW2P+RgX3vMOq+\u002f3R4BewVBAEDGowLfo1noPzABxbNpNeM\u002f\u002ftH\u002ffcq6+j\u002fQPtriorTBPw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2025","Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2025","Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2025","Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2025","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2025","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2025","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2025","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2025"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity (10)","showlegend":false,"x":{"dtype":"f8","bdata":"ZCrBMkuP8j\u002f76eyx0+riPzUCyF\u002fmQPo\u002fU7hAqdYBAEBJy640WYr+P38zSRiirfc\u002fCIark+ig6j9eOjSxSEL7P87mkeyADwVAJUgkQj2H1j8="},"y":{"dtype":"f8","bdata":"\u002fFLZkL+HqD+RPAapxii5vxb45jQ+pQhAvYHDxP0rBkAhU1EW1vEFQOj130XBnME\u002fQhJQVRuB4b\u002fdHgF7BUEAQD2B3tVJ6PQ\u002fyNYbXFAk6T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical (6)","showlegend":false,"x":{"dtype":"f8","bdata":"8OixbNRD8D+nfAFqcA\u002fwPxy0WobHmfg\u002f19GxL0dJ2T\u002fyaDO24E\u002f4P9N\u002fJ\u002fRXsfI\u002f"},"y":{"dtype":"f8","bdata":"IafSo4BtB0CaJ85gZhoJQC\u002fHisSYUghAHUEd6Qc+578oxdqZusioP8bS61VZ9QZA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2025","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2025","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2025","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2025","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality (21)","showlegend":false,"x":{"dtype":"f8","bdata":"PPPkseeU6z+2eirCzvPXP6TroNjSE7S\u002fSYY+FNuZ178t6N+RWRbRP1nvAFKdZ90\u002fdfBbI3+d1L\u002fqRcUqJuLBv05LwWcpQ9k\u002fQL\u002fA9Tpcdr+irPPsMfPeP3D6Sdv8Y+o\u002fWDyTHkGD9T+VGP9NYAThP4DIVjlQ+ZO\u002f0VlZm8LA1T9G5ak+dR\u002fpP0l9VmCFxMk\u002fOIC5w6GIob9zk9zNhCX4PzwDJWfXSdo\u002f"},"y":{"dtype":"f8","bdata":"Ilk\u002fewjsCkAbzJ2ctFMLQI6SYPPiOQVANaG0U\u002f\u002fyB0A6D2bEFU4HQHZV4mvL9tA\u002fKuGYMhmUBkBbjJIfYlEEQAa9rbC9JAhA9NnLqTptB0B+SKk4Ht2kP7aDvMReqwpAGcFGfcfUtT+otEgkyTYJQI9eUDHYFghALaHXFx8xB0C2YVm+nYULQOK3GU0lswVAbeirm02nCEDzvOVIHiMAQDFieNQL8wFA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2025"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"zFyrwwv24L8="},"y":{"dtype":"f8","bdata":"iQW7hKqxBkA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2025","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2025","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general (69)","showlegend":false,"x":{"dtype":"f8","bdata":"sXswhoCg8L89lW2beTb1v2YkFMGAhPG\u002foS6HeObw8b\u002f\u002fINhDmlXovykofOh0iPK\u002fsjMhlTTU9b88WjvxAdn4v3iv82xJAva\u002fM3+nIZmx778s7poXDZv1v8ChX70st\u002fa\u002fkNY9xGEw9L\u002f8wdAU8W32v9Sej6zl4fO\u002fOOPoJfZ0+r+8dXWewS7wv1ay6jmXTPm\u002fqwvMISdZ9L\u002fY9Scdtwv5v1y9TMmqC\u002fO\u002f325gGPlJ8r+S+TduYSn3vyoNkFAAKfW\u002fGmQrcyo07L8dIXImdsXkvxP8UU8EzO2\u002fMll+riHY9b\u002f33f0OnObwvyT5qBUpOPm\u002f30WT1tD+8r9JxHH9Vz35vxrQ01PyvO6\u002faGja9RZr+b\u002fn9ZK+Dsj3v1G41c+GNvO\u002ffXTQHARZ8b\u002fkO5hO7dLxv8ox6cDaT\u002fe\u002ff6bd7U\u002fb8r\u002fYep2TrJDuvwCj6HnHs\u002fm\u002fMXQfGUZ29b9nto6h7DHwv8rHJZY9tfa\u002fN3RPJw72\u002fr+u7zGnXij2v1rTw+kZh\u002fS\u002f2tXMKLRT7r9LV7Yf+P73v3BcIQimhfm\u002fkLKmK7iL+L+OIKZwhq\u002fzvytTHH2DJPS\u002fNwRiScYI7r\u002feCAHwZkn+vw1ZWuJctva\u002f7KtoEnmp+78MUN6nvH32v8peVgV82fu\u002fVBCnOMjp+78tXTz4jwPuvy5GaSE0Zvy\u002fuoYDGZnO+L8whDNsomb7v07VLAfIlvi\u002f1bnSgEsJ9b+\u002frzaa2DzSvx8nRM3VufG\u002f"},"y":{"dtype":"f8","bdata":"aS8G\u002fE3qA0DW0\u002f7sr60IQBDYlEhWywZAtWqJgi8pCEC76IR6sDsGQF9Z9cxB1QRAqfVqzmc1BUD1eA227koIQGqq0GcllAZAsiXZdw0jA0Dr3EzZnO8HQNCTwGdQsgVARk1SoZ5ICUDQH4KaGDAEQF30JM83ZQhAm8DfvJEqBUDLYmJnjRgJQNalysnp0gNADyfB0bl0CUB8JuVRpukDQDAF4G7hYQJA3nuKEgEKBEC0iKLLf2YGQCsIx3pJeARAimFObquKBUD9xI7jRp0EQGjKPxs3igZAhmz5rrHfB0C7nuEyW5gCQCWt5xEJUgxAZmpe0QOWAUDGIagFQW8BQC\u002fn+D+pngZAY\u002f8NRrYjBEBQ5RF4eAQHQGMOr8UNVgRAWFmqaMqSCEBnTddQLzsKQDv4aqrRNQVAsu3felyhCEAYWMwgJvwDQP\u002fIZWScVAdASbmnWzewA0D3\u002fHdLdegJQG4a\u002f0gCPgVAkTu52dFq8z8LIKdLNmQDQOoaN3nD7ghA3UBkWNRYBUAN5Q1LXXEGQNzazF3iXwNANmV5vVsxCEA41P7GQqsGQNSJhSz6ngVA1j0et3wfB0CLmypmd3sGQHLtko4VFwNA8XpwGmgzCED0WA\u002f9vD8FQDHFsfMZlQNAOQW6X\u002fKxCUBj7y5vonMDQM\u002f61t43vgZAMre4Us8zB0BclnYHsawJQMCYOXH2MAZAsFTYE5M4CUBjAoJiPHnXvyjlggSYIAJA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2025"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate (1)","showlegend":false,"x":{"dtype":"f8","bdata":"jDu5tUVUtr8="},"y":{"dtype":"f8","bdata":"epbmhQnq3r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2025"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor (1)","showlegend":false,"x":{"dtype":"f8","bdata":"v93xKZ18AsA="},"y":{"dtype":"f8","bdata":"YqmXuQVCAEA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2025"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language (4)","showlegend":false,"x":{"dtype":"f8","bdata":"NnclkuhzCMBXD9inY8cCwFh\u002fgMexDQXA0G7nrgy7l78="},"y":{"dtype":"f8","bdata":"EERziKiq7j+CzYFlsoTwP\u002f7byXJu2\u002fY\u002f2PKiuCTN7j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2025"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal (1)","showlegend":false,"x":{"dtype":"f8","bdata":"lBzrFRl5BsA="},"y":{"dtype":"f8","bdata":"eCgjdWS42z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2025"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length (1)","showlegend":false,"x":{"dtype":"f8","bdata":"N3RPJw72\u002fr8="},"y":{"dtype":"f8","bdata":"kTu52dFq8z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2025","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2025","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2025","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2025","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2025","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral (20)","showlegend":false,"x":{"dtype":"f8","bdata":"MKdWg4OCCcCQu3GjqJHuvyUJ\u002f5\u002fvOwXAK061Nm7fxz9yb8JlM8sIwCpYlOF3ZwHAH1eDBP6QCcDzV136o7LwP8uruE9X5Oo\u002fLS8RYB9LtD8Sj9DxerDTvyVIJEI9h9Y\u002frh4if+AD4T9iVp5kdpYDwGXy0nkfdAjAeIx75yoTBsChiVSmvCkJwIPdnLS2BOA\u002fFKhAWOH2BcCnAa4dW7kFwA=="},"y":{"dtype":"f8","bdata":"kSz3Be2l7b8G77rNVs38v8bMBeqg4fO\u002f00BJosIvxb8gXr\u002f+3\u002f7kv0kAZolXheO\u002fGfK1DWVp7b8IeSnrwCq8P64af\u002fpO3eK\u002fSHIA7tVknD8mc1UcNIr4v8jWG1xQJOk\u002fijddwLrC+b\u002fAoKmANMPzv13YBlci8vG\u002f2uzP3pPc8r8SSREy7pPvvxCOFBK4+ey\u002fHMH453oO7r9xDj9NF2vxvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2025","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2025","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2025","Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2025","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2025","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2025"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual (6)","showlegend":false,"x":{"dtype":"f8","bdata":"N9Xj0Lu96r\u002fCTFSusaoFwJS7CgA+AtM\u002fV5LDTLQcAcDAM4S8V\u002frfP0Yx9Wgp6QDA"},"y":{"dtype":"f8","bdata":"d2J8gs\u002flA8DsZftRvqf+v07dae5iOOC\u002fkPPs5qcN+b9XXTZ+A3L5v2kKvUJnLfS\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2025"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"cNT6QBgR+b8="},"y":{"dtype":"f8","bdata":"ubzF1WhCA8A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2025","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2025","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions (4)","showlegend":false,"x":{"dtype":"f8","bdata":"daYAhnCJ2z\u002flZdrBPnn3PxlTMOKe++A\u002f3KPz2KUp8z8="},"y":{"dtype":"f8","bdata":"eBvK7Hdrtz8QJuptplvWv4LNLfZvuwDA5GBfe8w6r78="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2025","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2025","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2025","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2025","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2025","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization (31)","showlegend":false,"x":{"dtype":"f8","bdata":"WhYT1zbPyD\u002f76eyx0+riP0TYFgiVheW\u002f1pdps9bk8r88T2ezqeTkv0Na5xmvFeG\u002faXCk99nE5j8bD3ilWJTfv1xUEjf\u002fQNu\u002fCIark+ig6j\u002fX0bEvR0nZP49BRXzOz+y\u002fpj\u002fa6ZIT779yEjg4KjnevzouDn0xn9q\u002fqjgJC0xP578ktl7ENFzuvxQyqrp2HtW\u002fOgslAP7d5r8icaDeKf\u002fbv8DgxqGB2qm\u002fRDOaxToO2L88L2DBt3bgv9p2rnxXgcG\u002fFh8Ve6wq5r+SnuanZXHsv+Qt0rkqJcu\u002fbHxsU9usyL9ptORBkFziv\u002fJoM7bgT\u002fg\u002f0MOKSEXs5L8="},"y":{"dtype":"f8","bdata":"rzh9cXs3BsCRPAapxii5v08en8w02QnAxtCizBrAC8BGc9P\u002fQCAMwCQDtgYVbAjAiqcFMZM81L\u002fMiD55QzkGwBzdIho8pAfAQhJQVRuB4b8dQR3pBz7nv+YUuQpx7v2\u002f1JCgI+46CMAWGcNts7sGwHMiMZmL+AfAO8PppE1JCMD89DyswJsIwBheiXsSygjAPs9ugxfDBMASKnbPwz0GwL0d11VCVwXA+Vi67PONCMAH8oYN2ZUHwJ7R5pAjFQjA8d7YOvgBBsCedvDJuS0KwFpcVUP66gPAwp0guhbFB8CUmajJ5UYHwCjF2pm6yKg\u002fDTv4EANlBMA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2025","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2025","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2025","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2025","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2025","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2025"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political (6)","showlegend":false,"x":{"dtype":"f8","bdata":"CA8\u002fULlJ+D9q\u002fQ0V7yf6P2oXMlYpuvg\u002fWDyTHkGD9T8Sj9DxerDTv7Ifcy9a5c0\u002f"},"y":{"dtype":"f8","bdata":"dwSrNdRn+b89P9arhub7v4BsoSPXo\u002fa\u002fGcFGfcfUtT8mc1UcNIr4v5q1uDz7Bw7A"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2025","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2025","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2025","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2025","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2025","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2025","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2025","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2025","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2025","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2025","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2025","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2025","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2025","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety (62)","showlegend":false,"x":{"dtype":"f8","bdata":"kLtxo6iR7r831ePQu73qv1oWE9c2z8g\u002fMFZEXNrD2T9kKsEyS4\u002fyP3ZNjBxFGf4\u002fHlVOuO0FAkBj1YeDgJHzP5yhDRKTofE\u002f2Ud\u002fVp8R7D9+qmTokUf0PyU3dT\u002fOOvE\u002fhoMKzl9Y8j\u002fgdlgwpe3NPxv+F1iLa+M\u002feJietk5L9D+MO7m1RVS2v1nvAFKdZ90\u002fPR2Vagxd8j+usBCAWnH0Px21+vzxT+U\u002fdpbas4v88j9\u002fM0kYoq33P9sK48JldO8\u002fiuCBvjab9j+NeaPI6PgAQEYG2QS0FPE\u002fGUzMzKa38j\u002fAx30HC8fxPzVit6A3uu0\u002fUw5\u002fnTyW3j\u002fUPppnC4\u002f2P+wfCipruOU\u002foqzz7DHz3j9uPND\u002fA7PqP8AzhLxX+t8\u002fJImldq7z8T\u002ftGVaZXvnxPyT8tdGV1\u002fI\u002fOi\u002fs4D3z1D++TyogiFLzP4MOJLEk1+8\u002f9yqtsf3X7z+8JLd2yHnzP57B2\u002f6tf+Q\u002f+ikKpvbv\u002fT+t0ofv4EPvP9rUay8Zk+o\u002fjgPPk3HF7T8rwop6vc\u002fwP\u002f1pO\u002faOQuc\u002fLHnemHq94j+sp99RXnoBQBSEvViC2OY\u002fbzsgOm2\u002f5j\u002fjYF2YWffwPwqMmPqbLeY\u002fp0r9IU4H\u002fz+7uNogRfD3P9sADTKTBPE\u002fv682mtg80r8SCfUB6rj4Pw=="},"y":{"dtype":"f8","bdata":"Bu+6zVbN\u002fL93YnyCz+UDwK84fXF7NwbASvdzbJYCB8D8UtmQv4eoP8jKmdqx5QLA2uMKaqBJ779NKdEHQWIFwCDzMi+5YwnAiZHy+z+NCsCifXUn0DcFwHQTJsNq3gbA75ufZPkMBcDMdnJUVTcJwI+pYo5vFwbAeC+ssHjXCcB6luaFCerev3ZV4mvL9tA\u002fdRIe6wCHDcCLJp0JGjoIwOioyLiPRgXAjayHcwVvCsDo9d9FwZzBPxJRghHDmAPAlokD2BGCBcAi1RDNl7fGvxluJj6GhQjApos8uEeKCMDOLqpgwZMGwI6GafRyJQPAkFHRrzSNCcDVvo5yHn8KwOP0ybNGtwjAfkipOB7dpD+\u002fyh7XLuYFwFddNn4Dcvm\u002faAQUSFqkC8CiL046jjsFwGbZPKI1GQvAKOAgjhJkBcALnhy1TU0HwHmGqBNBRQnAvd5RfgowBsCRNyff9SUHwK+N17fGjQTAzuw90ZGH+L\u002fYbhOfPQgJwHhBbfZJdQrA05ZgHVJqBcBLfIElrsoHwOi15Z1AWwTAShGS+4sNB8CFFBy9nBr9vyyVcBMOqwXAvbI92WXxCsBNx5SI4goFwCTI7w1gSgbAqLJW5U76\u002f79NvjPFE24CwPIMxgNIfQbAYwKCYjx5179V04zXXxoGwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2025"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism (1)","showlegend":false,"x":{"dtype":"f8","bdata":"rh4if+AD4T8="},"y":{"dtype":"f8","bdata":"ijddwLrC+b8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2025","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2025","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2025","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2025","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2025","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2025","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social (18)","showlegend":false,"x":{"dtype":"f8","bdata":"TY8vYpJvAkC\u002fLuPgaacCQIgvl++q2vo\u002faor1+0LwAECqzSBMzDsEQFSAwW2q\u002fwRA4sZaFJ3BAEBJz6DETSQGQPhatwog6P8\u002fGVMw4p774D\u002fX0bEvR0nZPwJFIB\u002fMFwVAav0NFe8n+j9wrG8q\u002fZ4BQMJbIJd9av4\u002fbfwhNK5CBEAP7vNre9P\u002fP\u002fJoM7bgT\u002fg\u002f"},"y":{"dtype":"f8","bdata":"BT1DS2oj\u002fL\u002fa913rQOn\u002fv3ESPQFbwP+\u002f3vQowuKH\u002f7\u002fXLk8whGUDwKhB2+pLh9y\u002fr\u002fs1bnqTAsCuZQeOf2vkv5qYHk0iiqq\u002fgs0t9m+7AMAdQR3pBz7nv5CaYSPeBbY\u002fPT\u002fWq4bm+7+V4qKCAhQBwNhRZNkyOv2\u002f0D7a4qK0wT\u002f4e1E9qyP8vyjF2pm6yKg\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2025","Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2025","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2025","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2025","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2025","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2025"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity (6)","showlegend":false,"x":{"dtype":"f8","bdata":"dk2MHEUZ\u002fj\u002fUbymkMmADQDoen422LQVA+cEDMRl2BEC7uNogRfD3P4rKg9Um6gNA"},"y":{"dtype":"f8","bdata":"yMqZ2rHlAsCKxaJMLx\u002f7vywtXofpcfi\u002fdPYIguiH+79NvjPFE24CwDqDpl3lQO6\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2025","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2025","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value (15)","showlegend":false,"x":{"dtype":"f8","bdata":"llWVR0s2DECQ9JdpjUcIQHTN04LkgwZAzMBIj45hBUB5VpXQHQYPQCZ7cJg8igRA+ikKpvbv\u002fT\u002fiinHCujIIQIPdnLS2BOA\u002fDCAeexfFB0BB64XOaysJQKyn31FeegFADAfTUkL3B0CnSv0hTgf\u002fP5o7G52\u002fJgtA"},"y":{"dtype":"f8","bdata":"KqJ3FkEy8L\u002f4kO+ZUcbjv2sYL9IG5Om\u002f5TiZdZm45b\u002faTua5Az7qvwePeiwrtuK\u002fzuw90ZGH+L9zkLOpEWzwvxCOFBK4+ey\u002fpwlp\u002fOX587\u002f5Pu8BXULtv4UUHL2cGv2\u002fgGWt\u002fHIK7r+oslblTvr\u002fvw6bPuHHU\u002fe\u002f"},"type":"scatter"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scattermap":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermap"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"font":{"size":16},"text":"Multi-label Clusters (All Years)"},"xaxis":{"range":[-4.5,4.5],"title":{"text":""},"showgrid":true,"gridcolor":"lightgray"},"yaxis":{"range":[-4.5,4.5],"title":{"text":""},"showgrid":true,"gridcolor":"lightgray","scaleanchor":"x","scaleratio":1},"height":800,"width":1000,"hovermode":"closest"},                        {"responsive": true}                    )                };            </script>        </div>
</body>
</html>