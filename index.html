<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />   <!--It is necessary to use the UTF-8 encoding with plotly graphics to get e.g. negative signs to render correctly -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Visualisation of Alignment Survey</title>
</head>

<body>
    <h1>Visualisation of Alignment Survey</h1>
    <h2>Papers from each year (2022-2025)</h2>
    <div>                            <div id="10515908-831b-4c61-bf14-b91c42c9c345" class="plotly-graph-div" style="height:700px; width:900px;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("10515908-831b-4c61-bf14-b91c42c9c345")) {                    Plotly.newPlot(                        "10515908-831b-4c61-bf14-b91c42c9c345",                        [{"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"bias","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"cultural","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"culture","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"demographics","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"diversity","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"ethical","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"factuality","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"faithfulness","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"general","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"hate","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"humor","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"language","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"legal","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"length","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"moral","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"multilingual","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"offensiveness","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"opinions","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"personalization","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"political","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"safety","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"sexism","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"social","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"toxicity","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"value","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2022"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity","showlegend":false,"visible":true,"x":{"dtype":"f8","bdata":"QcTlUpvn6j8="},"y":{"dtype":"f8","bdata":"cArELGj8AUA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general","showlegend":false,"visible":true,"x":{"dtype":"f8","bdata":"+Y86zfYk8b\u002fmVgp1xgTuv7vMY7x2iPC\u002fiGmDEdMG878="},"y":{"dtype":"f8","bdata":"Iia87TxWA0CRGi0AYe0DQJSGgyX4NglATTu+wEPWBkA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral","showlegend":false,"visible":true,"x":{"dtype":"f8","bdata":"u54trD6UA8A="},"y":{"dtype":"f8","bdata":"wHpg+B2J8L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization","showlegend":false,"visible":true,"x":{"dtype":"f8","bdata":"IZ2TZPrs4L8="},"y":{"dtype":"f8","bdata":"qv0g9NbgBsA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"wLZPHFmJCkA="},"y":{"dtype":"f8","bdata":"VcJn\u002f27Q7z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2023"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"g+o8T29q9j8="},"y":{"dtype":"f8","bdata":"ZRIs8oL9BEA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"twhPOiDi3z8="},"y":{"dtype":"f8","bdata":"u6PDkVboDEA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"j2Rgu4Hm8b+aQ2sVvUbxv7qUehBdTPC\u002f+EK9NT9C7L9Ou3Qr1gPivym+eeDGpve\u002fw\u002fZ0a5bb9b9sFlxxkdT1vxSKpW5wpvK\u002fjU+htdoe9b\u002f8FnsK7YDzvw=="},"y":{"dtype":"f8","bdata":"+NNB6LYuA0D9Re1vFPsGQJrdkmjoDQRAR5K2+rahBUCGJSMFT58KQFiRPVRY4AJAWgWQ3NWCAUCuz1Wk8vgGQDHNcqynggVAlsNJxQ5yBkCVR57fasQCQA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"GsFBA5MABsA="},"y":{"dtype":"f8","bdata":"0m21ehjJ6L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"U+LBxU44478="},"y":{"dtype":"f8","bdata":"XEuxPTq5BsA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"wMDIji5uCkC3pS15iWj1P18dDS6OKvw\u002fyHfpV3\u002ft+D97iGhJZdQBQJSmqHqqs\u002fY\u002fo7VLmWT9AUBLjr+JQ+IHQMtr2\u002fn87\u002fE\u002fe0ceoyMb\u002fD9W1kdcnRn9P9X9ych4KgVAviYUB2wK7T+iPbZCjcsGQH8WTlRYfQBAOOqgFmSizD9iXicF0FjsP6\u002fOVU4ozghA"},"y":{"dtype":"f8","bdata":"1BMAwTlH2b+eZQDVSxjNvzVpg\u002fnnEva\u002fqkgfygiVy7\u002ffvZGa8GHSv03qlRgkCNW\u002faoJh8OmrrD+6gvuzxcjBv+Sq6I9vo6o\u002fUlhAfZ25+b8qDLnMV7n1v5uvo\u002fC4FPQ\u002fur2SMI94zL\u002fgSThak2jiP34FJw8xE\u002fg\u002fqMXKmYOJ9r9gHsEP5E\u002fxv3jFAKyV8+o\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2024","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2024"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"VQejyXvwBkBEyCsZyCIIQN2E5gLqmAdAwMDIji5uCkC3pS15iWj1P2hypbIyUvU\u002fX8J0jR9EA0CUpqh6qrP2P6I9tkKNywZAxGgHtpmh1z9uDO\u002fGIIbDP+jjhSjBWdk\u002fswdWBONMBkC9hoQ\u002fBqUIQAoOFeuhGL+\u002f"},"y":{"dtype":"f8","bdata":"WB7J5\u002fuX4D9wcfnL5bDwP8QerIJZjfE\u002f1BMAwTlH2b+eZQDVSxjNv3nCWE8Umu6\u002fzJGSMmE45b9N6pUYJAjVv+BJOFqTaOI\u002fsJTZtm598r9uWc8vvmvKv92qJ0gipuU\u002fs5ksZbYy2j+ucP0VTlTjP9o385uH8eU\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2024","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"GvRCdJEaAUDId+lXf+34P3uIaEll1AFAo7VLmWT9AUBLjr+JQ+IHQMtr2\u002fn87\u002fE\u002f2Mb70RLL9T\u002fV\u002fcnIeCoFQK\u002fOVU4ozghA"},"y":{"dtype":"f8","bdata":"bByX+r\u002fM+T+qSB\u002fKCJXLv9+9kZrwYdK\u002faoJh8OmrrD+6gvuzxcjBv+Sq6I9vo6o\u002fyVyg49nSAUCbr6PwuBT0P3jFAKyV8+o\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2024","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2024","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2024","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"Wr1t6Ijy7z8+cnD68YHxPyHpjaRrpOE\u002f2Mb70RLL9T9\u002fFk5UWH0AQOjjhSjBWdk\u002f"},"y":{"dtype":"f8","bdata":"g2\u002fhv+kZB0BApi2XLy3RP\u002fGP02I\u002f3cq\u002fyVyg49nSAUB+BScPMRP4P92qJ0gipuU\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"AK9KtLV\u002f8T8a4GWUWlfqPw=="},"y":{"dtype":"f8","bdata":"Hd7wYAqL7b9MhZAZNVcIQA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"TPgcQP4o0D+Y9ERJZAbQv7eGx8t7Quc\u002fUC4t8EwVzL98qWyrpVywv6ZyNm0Tj8O\u002fyEU5XYedp78+J\u002fDhxtnmP91TrH1jCNs\u002fviYUB2wK7T9AhIEA+ILSP9N2MUGFyNM\u002fxKDxMLu+7j\u002flDWXPMKbUP8xGruAeUrm\u002f"},"y":{"dtype":"f8","bdata":"FOsLNEuFCUC7AWj2r8AKQChf+EBPXsU\u002fLFf3aQHGAkDda5iV7fAJQFDn97MBVQ5A6DtlhDZACkDejD41QJXhv4hRZlgcSgdAur2SMI94zL\u002fQm2FVkkYGQK6oFPVaEQVAOAMOFw7eCUCSluy6gIoNQAD\u002fOo0nRgpA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2024","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"Tqw9mTkc+7+HJZo3m+zyvyNeYRf8i\u002fS\u002f7trmNSGW8r+O0EuR+434v+aR5MRzhuy\u002fcWIyq\u002fCi6b+Yc8U6ppjtv6QPRk7AM\u002fa\u002fGIWYLVjB+b+kbSsqpb\u002fcv5T97MLklfu\u002fdoBKgbtG8b+qtlGfnib6vzayPrZRev2\u002fVKZ9UcCS878hAM7U0gv0vzGdfuQsjvK\u002fpJmeUltS87+yB8fqz\u002f75v5WCj8RA4PW\u002fhiE9qTS8xL8G\u002fLGuMgbxvw=="},"y":{"dtype":"f8","bdata":"NIa8ZWZkBUBZnCMoQwUIQENBmanwFwVAH9B2hTFYB0AoOtoJ9OAFQISFjLCU5QNAqI8wj3NdCEB9z\u002f8RrAsEQLYZAG0DHgNAw+4uXGWJBECKAExKZp8CQI96oJSZAQVAGujj1VndB0Bh5OYACRQKQIJGJRQBuwBAK8t6WniTB0AF21BgIE4FQMMOTDoq\u002fwFASxfD4O1NA0BAD44iEkUFQJ4GauI7hANAtoMZF2+sxr+mQqYy+DQGQA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2024"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"UBFDMdJv5L8="},"y":{"dtype":"f8","bdata":"WO5zTbOwtT8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2024"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"ELyQxKpZAcA="},"y":{"dtype":"f8","bdata":"rDQB0Vi6\u002fT8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2024"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"Cg4V66EYv78="},"y":{"dtype":"f8","bdata":"2jfzm4fx5T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"UcFj+O0RCMC3pS15iWj1P5SmqHqqs\u002fY\u002fbgzvxiCGwz846qAWZKLMP+jjhSjBWdk\u002fYl4nBdBY7D\u002fKBixm+zwFwDlqRAKFFAfA"},"y":{"dtype":"f8","bdata":"gmRWTS2g+7+eZQDVSxjNv03qlRgkCNW\u002fblnPL75ryr+oxcqZg4n2v92qJ0gipuU\u002fYB7BD+RP8b9qbPmJiEfqv2aHvDHJjPC\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"+9Ld9WRxAsDEaAe2maHXPyYLXEilGAPA"},"y":{"dtype":"f8","bdata":"mE2\u002fJu8d\u002fr+wlNm2bn3yv\u002fudSqmYu\u002fy\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2024"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"j9a6sVj0\u002fb8="},"y":{"dtype":"f8","bdata":"zZ\u002f\u002fK6GvAsA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"yHfpV3\u002ft+D+134\u002fNjVPcP8tr2\u002fn87\u002fE\u002f"},"y":{"dtype":"f8","bdata":"qkgfygiVy78YeEUhbbcEwOSq6I9vo6o\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2024","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"cjuwsWpW0j9ocqWyMlL1P+DLjWZPHuG\u002fKhetk7I54b8h6Y2ka6ThPwCvSrS1f\u002fE\u002fYJp58dmIsr8RgJbMHFbdvyHjwT1lE+W\u002f"},"y":{"dtype":"f8","bdata":"YcwuoFwGB8B5wlhPFJruv7D1ICzrBgjAcoVvK7\u002fkCMDxj9NiP93Kvx3e8GAKi+2\u002fsMfaKc0GDcD0WeJFZ5AIwLO5+rfyJAzA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2024"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"Xx0NLo4q\u002fD97Rx6jIxv8P1bWR1ydGf0\u002fviYUB2wK7T846qAWZKLMP7XAuhHWw8G\u002f"},"y":{"dtype":"f8","bdata":"NWmD+ecS9r9SWEB9nbn5vyoMucxXufW\u002fur2SMI94zL+oxcqZg4n2vxngBwb9qwvA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2024","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2024","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2024","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2024","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"AWcByWf95j+di5v3xNbxP1K6n1jbDug\u002f0q3u7+Ry9z9itYKx6HLlP8jmeCLuwPA\u002fDK8\u002fOAOq1T9QEUMx0m\u002fkv7eGx8t7Quc\u002fI8+8YRxH6T\u002f0CDyZX4j1P8XKfemeFOo\u002fK\u002fKdwY619j8+cnD68YHxP+Fz2JKVrd0\u002fZE9cSK6i5T97iGhJZdQBQPRFo0Q2hOw\u002fdzm8uIKn7T9cbrXrMf3rP8lm2BUtyOU\u002fhJZkNIUK7z+By+e562jgP+BigaAbqNo\u002fPifw4cbZ5j8XLOFLFprqP8RoB7aZodc\u002f03W8WOs39j99VuZfhGDpPxbintyftNc\u002f5NwmhIs\u002f8D\u002fT6paCW0v\u002fP8E0J8vWNPU\u002fDxq3nwLV4z+GIT2pNLzEv8r\u002fymanHd4\u002f"},"y":{"dtype":"f8","bdata":"ExR9bIQABsBsQOxkZrIFwO8K3T1OsAfAoFGpzF1jBcDgLyEQU0cJwMSKZh+BFQzAZutsuxs+B8BY7nNNs7C1Pyhf+EBPXsU\u002fQRPAsOmUAcB3CX86ypIDwDbPwQXnfATAWZMudEhjCsBApi2XLy3RP14aZSlMUQbAr95+qdjlA8DfvZGa8GHSv+4TzqGyFQfAjAf8IvM7AsA0qYu4Ub4DwCphTKTBrgvAv+HNL5w5CcBmOtsh6R0HwK5EzJ4LMQfA3ow+NUCV4b\u002fxleS4NH0FwLCU2bZuffK\u002fLNz6fx3sBcBLOPOsdH0BwConUmZ60wXAnoK8iMPkCcAII7hQOqEAwIq0dlu7xwHAEBMJOexvBsC2gxkXb6zGv0P47rifQAfA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"Yl4nBdBY7D8="},"y":{"dtype":"f8","bdata":"YB7BD+RP8b8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"wMDIji5uCkDoJosIeA8EQF\u002fCdI0fRANAo7VLmWT9AUC134\u002fNjVPcPwCvSrS1f\u002fE\u002fS46\u002fiUPiB0B7Rx6jIxv8Pw=="},"y":{"dtype":"f8","bdata":"1BMAwTlH2b\u002f6GEzn4ncCwMyRkjJhOOW\u002faoJh8OmrrD8YeEUhbbcEwB3e8GAKi+2\u002fuoL7s8XIwb9SWEB9nbn5vw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2024","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"t4kgQXY2A0BCrNiEBQ0EQD5RzfAYZgVAwTQny9Y09T9gj5GSOCoEQA=="},"y":{"dtype":"f8","bdata":"\u002fVJu\u002f64G8L8A7YTRamHwvyRxgB2zcPW\u002firR2W7vHAcCUEkCMgUv0vw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2024","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"0+qWgltL\u002fz+xErJCtp0CQA=="},"y":{"dtype":"f8","bdata":"CCO4UDqhAMATmBPhtAHgvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"CUwWEXARCEA="},"y":{"dtype":"f8","bdata":"85G\u002fJbuj4z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2025","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2025","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"PANz+WA0tT\u002fMkEr9e5HIPxZ9lOs89AhAgnfLXs\u002f4AEAJTBYRcBEIQI8m34X1QwBAPysnTGR9B0DgyVS9dP8CQJO5oJtPzQhAMvA\u002fzwGfCUCuPCG2oogEQLq5WVQhIglAlO3gLogZ+T+qpD\u002fStYj3Pw=="},"y":{"dtype":"f8","bdata":"IcS987S1278rLDTGpQ\u002fTv6eKXHlmF9o\u002f0SPvq6JK67\u002fzkb8lu6PjP6dEV+T8uOY\u002fjKRMcLAI8j\u002fABOQNCsveP+D2\u002flddJfY\u002f0\u002fBYUagz4j8xwl083mHaP+oLL14wfuM\u002fQKQgKu7t\u002fD\u002f0Q11R1Ua6Pw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"HkaH6SzQBED4whb82pkIQDRTF5b3OANA"},"y":{"dtype":"f8","bdata":"rAmnZhVI9z9NzeIUjAfpP\u002fpU87fsYfI\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2025","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2025"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"gSES7qOp3j95VUFJ7G8BQHDND3nLWgVATiceAb94BECkuNdhq1gCQA=="},"y":{"dtype":"f8","bdata":"4Kpha5vRnz9Fubht0o3+P\u002fpRA8PX5wBA2s56TUG4\u002fD8jXvMBOTO0vw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2025"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"TXaRBjZA9j+MlQGzHgHFPw=="},"y":{"dtype":"f8","bdata":"Amc4iz1B1b9uqs7gtd7Kvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"0V46T3FK8D9TNRmahsHpP2CQQXJVrOo\u002fqqQ\u002f0rWI9z8="},"y":{"dtype":"f8","bdata":"Mzi9HDZpBUC4hmWl\u002f1kHQJxKjwphJQhA9ENdUdVGuj8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2025"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"GuJ+gWdK2T+uEcA1ilnZP4gm0nrlfeY\u002fujsumOBM5T+U7eAuiBn5Pw=="},"y":{"dtype":"f8","bdata":"gYRV4RS6B0D4U1Q\u002f4xkGQKLAiqDw2glAd4i8MyF7B0BApCAq7u38Pw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2025"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"XmBFETQ01r8="},"y":{"dtype":"f8","bdata":"LMpP6jeOB0A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2025","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"WiXGkyVp87+2O6lnZqnyv5YK6LDXs\u002fe\u002fpnikSWxp8L\u002fRhBhmgmP3v+YkhswTXPO\u002f9RN+9AF58L\u002f\u002fb\u002faYH5f2vy+9is8a5fS\u002f1iDMBQ3o87\u002fYVvvc1W72v6AcGlb7lQDAZg2sBnxR9790+wxxS1Dwv3l8+oMRJPi\u002f9btGiNyj9r\u002fnVzJjQHTzv2qJNngsTPe\u002fBjRH7ujO9r9F4OAhTE38v7FwxubsL\u002fe\u002f9z66dOqH9L8yRPSSG6zzvwN7CRO42fO\u002fthy\u002frCJY9L\u002fjDI+0OqHyv4CJ6GieVu6\u002fJNS2G7HOAMDpmEYdeCD2vwrcf9PpDPe\u002fQgN8\u002fdgT6b8="},"y":{"dtype":"f8","bdata":"dxO7zeoqBkATp7d+ibgFQEi62LQeSQRAHQovHnNPBUDkGM5RinIDQLZ+0Wb2TANAF2jEb6mrA0BmxEgRvZADQNDxqXXKCgdAvEfzqd\u002faBUD2OxOpyWUHQKaAVVmyoPY\u002f0jBjU8P9BUDIugh\u002fjgUKQGkLsxp99gVAfzeoEsPtBkBWcwqpX7sEQA3x+0ffuglA0ntU1WcxBEBRQYHnGLAIQCFrMhoA1gRA74PQ1bWwBkCtGjsNVy0FQFqK\u002f1TzhgFAOVFjwv6ZB0CIuWnIrjYHQMrArsUVDAhAY7ePi9fiA0BG5r7TVJMIQKP124rpcwZAl6WkbALUA0A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"5anFOYP\u002fBMAhlfNLQOYDwNkXGchm2QbA"},"y":{"dtype":"f8","bdata":"Sc\u002f8MMvP9T9Atod3FUP2PyrF6uCrueM\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2025"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"3P74mldVA8A="},"y":{"dtype":"f8","bdata":"ncm355lo0z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2025"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"oBwaVvuVAMA="},"y":{"dtype":"f8","bdata":"poBVWbKg9j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2025","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2025"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"Zrxybwz1BcA8HbroZRDwv0l0JUvcWgjAPANz+WA0tT90PAa883QIwEfixnCsZgjAvgBjMGdPCcAVv7k7QzAJwByHphef1c4\u002f"},"y":{"dtype":"f8","bdata":"GJHNP4A99r86FKHfLFz9v9JwUjQBGfW\u002fIcS987S1279a0QTzwH70v0pjduMG0\u002fK\u002f4xRpNZzs9r8sh8ZFx775v16P75sxH\u002fS\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2025","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2025","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2025"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"bfez8jWj579TnnS+yogBwMyQSv17kcg\u002f"},"y":{"dtype":"f8","bdata":"zKn8XvmlBMCyN10cYAn4vyssNMalD9O\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2025"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"gSES7qOp3j8="},"y":{"dtype":"f8","bdata":"4Kpha5vRnz8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2025","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2025","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"nXSVvLM\u002f0T+MlQGzHgHFP8DBQ0SSRe+\u002fjDTrW4pc2L+SXOZ7ieflv4btJsjjUeC\u002f+rdwjvDLyL\u002fiBKyjd53kvzzCeIomw+q\u002fNkKN1TQAx7+L4O2aCW7pvwKn5DDy6s2\u002fbFffKA7T178wKcuS+Obsv2Hmo9PhqfC\u002f2UWXhSc7279SkKcJJMPHv54TkYuLgti\u002fZhcoNoYf1b+qpD\u002fStYj3Pw=="},"y":{"dtype":"f8","bdata":"cFg8Kbr5BMBuqs7gtd7Kv5yunLmeNgbAY9C7Zz2PBsCX5hqFRXgJwPcN2S9i4AjAQSRRDWygCsCobM\u002fZG0EHwNIjj5uCEQfAHeKpvfPGCMCIKRMPj\u002f8HwHQ+D6egSAnAuny7V0gPB8Deb5H+oM4FwH2Gag2mNwbAFVRROMx1CMB\u002fkJ4oKJAKwBTUmtlAgwXAflV1ALvTCMD0Q11R1Ua6Pw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2025","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2025","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2025","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2025","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2025","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"PB266GUQ8L9t97PyNaPnv510lbyzP9E\u002ftC8+8X839j9NdpEGNkD2P8sUAKbotP4\u002fgnfLXs\u002f4AEASwgh4KBbqPxYDIxwy4+4\u002fW7dBbMA+8T\u002f4OUpLKhjwP6IP4P0SoNQ\u002fkVGKXJHU6T\u002fAD9NDtlfxP+Dm8g4CJ+g\u002fcJj7htfE5D8dc05FFPj\u002fPz2IGeAB2PI\u002f1T9++ByR7D96nPiImfz2P2YRCZlA9e0\u002fCla2+LhF5T8U+MI7fvfbPwdzpzlznv0\u002fccaQ4SDD7z+GUSP633f0Pw=="},"y":{"dtype":"f8","bdata":"OhSh3yxc\u002fb\u002fMqfxe+aUEwHBYPCm6+QTAb7P\u002fwLBbBcACZziLPUHVv1aXYJOMdwDA0SPvq6JK679GyGnBBXgFwOy+ScpYhAjAQsDzni4RBcCmgjCEdtUDwPqxMaumXwXAqx2JPX9lCMDBOfkXXVQIwIu9LbkRSAbAp7ugZ73yBcD0Ms1n8t7+vwYbtajKYAnAy1B3DN8MBsDZHSnEIHwEwN2aT8I8vQrA\u002fG6Yga\u002fsBcDhdzAHoHkGwIYzNJYiQ\u002fi\u002f6zi9At6\u002fCMCEZ0GZCNUHwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2025","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"f7UQIWY3AkAzmFZYHIoBQJfZwNaumgNAvCwQAGh4A0DNYd\u002fZovADQAxjSoXnggNAY6KOluTn\u002fj+kuNdhq1gCQCrQEqQghP4\u002fqqQ\u002f0rWI9z8="},"y":{"dtype":"f8","bdata":"6KK9GAMzAMCKppVyeXYBwLgkUoOeGP+\u002feAuq3XZ\u002fAMAiUOJpo8ADwBK7\u002fX1PTgHAhPWorSE6AMAjXvMBOTO0v\u002f9nfdS7bgHA9ENdUdVGuj8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2025"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"yxQApui0\u002fj8="},"y":{"dtype":"f8","bdata":"Vpdgk4x3AMA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2025","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"qOrsXgW3CEAobSJ2qjIGQKtM2EkwEgdAvgKjNyhiBkCwbJyaxVoEQO2gM0TBZwZAHXNORRT4\u002fz\u002fMB\u002fR8CioFQByHphef1c4\u002fzbLR7U\u002f1A0BBiJEg2rMDQAdzpzlznv0\u002fPVEjuSwtCEA="},"y":{"dtype":"f8","bdata":"npVq\u002fpyU3b\u002fkGP52UNrov\u002fXj13wPiOK\u002fuESbkST51L8NnjEZbmPhvxNI08tZpeG\u002f9DLNZ\u002fLe\u002fr9VyxqkjNXjv16P75sxH\u002fS\u002f3lxcO1Nw4b\u002fYxgW2QMzvv4YzNJYiQ\u002fi\u002fGS9evjRG478="},"type":"scatter"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scattermap":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermap"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"font":{"size":16},"text":"Multi-label Clusters for each Year"},"xaxis":{"range":[-4.5,4.5],"title":{"text":""},"showgrid":true,"gridcolor":"lightgray"},"yaxis":{"range":[-4.5,4.5],"title":{"text":""},"showgrid":true,"gridcolor":"lightgray","scaleanchor":"x","scaleratio":1},"height":700,"width":900,"hovermode":"closest","sliders":[{"active":0,"currentvalue":{"prefix":"Year: ","visible":true,"xanchor":"center"},"len":0.9,"pad":{"b":10,"t":50},"steps":[{"args":[{"visible":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false]}],"label":"2022","method":"update"},{"args":[{"visible":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false]}],"label":"2023","method":"update"},{"args":[{"visible":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false]}],"label":"2024","method":"update"},{"args":[{"visible":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true]}],"label":"2025","method":"update"}],"x":0.0,"xanchor":"left","y":-0.1,"yanchor":"top"}],"showlegend":true},                        {"responsive": true}                    )                };            </script>        </div>
    <br>    
    <h2>All papers</h2>
    <div>                        <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.3.1.min.js" integrity="sha256-4rD3fugVb/nVJYUv5Ky3v+fYXoouHaBSP20WIJuEiWg=" crossorigin="anonymous"></script>                <div id="07682821-26fb-4346-a621-74899bacfe39" class="plotly-graph-div" style="height:800px; width:1000px;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("07682821-26fb-4346-a621-74899bacfe39")) {                    Plotly.newPlot(                        "07682821-26fb-4346-a621-74899bacfe39",                        [{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2022","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2022","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2022","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2022","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2022","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2022","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2022","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2022","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2022","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2022","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2022","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2022","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2022"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias (19)","showlegend":true,"x":{"dtype":"f8","bdata":"CUwWEXARCEDAwMiOLm4KQLelLXmJaPU\u002fXx0NLo4q\u002fD\u002fId+lXf+34P3uIaEll1AFAlKaoeqqz9j+jtUuZZP0BQEuOv4lD4gdAy2vb+fzv8T97Rx6jIxv8P1bWR1ydGf0\u002f1f3JyHgqBUC+JhQHbArtP6I9tkKNywZAfxZOVFh9AEA46qAWZKLMP2JeJwXQWOw\u002fr85VTijOCEA="},"y":{"dtype":"f8","bdata":"85G\u002fJbuj4z\u002fUEwDBOUfZv55lANVLGM2\u002fNWmD+ecS9r+qSB\u002fKCJXLv9+9kZrwYdK\u002fTeqVGCQI1b9qgmHw6ausP7qC+7PFyMG\u002f5Kroj2+jqj9SWEB9nbn5vyoMucxXufW\u002fm6+j8LgU9D+6vZIwj3jMv+BJOFqTaOI\u002ffgUnDzET+D+oxcqZg4n2v2AewQ\u002fkT\u002fG\u002feMUArJXz6j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2022","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2022","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2022","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2022","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2022","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2022","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2022","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2022","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2022","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2022","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2022","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2022","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2022","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2022"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural (30)","showlegend":true,"x":{"dtype":"f8","bdata":"PANz+WA0tT\u002fMkEr9e5HIPxZ9lOs89AhAgnfLXs\u002f4AEAJTBYRcBEIQI8m34X1QwBAPysnTGR9B0DgyVS9dP8CQFUHo8l78AZARMgrGcgiCEDdhOYC6pgHQMC2TxxZiQpAwMDIji5uCkC3pS15iWj1P2hypbIyUvU\u002fX8J0jR9EA0CUpqh6qrP2P6I9tkKNywZAxGgHtpmh1z9uDO\u002fGIIbDP+jjhSjBWdk\u002fk7mgm0\u002fNCEAy8D\u002fPAZ8JQK48IbaiiARAurlZVCEiCUCU7eAuiBn5P6qkP9K1iPc\u002fswdWBONMBkC9hoQ\u002fBqUIQAoOFeuhGL+\u002f"},"y":{"dtype":"f8","bdata":"IcS987S1278rLDTGpQ\u002fTv6eKXHlmF9o\u002f0SPvq6JK67\u002fzkb8lu6PjP6dEV+T8uOY\u002fjKRMcLAI8j\u002fABOQNCsveP1geyef7l+A\u002fcHH5y+Ww8D\u002fEHqyCWY3xP1XCZ\u002f9u0O8\u002f1BMAwTlH2b+eZQDVSxjNv3nCWE8Umu6\u002fzJGSMmE45b9N6pUYJAjVv+BJOFqTaOI\u002fsJTZtm598r9uWc8vvmvKv92qJ0gipuU\u002f4Pb+V10l9j\u002fT8FhRqDPiPzHCXTzeYdo\u002f6gsvXjB+4z9ApCAq7u38P\u002fRDXVHVRro\u002fs5ksZbYy2j+ucP0VTlTjP9o385uH8eU\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2022","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2022","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2022"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture (3)","showlegend":true,"x":{"dtype":"f8","bdata":"HkaH6SzQBED4whb82pkIQDRTF5b3OANA"},"y":{"dtype":"f8","bdata":"rAmnZhVI9z9NzeIUjAfpP\u002fpU87fsYfI\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2022","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2022","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2022","Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2022","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2022","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2022","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2022","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2022","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2022","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2022"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics (14)","showlegend":true,"x":{"dtype":"f8","bdata":"gSES7qOp3j95VUFJ7G8BQHDND3nLWgVAGvRCdJEaAUDId+lXf+34P3uIaEll1AFAo7VLmWT9AUBLjr+JQ+IHQMtr2\u002fn87\u002fE\u002f2Mb70RLL9T\u002fV\u002fcnIeCoFQK\u002fOVU4ozghATiceAb94BECkuNdhq1gCQA=="},"y":{"dtype":"f8","bdata":"4Kpha5vRnz9Fubht0o3+P\u002fpRA8PX5wBAbByX+r\u002fM+T+qSB\u002fKCJXLv9+9kZrwYdK\u002faoJh8OmrrD+6gvuzxcjBv+Sq6I9vo6o\u002fyVyg49nSAUCbr6PwuBT0P3jFAKyV8+o\u002f2s56TUG4\u002fD8jXvMBOTO0vw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2022","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2022","Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2022","Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2022","Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2022","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2022","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2022","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2022","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2022","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2022"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity (10)","showlegend":true,"x":{"dtype":"f8","bdata":"TXaRBjZA9j+MlQGzHgHFP1q9beiI8u8\u002fg+o8T29q9j9BxOVSm+fqPz5ycPrxgfE\u002fIemNpGuk4T\u002fYxvvREsv1P38WTlRYfQBA6OOFKMFZ2T8="},"y":{"dtype":"f8","bdata":"Amc4iz1B1b9uqs7gtd7Kv4Nv4b\u002fpGQdAZRIs8oL9BEBwCsQsaPwBQECmLZcvLdE\u002f8Y\u002fTYj\u002fdyr\u002fJXKDj2dIBQH4FJw8xE\u002fg\u002f3aonSCKm5T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2022","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2022","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2022","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2022","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2022","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2022"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical (6)","showlegend":true,"x":{"dtype":"f8","bdata":"0V46T3FK8D9TNRmahsHpP2CQQXJVrOo\u002fAK9KtLV\u002f8T+qpD\u002fStYj3PxrgZZRaV+o\u002f"},"y":{"dtype":"f8","bdata":"Mzi9HDZpBUC4hmWl\u002f1kHQJxKjwphJQhAHd7wYAqL7b\u002f0Q11R1Ua6P0yFkBk1VwhA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2022","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2022","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2022","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2022","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality (21)","showlegend":true,"x":{"dtype":"f8","bdata":"GuJ+gWdK2T+uEcA1ilnZP7cITzog4t8\u002fTPgcQP4o0D+Y9ERJZAbQv7eGx8t7Quc\u002fUC4t8EwVzL98qWyrpVywv6ZyNm0Tj8O\u002fyEU5XYedp78+J\u002fDhxtnmP91TrH1jCNs\u002fviYUB2wK7T9AhIEA+ILSP9N2MUGFyNM\u002fxKDxMLu+7j\u002flDWXPMKbUP4gm0nrlfeY\u002fujsumOBM5T+U7eAuiBn5P8xGruAeUrm\u002f"},"y":{"dtype":"f8","bdata":"gYRV4RS6B0D4U1Q\u002f4xkGQLujw5FW6AxAFOsLNEuFCUC7AWj2r8AKQChf+EBPXsU\u002fLFf3aQHGAkDda5iV7fAJQFDn97MBVQ5A6DtlhDZACkDejD41QJXhv4hRZlgcSgdAur2SMI94zL\u002fQm2FVkkYGQK6oFPVaEQVAOAMOFw7eCUCSluy6gIoNQKLAiqDw2glAd4i8MyF7B0BApCAq7u38PwD\u002fOo0nRgpA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2022"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness (1)","showlegend":true,"x":{"dtype":"f8","bdata":"XmBFETQ01r8="},"y":{"dtype":"f8","bdata":"LMpP6jeOB0A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2022","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2022","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general (69)","showlegend":true,"x":{"dtype":"f8","bdata":"WiXGkyVp87+2O6lnZqnyv5YK6LDXs\u002fe\u002fpnikSWxp8L\u002fRhBhmgmP3v+YkhswTXPO\u002f9RN+9AF58L\u002f\u002fb\u002faYH5f2v06sPZk5HPu\u002fhyWaN5vs8r8jXmEX\u002fIv0v+7a5jUhlvK\u002fjtBLkfuN+L\u002fmkeTEc4bsv3FiMqvwoum\u002fmHPFOqaY7b+kD0ZOwDP2v49kYLuB5vG\u002fmkNrFb1G8b+6lHoQXUzwv\u002fhCvTU\u002fQuy\u002fTrt0K9YD4r8pvnngxqb3v8P2dGuW2\u002fW\u002fbBZccZHU9b8UiqVucKbyv41PobXaHvW\u002f\u002fBZ7Cu2A87\u002f5jzrN9iTxv+ZWCnXGBO6\u002fu8xjvHaI8L+IaYMR0wbzvxiFmC1Ywfm\u002fpG0rKqW\u002f3L+U\u002fezC5JX7v3aASoG7RvG\u002fqrZRn54m+r82sj62UXr9v1SmfVHAkvO\u002fIQDO1NIL9L8xnX7kLI7yv6SZnlJbUvO\u002fL72Kzxrl9L\u002fWIMwFDejzv9hW+9zVbva\u002foBwaVvuVAMBmDawGfFH3v3T7DHFLUPC\u002feXz6gxEk+L\u002f1u0aI3KP2v+dXMmNAdPO\u002faok2eCxM978GNEfu6M72v0Xg4CFMTfy\u002fsXDG5uwv97\u002f3Prp06of0vzJE9JIbrPO\u002fA3sJE7jZ87+2HL+sIlj0v+MMj7Q6ofK\u002fgInoaJ5W7r8k1LYbsc4AwOmYRh14IPa\u002fCtx\u002f0+kM979CA3z92BPpv7IHx+rP\u002fvm\u002flYKPxEDg9b+GIT2pNLzEvwb8sa4yBvG\u002f"},"y":{"dtype":"f8","bdata":"dxO7zeoqBkATp7d+ibgFQEi62LQeSQRAHQovHnNPBUDkGM5RinIDQLZ+0Wb2TANAF2jEb6mrA0BmxEgRvZADQDSGvGVmZAVAWZwjKEMFCEBDQZmp8BcFQB\u002fQdoUxWAdAKDraCfTgBUCEhYywlOUDQKiPMI9zXQhAfc\u002f\u002fEawLBEC2GQBtAx4DQPjTQei2LgNA\u002fUXtbxT7BkCa3ZJo6A0EQEeStvq2oQVAhiUjBU+fCkBYkT1UWOACQFoFkNzVggFArs9VpPL4BkAxzXKsp4IFQJbDScUOcgZAlUee32rEAkAiJrztPFYDQJEaLQBh7QNAlIaDJfg2CUBNO77AQ9YGQMPuLlxliQRAigBMSmafAkCPeqCUmQEFQBro49VZ3QdAYeTmAAkUCkCCRiUUAbsAQCvLelp4kwdABdtQYCBOBUDDDkw6Kv8BQEsXw+DtTQNA0PGpdcoKB0C8R\u002fOp39oFQPY7E6nJZQdApoBVWbKg9j\u002fSMGNTw\u002f0FQMi6CH+OBQpAaQuzGn32BUB\u002fN6gSw+0GQFZzCqlfuwRADfH7R9+6CUDSe1TVZzEEQFFBgecYsAhAIWsyGgDWBEDvg9DVtbAGQK0aOw1XLQVAWor\u002fVPOGAUA5UWPC\u002fpkHQIi5aciuNgdAysCuxRUMCEBjt4+L1+IDQEbmvtNUkwhAo\u002fXbiulzBkCXpaRsAtQDQEAPjiISRQVAngZq4juEA0C2gxkXb6zGv6ZCpjL4NAZA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2022"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate (1)","showlegend":true,"x":{"dtype":"f8","bdata":"UBFDMdJv5L8="},"y":{"dtype":"f8","bdata":"WO5zTbOwtT8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2022"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor (1)","showlegend":true,"x":{"dtype":"f8","bdata":"ELyQxKpZAcA="},"y":{"dtype":"f8","bdata":"rDQB0Vi6\u002fT8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2022","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2022","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2022","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2022"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language (4)","showlegend":true,"x":{"dtype":"f8","bdata":"5anFOYP\u002fBMAhlfNLQOYDwNkXGchm2QbACg4V66EYv78="},"y":{"dtype":"f8","bdata":"Sc\u002f8MMvP9T9Atod3FUP2PyrF6uCrueM\u002f2jfzm4fx5T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2022"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal (1)","showlegend":true,"x":{"dtype":"f8","bdata":"3P74mldVA8A="},"y":{"dtype":"f8","bdata":"ncm355lo0z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2022"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length (1)","showlegend":true,"x":{"dtype":"f8","bdata":"oBwaVvuVAMA="},"y":{"dtype":"f8","bdata":"poBVWbKg9j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2022","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2022","Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2022","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2022","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2022","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2022","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2022","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral (20)","showlegend":true,"x":{"dtype":"f8","bdata":"Zrxybwz1BcA8HbroZRDwv0l0JUvcWgjAPANz+WA0tT9RwWP47REIwBrBQQOTAAbAu54trD6UA8C3pS15iWj1P5SmqHqqs\u002fY\u002fbgzvxiCGwz846qAWZKLMP+jjhSjBWdk\u002fYl4nBdBY7D90PAa883QIwEfixnCsZgjAvgBjMGdPCcAVv7k7QzAJwByHphef1c4\u002fygYsZvs8BcA5akQChRQHwA=="},"y":{"dtype":"f8","bdata":"GJHNP4A99r86FKHfLFz9v9JwUjQBGfW\u002fIcS987S127+CZFZNLaD7v9JttXoYyei\u002fwHpg+B2J8L+eZQDVSxjNv03qlRgkCNW\u002fblnPL75ryr+oxcqZg4n2v92qJ0gipuU\u002fYB7BD+RP8b9a0QTzwH70v0pjduMG0\u002fK\u002f4xRpNZzs9r8sh8ZFx775v16P75sxH\u002fS\u002famz5iYhH6r9mh7wxyYzwvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2022","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2022","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2022","Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2022","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2022","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2022"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual (6)","showlegend":true,"x":{"dtype":"f8","bdata":"bfez8jWj579TnnS+yogBwMyQSv17kcg\u002f+9Ld9WRxAsDEaAe2maHXPyYLXEilGAPA"},"y":{"dtype":"f8","bdata":"zKn8XvmlBMCyN10cYAn4vyssNMalD9O\u002fmE2\u002fJu8d\u002fr+wlNm2bn3yv\u002fudSqmYu\u002fy\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2022"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness (1)","showlegend":true,"x":{"dtype":"f8","bdata":"j9a6sVj0\u002fb8="},"y":{"dtype":"f8","bdata":"zZ\u002f\u002fK6GvAsA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2022","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2022","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions (4)","showlegend":true,"x":{"dtype":"f8","bdata":"gSES7qOp3j\u002fId+lXf+34P7Xfj82NU9w\u002fy2vb+fzv8T8="},"y":{"dtype":"f8","bdata":"4Kpha5vRnz+qSB\u002fKCJXLvxh4RSFttwTA5Kroj2+jqj8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2022","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2022","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2022","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2022","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2022","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2022","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization (31)","showlegend":true,"x":{"dtype":"f8","bdata":"nXSVvLM\u002f0T+MlQGzHgHFP8DBQ0SSRe+\u002fcjuwsWpW0j9T4sHFTjjjvyGdk2T67OC\u002faHKlsjJS9T\u002fgy41mTx7hvyoXrZOyOeG\u002fIemNpGuk4T8Ar0q0tX\u002fxP2CaefHZiLK\u002fEYCWzBxW3b+MNOtbilzYv5Jc5nuJ5+W\u002fhu0myONR4L\u002f6t3CO8MvIv+IErKN3neS\u002fPMJ4iibD6r82Qo3VNADHv4vg7ZoJbum\u002fAqfkMPLqzb9sV98oDtPXvzApy5L45uy\u002fYeaj0+Gp8L\u002fZRZeFJzvbv1KQpwkkw8e\u002fnhORi4uC2L9mFyg2hh\u002fVv6qkP9K1iPc\u002fIePBPWUT5b8="},"y":{"dtype":"f8","bdata":"cFg8Kbr5BMBuqs7gtd7Kv5yunLmeNgbAYcwuoFwGB8BcS7E9OrkGwKr9IPTW4AbAecJYTxSa7r+w9SAs6wYIwHKFbyu\u002f5AjA8Y\u002fTYj\u002fdyr8d3vBgCovtv7DH2inNBg3A9FniRWeQCMBj0LtnPY8GwJfmGoVFeAnA9w3ZL2LgCMBBJFENbKAKwKhsz9kbQQfA0iOPm4IRB8Ad4qm988YIwIgpEw+P\u002fwfAdD4Pp6BICcC6fLtXSA8HwN5vkf6gzgXAfYZqDaY3BsAVVFE4zHUIwH+QnigokArAFNSa2UCDBcB+VXUAu9MIwPRDXVHVRro\u002fs7n6t\u002fIkDMA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2022","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2022","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2022","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2022","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2022","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2022"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political (6)","showlegend":true,"x":{"dtype":"f8","bdata":"Xx0NLo4q\u002fD97Rx6jIxv8P1bWR1ydGf0\u002fviYUB2wK7T846qAWZKLMP7XAuhHWw8G\u002f"},"y":{"dtype":"f8","bdata":"NWmD+ecS9r9SWEB9nbn5vyoMucxXufW\u002fur2SMI94zL+oxcqZg4n2vxngBwb9qwvA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2022","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2022","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2022","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2022","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2022","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2022","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2022","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2022","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2022","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2022","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2022","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2022","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2022","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2022","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2022","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2022","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2022","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety (62)","showlegend":true,"x":{"dtype":"f8","bdata":"PB266GUQ8L9t97PyNaPnv510lbyzP9E\u002ftC8+8X839j9NdpEGNkD2P8sUAKbotP4\u002fgnfLXs\u002f4AEASwgh4KBbqPxYDIxwy4+4\u002fAWcByWf95j+di5v3xNbxP1K6n1jbDug\u002f0q3u7+Ry9z9itYKx6HLlP8jmeCLuwPA\u002fDK8\u002fOAOq1T9QEUMx0m\u002fkv7eGx8t7Quc\u002fI8+8YRxH6T\u002f0CDyZX4j1P8XKfemeFOo\u002fK\u002fKdwY619j8+cnD68YHxP+Fz2JKVrd0\u002fZE9cSK6i5T97iGhJZdQBQPRFo0Q2hOw\u002fdzm8uIKn7T9cbrXrMf3rP8lm2BUtyOU\u002fhJZkNIUK7z+By+e562jgP+BigaAbqNo\u002fPifw4cbZ5j8XLOFLFprqP8RoB7aZodc\u002f03W8WOs39j99VuZfhGDpP1u3QWzAPvE\u002f+DlKSyoY8D+iD+D9EqDUP5FRilyR1Ok\u002fwA\u002fTQ7ZX8T\u002fg5vIOAifoP3CY+4bXxOQ\u002fHXNORRT4\u002fz89iBngAdjyP9U\u002ffvgckew\u002fepz4iJn89j9mEQmZQPXtPwpWtvi4ReU\u002fFPjCO3732z8Hc6c5c579P3HGkOEgw+8\u002fhlEj+t939D8W4p7cn7TXP+TcJoSLP\u002fA\u002f0+qWgltL\u002fz\u002fBNCfL1jT1Pw8at58C1eM\u002fhiE9qTS8xL\u002fK\u002f8pmpx3ePw=="},"y":{"dtype":"f8","bdata":"OhSh3yxc\u002fb\u002fMqfxe+aUEwHBYPCm6+QTAb7P\u002fwLBbBcACZziLPUHVv1aXYJOMdwDA0SPvq6JK679GyGnBBXgFwOy+ScpYhAjAExR9bIQABsBsQOxkZrIFwO8K3T1OsAfAoFGpzF1jBcDgLyEQU0cJwMSKZh+BFQzAZutsuxs+B8BY7nNNs7C1Pyhf+EBPXsU\u002fQRPAsOmUAcB3CX86ypIDwDbPwQXnfATAWZMudEhjCsBApi2XLy3RP14aZSlMUQbAr95+qdjlA8DfvZGa8GHSv+4TzqGyFQfAjAf8IvM7AsA0qYu4Ub4DwCphTKTBrgvAv+HNL5w5CcBmOtsh6R0HwK5EzJ4LMQfA3ow+NUCV4b\u002fxleS4NH0FwLCU2bZuffK\u002fLNz6fx3sBcBLOPOsdH0BwELA854uEQXApoIwhHbVA8D6sTGrpl8FwKsdiT1\u002fZQjAwTn5F11UCMCLvS25EUgGwKe7oGe98gXA9DLNZ\u002fLe\u002fr8GG7WoymAJwMtQdwzfDAbA2R0pxCB8BMDdmk\u002fCPL0KwPxumIGv7AXA4XcwB6B5BsCGMzSWIkP4v+s4vQLevwjAhGdBmQjVB8AqJ1JmetMFwJ6CvIjD5AnACCO4UDqhAMCKtHZbu8cBwBATCTnsbwbAtoMZF2+sxr9D+O64n0AHwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2022"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism (1)","showlegend":true,"x":{"dtype":"f8","bdata":"Yl4nBdBY7D8="},"y":{"dtype":"f8","bdata":"YB7BD+RP8b8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2022","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2022","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2022","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2022","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2022","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2022","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2022"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social (18)","showlegend":true,"x":{"dtype":"f8","bdata":"f7UQIWY3AkAzmFZYHIoBQJfZwNaumgNAvCwQAGh4A0DNYd\u002fZovADQMDAyI4ubgpA6CaLCHgPBEBfwnSNH0QDQKO1S5lk\u002fQFAtd+PzY1T3D8Ar0q0tX\u002fxP0uOv4lD4gdAe0ceoyMb\u002fD8MY0qF54IDQGOijpbk5\u002f4\u002fpLjXYatYAkAq0BKkIIT+P6qkP9K1iPc\u002f"},"y":{"dtype":"f8","bdata":"6KK9GAMzAMCKppVyeXYBwLgkUoOeGP+\u002feAuq3XZ\u002fAMAiUOJpo8ADwNQTAME5R9m\u002f+hhM5+J3AsDMkZIyYTjlv2qCYfDpq6w\u002fGHhFIW23BMAd3vBgCovtv7qC+7PFyMG\u002fUlhAfZ25+b8Su\u002f19T04BwIT1qK0hOgDAI17zATkztL\u002f\u002fZ33Uu24BwPRDXVHVRro\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2022","Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2022","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2022","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2022","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2022","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2022"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity (6)","showlegend":true,"x":{"dtype":"f8","bdata":"yxQApui0\u002fj+3iSBBdjYDQEKs2IQFDQRAPlHN8BhmBUDBNCfL1jT1P2CPkZI4KgRA"},"y":{"dtype":"f8","bdata":"Vpdgk4x3AMD9Um7\u002frgbwvwDthNFqYfC\u002fJHGAHbNw9b+KtHZbu8cBwJQSQIyBS\u002fS\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2022","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2022","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2022","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2022","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value (15)","showlegend":true,"x":{"dtype":"f8","bdata":"qOrsXgW3CEAobSJ2qjIGQKtM2EkwEgdAvgKjNyhiBkCwbJyaxVoEQO2gM0TBZwZAHXNORRT4\u002fz\u002fMB\u002fR8CioFQByHphef1c4\u002fzbLR7U\u002f1A0BBiJEg2rMDQAdzpzlznv0\u002fPVEjuSwtCEDT6paCW0v\u002fP7ESskK2nQJA"},"y":{"dtype":"f8","bdata":"npVq\u002fpyU3b\u002fkGP52UNrov\u002fXj13wPiOK\u002fuESbkST51L8NnjEZbmPhvxNI08tZpeG\u002f9DLNZ\u002fLe\u002fr9VyxqkjNXjv16P75sxH\u002fS\u002f3lxcO1Nw4b\u002fYxgW2QMzvv4YzNJYiQ\u002fi\u002fGS9evjRG478II7hQOqEAwBOYE+G0AeC\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2023","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2023","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2023","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2023","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2023","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2023","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2023","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2023","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2023","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2023","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2023","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2023"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias (19)","showlegend":false,"x":{"dtype":"f8","bdata":"CUwWEXARCEDAwMiOLm4KQLelLXmJaPU\u002fXx0NLo4q\u002fD\u002fId+lXf+34P3uIaEll1AFAlKaoeqqz9j+jtUuZZP0BQEuOv4lD4gdAy2vb+fzv8T97Rx6jIxv8P1bWR1ydGf0\u002f1f3JyHgqBUC+JhQHbArtP6I9tkKNywZAfxZOVFh9AEA46qAWZKLMP2JeJwXQWOw\u002fr85VTijOCEA="},"y":{"dtype":"f8","bdata":"85G\u002fJbuj4z\u002fUEwDBOUfZv55lANVLGM2\u002fNWmD+ecS9r+qSB\u002fKCJXLv9+9kZrwYdK\u002fTeqVGCQI1b9qgmHw6ausP7qC+7PFyMG\u002f5Kroj2+jqj9SWEB9nbn5vyoMucxXufW\u002fm6+j8LgU9D+6vZIwj3jMv+BJOFqTaOI\u002ffgUnDzET+D+oxcqZg4n2v2AewQ\u002fkT\u002fG\u002feMUArJXz6j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2023","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2023","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2023","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2023","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2023","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2023","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2023","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2023","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2023","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2023","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2023","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2023","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2023"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural (30)","showlegend":false,"x":{"dtype":"f8","bdata":"PANz+WA0tT\u002fMkEr9e5HIPxZ9lOs89AhAgnfLXs\u002f4AEAJTBYRcBEIQI8m34X1QwBAPysnTGR9B0DgyVS9dP8CQFUHo8l78AZARMgrGcgiCEDdhOYC6pgHQMC2TxxZiQpAwMDIji5uCkC3pS15iWj1P2hypbIyUvU\u002fX8J0jR9EA0CUpqh6qrP2P6I9tkKNywZAxGgHtpmh1z9uDO\u002fGIIbDP+jjhSjBWdk\u002fk7mgm0\u002fNCEAy8D\u002fPAZ8JQK48IbaiiARAurlZVCEiCUCU7eAuiBn5P6qkP9K1iPc\u002fswdWBONMBkC9hoQ\u002fBqUIQAoOFeuhGL+\u002f"},"y":{"dtype":"f8","bdata":"IcS987S1278rLDTGpQ\u002fTv6eKXHlmF9o\u002f0SPvq6JK67\u002fzkb8lu6PjP6dEV+T8uOY\u002fjKRMcLAI8j\u002fABOQNCsveP1geyef7l+A\u002fcHH5y+Ww8D\u002fEHqyCWY3xP1XCZ\u002f9u0O8\u002f1BMAwTlH2b+eZQDVSxjNv3nCWE8Umu6\u002fzJGSMmE45b9N6pUYJAjVv+BJOFqTaOI\u002fsJTZtm598r9uWc8vvmvKv92qJ0gipuU\u002f4Pb+V10l9j\u002fT8FhRqDPiPzHCXTzeYdo\u002f6gsvXjB+4z9ApCAq7u38P\u002fRDXVHVRro\u002fs5ksZbYy2j+ucP0VTlTjP9o385uH8eU\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2023","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2023","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2023"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture (3)","showlegend":false,"x":{"dtype":"f8","bdata":"HkaH6SzQBED4whb82pkIQDRTF5b3OANA"},"y":{"dtype":"f8","bdata":"rAmnZhVI9z9NzeIUjAfpP\u002fpU87fsYfI\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2023","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2023","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2023","Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2023","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2023","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2023","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2023","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2023","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2023","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2023"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics (14)","showlegend":false,"x":{"dtype":"f8","bdata":"gSES7qOp3j95VUFJ7G8BQHDND3nLWgVAGvRCdJEaAUDId+lXf+34P3uIaEll1AFAo7VLmWT9AUBLjr+JQ+IHQMtr2\u002fn87\u002fE\u002f2Mb70RLL9T\u002fV\u002fcnIeCoFQK\u002fOVU4ozghATiceAb94BECkuNdhq1gCQA=="},"y":{"dtype":"f8","bdata":"4Kpha5vRnz9Fubht0o3+P\u002fpRA8PX5wBAbByX+r\u002fM+T+qSB\u002fKCJXLv9+9kZrwYdK\u002faoJh8OmrrD+6gvuzxcjBv+Sq6I9vo6o\u002fyVyg49nSAUCbr6PwuBT0P3jFAKyV8+o\u002f2s56TUG4\u002fD8jXvMBOTO0vw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2023","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2023","Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2023","Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2023","Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2023","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2023","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2023","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2023","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2023","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2023"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity (10)","showlegend":false,"x":{"dtype":"f8","bdata":"TXaRBjZA9j+MlQGzHgHFP1q9beiI8u8\u002fg+o8T29q9j9BxOVSm+fqPz5ycPrxgfE\u002fIemNpGuk4T\u002fYxvvREsv1P38WTlRYfQBA6OOFKMFZ2T8="},"y":{"dtype":"f8","bdata":"Amc4iz1B1b9uqs7gtd7Kv4Nv4b\u002fpGQdAZRIs8oL9BEBwCsQsaPwBQECmLZcvLdE\u002f8Y\u002fTYj\u002fdyr\u002fJXKDj2dIBQH4FJw8xE\u002fg\u002f3aonSCKm5T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2023","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2023","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2023","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2023","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2023","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2023"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical (6)","showlegend":false,"x":{"dtype":"f8","bdata":"0V46T3FK8D9TNRmahsHpP2CQQXJVrOo\u002fAK9KtLV\u002f8T+qpD\u002fStYj3PxrgZZRaV+o\u002f"},"y":{"dtype":"f8","bdata":"Mzi9HDZpBUC4hmWl\u002f1kHQJxKjwphJQhAHd7wYAqL7b\u002f0Q11R1Ua6P0yFkBk1VwhA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2023","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2023","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2023","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2023","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality (21)","showlegend":false,"x":{"dtype":"f8","bdata":"GuJ+gWdK2T+uEcA1ilnZP7cITzog4t8\u002fTPgcQP4o0D+Y9ERJZAbQv7eGx8t7Quc\u002fUC4t8EwVzL98qWyrpVywv6ZyNm0Tj8O\u002fyEU5XYedp78+J\u002fDhxtnmP91TrH1jCNs\u002fviYUB2wK7T9AhIEA+ILSP9N2MUGFyNM\u002fxKDxMLu+7j\u002flDWXPMKbUP4gm0nrlfeY\u002fujsumOBM5T+U7eAuiBn5P8xGruAeUrm\u002f"},"y":{"dtype":"f8","bdata":"gYRV4RS6B0D4U1Q\u002f4xkGQLujw5FW6AxAFOsLNEuFCUC7AWj2r8AKQChf+EBPXsU\u002fLFf3aQHGAkDda5iV7fAJQFDn97MBVQ5A6DtlhDZACkDejD41QJXhv4hRZlgcSgdAur2SMI94zL\u002fQm2FVkkYGQK6oFPVaEQVAOAMOFw7eCUCSluy6gIoNQKLAiqDw2glAd4i8MyF7B0BApCAq7u38PwD\u002fOo0nRgpA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2023"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"XmBFETQ01r8="},"y":{"dtype":"f8","bdata":"LMpP6jeOB0A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2023","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2023","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general (69)","showlegend":false,"x":{"dtype":"f8","bdata":"WiXGkyVp87+2O6lnZqnyv5YK6LDXs\u002fe\u002fpnikSWxp8L\u002fRhBhmgmP3v+YkhswTXPO\u002f9RN+9AF58L\u002f\u002fb\u002faYH5f2v06sPZk5HPu\u002fhyWaN5vs8r8jXmEX\u002fIv0v+7a5jUhlvK\u002fjtBLkfuN+L\u002fmkeTEc4bsv3FiMqvwoum\u002fmHPFOqaY7b+kD0ZOwDP2v49kYLuB5vG\u002fmkNrFb1G8b+6lHoQXUzwv\u002fhCvTU\u002fQuy\u002fTrt0K9YD4r8pvnngxqb3v8P2dGuW2\u002fW\u002fbBZccZHU9b8UiqVucKbyv41PobXaHvW\u002f\u002fBZ7Cu2A87\u002f5jzrN9iTxv+ZWCnXGBO6\u002fu8xjvHaI8L+IaYMR0wbzvxiFmC1Ywfm\u002fpG0rKqW\u002f3L+U\u002fezC5JX7v3aASoG7RvG\u002fqrZRn54m+r82sj62UXr9v1SmfVHAkvO\u002fIQDO1NIL9L8xnX7kLI7yv6SZnlJbUvO\u002fL72Kzxrl9L\u002fWIMwFDejzv9hW+9zVbva\u002foBwaVvuVAMBmDawGfFH3v3T7DHFLUPC\u002feXz6gxEk+L\u002f1u0aI3KP2v+dXMmNAdPO\u002faok2eCxM978GNEfu6M72v0Xg4CFMTfy\u002fsXDG5uwv97\u002f3Prp06of0vzJE9JIbrPO\u002fA3sJE7jZ87+2HL+sIlj0v+MMj7Q6ofK\u002fgInoaJ5W7r8k1LYbsc4AwOmYRh14IPa\u002fCtx\u002f0+kM979CA3z92BPpv7IHx+rP\u002fvm\u002flYKPxEDg9b+GIT2pNLzEvwb8sa4yBvG\u002f"},"y":{"dtype":"f8","bdata":"dxO7zeoqBkATp7d+ibgFQEi62LQeSQRAHQovHnNPBUDkGM5RinIDQLZ+0Wb2TANAF2jEb6mrA0BmxEgRvZADQDSGvGVmZAVAWZwjKEMFCEBDQZmp8BcFQB\u002fQdoUxWAdAKDraCfTgBUCEhYywlOUDQKiPMI9zXQhAfc\u002f\u002fEawLBEC2GQBtAx4DQPjTQei2LgNA\u002fUXtbxT7BkCa3ZJo6A0EQEeStvq2oQVAhiUjBU+fCkBYkT1UWOACQFoFkNzVggFArs9VpPL4BkAxzXKsp4IFQJbDScUOcgZAlUee32rEAkAiJrztPFYDQJEaLQBh7QNAlIaDJfg2CUBNO77AQ9YGQMPuLlxliQRAigBMSmafAkCPeqCUmQEFQBro49VZ3QdAYeTmAAkUCkCCRiUUAbsAQCvLelp4kwdABdtQYCBOBUDDDkw6Kv8BQEsXw+DtTQNA0PGpdcoKB0C8R\u002fOp39oFQPY7E6nJZQdApoBVWbKg9j\u002fSMGNTw\u002f0FQMi6CH+OBQpAaQuzGn32BUB\u002fN6gSw+0GQFZzCqlfuwRADfH7R9+6CUDSe1TVZzEEQFFBgecYsAhAIWsyGgDWBEDvg9DVtbAGQK0aOw1XLQVAWor\u002fVPOGAUA5UWPC\u002fpkHQIi5aciuNgdAysCuxRUMCEBjt4+L1+IDQEbmvtNUkwhAo\u002fXbiulzBkCXpaRsAtQDQEAPjiISRQVAngZq4juEA0C2gxkXb6zGv6ZCpjL4NAZA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2023"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate (1)","showlegend":false,"x":{"dtype":"f8","bdata":"UBFDMdJv5L8="},"y":{"dtype":"f8","bdata":"WO5zTbOwtT8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2023"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor (1)","showlegend":false,"x":{"dtype":"f8","bdata":"ELyQxKpZAcA="},"y":{"dtype":"f8","bdata":"rDQB0Vi6\u002fT8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2023","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2023","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2023","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2023"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language (4)","showlegend":false,"x":{"dtype":"f8","bdata":"5anFOYP\u002fBMAhlfNLQOYDwNkXGchm2QbACg4V66EYv78="},"y":{"dtype":"f8","bdata":"Sc\u002f8MMvP9T9Atod3FUP2PyrF6uCrueM\u002f2jfzm4fx5T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2023"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal (1)","showlegend":false,"x":{"dtype":"f8","bdata":"3P74mldVA8A="},"y":{"dtype":"f8","bdata":"ncm355lo0z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2023"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length (1)","showlegend":false,"x":{"dtype":"f8","bdata":"oBwaVvuVAMA="},"y":{"dtype":"f8","bdata":"poBVWbKg9j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2023","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2023","Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2023","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2023","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2023","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2023","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2023","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral (20)","showlegend":false,"x":{"dtype":"f8","bdata":"Zrxybwz1BcA8HbroZRDwv0l0JUvcWgjAPANz+WA0tT9RwWP47REIwBrBQQOTAAbAu54trD6UA8C3pS15iWj1P5SmqHqqs\u002fY\u002fbgzvxiCGwz846qAWZKLMP+jjhSjBWdk\u002fYl4nBdBY7D90PAa883QIwEfixnCsZgjAvgBjMGdPCcAVv7k7QzAJwByHphef1c4\u002fygYsZvs8BcA5akQChRQHwA=="},"y":{"dtype":"f8","bdata":"GJHNP4A99r86FKHfLFz9v9JwUjQBGfW\u002fIcS987S127+CZFZNLaD7v9JttXoYyei\u002fwHpg+B2J8L+eZQDVSxjNv03qlRgkCNW\u002fblnPL75ryr+oxcqZg4n2v92qJ0gipuU\u002fYB7BD+RP8b9a0QTzwH70v0pjduMG0\u002fK\u002f4xRpNZzs9r8sh8ZFx775v16P75sxH\u002fS\u002famz5iYhH6r9mh7wxyYzwvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2023","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2023","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2023","Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2023","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2023","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2023"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual (6)","showlegend":false,"x":{"dtype":"f8","bdata":"bfez8jWj579TnnS+yogBwMyQSv17kcg\u002f+9Ld9WRxAsDEaAe2maHXPyYLXEilGAPA"},"y":{"dtype":"f8","bdata":"zKn8XvmlBMCyN10cYAn4vyssNMalD9O\u002fmE2\u002fJu8d\u002fr+wlNm2bn3yv\u002fudSqmYu\u002fy\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2023"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"j9a6sVj0\u002fb8="},"y":{"dtype":"f8","bdata":"zZ\u002f\u002fK6GvAsA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2023","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2023","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions (4)","showlegend":false,"x":{"dtype":"f8","bdata":"gSES7qOp3j\u002fId+lXf+34P7Xfj82NU9w\u002fy2vb+fzv8T8="},"y":{"dtype":"f8","bdata":"4Kpha5vRnz+qSB\u002fKCJXLvxh4RSFttwTA5Kroj2+jqj8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2023","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2023","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2023","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2023","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2023","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2023","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization (31)","showlegend":false,"x":{"dtype":"f8","bdata":"nXSVvLM\u002f0T+MlQGzHgHFP8DBQ0SSRe+\u002fcjuwsWpW0j9T4sHFTjjjvyGdk2T67OC\u002faHKlsjJS9T\u002fgy41mTx7hvyoXrZOyOeG\u002fIemNpGuk4T8Ar0q0tX\u002fxP2CaefHZiLK\u002fEYCWzBxW3b+MNOtbilzYv5Jc5nuJ5+W\u002fhu0myONR4L\u002f6t3CO8MvIv+IErKN3neS\u002fPMJ4iibD6r82Qo3VNADHv4vg7ZoJbum\u002fAqfkMPLqzb9sV98oDtPXvzApy5L45uy\u002fYeaj0+Gp8L\u002fZRZeFJzvbv1KQpwkkw8e\u002fnhORi4uC2L9mFyg2hh\u002fVv6qkP9K1iPc\u002fIePBPWUT5b8="},"y":{"dtype":"f8","bdata":"cFg8Kbr5BMBuqs7gtd7Kv5yunLmeNgbAYcwuoFwGB8BcS7E9OrkGwKr9IPTW4AbAecJYTxSa7r+w9SAs6wYIwHKFbyu\u002f5AjA8Y\u002fTYj\u002fdyr8d3vBgCovtv7DH2inNBg3A9FniRWeQCMBj0LtnPY8GwJfmGoVFeAnA9w3ZL2LgCMBBJFENbKAKwKhsz9kbQQfA0iOPm4IRB8Ad4qm988YIwIgpEw+P\u002fwfAdD4Pp6BICcC6fLtXSA8HwN5vkf6gzgXAfYZqDaY3BsAVVFE4zHUIwH+QnigokArAFNSa2UCDBcB+VXUAu9MIwPRDXVHVRro\u002fs7n6t\u002fIkDMA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2023","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2023","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2023","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2023","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2023","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2023"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political (6)","showlegend":false,"x":{"dtype":"f8","bdata":"Xx0NLo4q\u002fD97Rx6jIxv8P1bWR1ydGf0\u002fviYUB2wK7T846qAWZKLMP7XAuhHWw8G\u002f"},"y":{"dtype":"f8","bdata":"NWmD+ecS9r9SWEB9nbn5vyoMucxXufW\u002fur2SMI94zL+oxcqZg4n2vxngBwb9qwvA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2023","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2023","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2023","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2023","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2023","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2023","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2023","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2023","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2023","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2023","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2023","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2023","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2023","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2023","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2023","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2023","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2023","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety (62)","showlegend":false,"x":{"dtype":"f8","bdata":"PB266GUQ8L9t97PyNaPnv510lbyzP9E\u002ftC8+8X839j9NdpEGNkD2P8sUAKbotP4\u002fgnfLXs\u002f4AEASwgh4KBbqPxYDIxwy4+4\u002fAWcByWf95j+di5v3xNbxP1K6n1jbDug\u002f0q3u7+Ry9z9itYKx6HLlP8jmeCLuwPA\u002fDK8\u002fOAOq1T9QEUMx0m\u002fkv7eGx8t7Quc\u002fI8+8YRxH6T\u002f0CDyZX4j1P8XKfemeFOo\u002fK\u002fKdwY619j8+cnD68YHxP+Fz2JKVrd0\u002fZE9cSK6i5T97iGhJZdQBQPRFo0Q2hOw\u002fdzm8uIKn7T9cbrXrMf3rP8lm2BUtyOU\u002fhJZkNIUK7z+By+e562jgP+BigaAbqNo\u002fPifw4cbZ5j8XLOFLFprqP8RoB7aZodc\u002f03W8WOs39j99VuZfhGDpP1u3QWzAPvE\u002f+DlKSyoY8D+iD+D9EqDUP5FRilyR1Ok\u002fwA\u002fTQ7ZX8T\u002fg5vIOAifoP3CY+4bXxOQ\u002fHXNORRT4\u002fz89iBngAdjyP9U\u002ffvgckew\u002fepz4iJn89j9mEQmZQPXtPwpWtvi4ReU\u002fFPjCO3732z8Hc6c5c579P3HGkOEgw+8\u002fhlEj+t939D8W4p7cn7TXP+TcJoSLP\u002fA\u002f0+qWgltL\u002fz\u002fBNCfL1jT1Pw8at58C1eM\u002fhiE9qTS8xL\u002fK\u002f8pmpx3ePw=="},"y":{"dtype":"f8","bdata":"OhSh3yxc\u002fb\u002fMqfxe+aUEwHBYPCm6+QTAb7P\u002fwLBbBcACZziLPUHVv1aXYJOMdwDA0SPvq6JK679GyGnBBXgFwOy+ScpYhAjAExR9bIQABsBsQOxkZrIFwO8K3T1OsAfAoFGpzF1jBcDgLyEQU0cJwMSKZh+BFQzAZutsuxs+B8BY7nNNs7C1Pyhf+EBPXsU\u002fQRPAsOmUAcB3CX86ypIDwDbPwQXnfATAWZMudEhjCsBApi2XLy3RP14aZSlMUQbAr95+qdjlA8DfvZGa8GHSv+4TzqGyFQfAjAf8IvM7AsA0qYu4Ub4DwCphTKTBrgvAv+HNL5w5CcBmOtsh6R0HwK5EzJ4LMQfA3ow+NUCV4b\u002fxleS4NH0FwLCU2bZuffK\u002fLNz6fx3sBcBLOPOsdH0BwELA854uEQXApoIwhHbVA8D6sTGrpl8FwKsdiT1\u002fZQjAwTn5F11UCMCLvS25EUgGwKe7oGe98gXA9DLNZ\u002fLe\u002fr8GG7WoymAJwMtQdwzfDAbA2R0pxCB8BMDdmk\u002fCPL0KwPxumIGv7AXA4XcwB6B5BsCGMzSWIkP4v+s4vQLevwjAhGdBmQjVB8AqJ1JmetMFwJ6CvIjD5AnACCO4UDqhAMCKtHZbu8cBwBATCTnsbwbAtoMZF2+sxr9D+O64n0AHwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2023"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism (1)","showlegend":false,"x":{"dtype":"f8","bdata":"Yl4nBdBY7D8="},"y":{"dtype":"f8","bdata":"YB7BD+RP8b8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2023","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2023","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2023","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2023","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2023","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2023","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2023"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social (18)","showlegend":false,"x":{"dtype":"f8","bdata":"f7UQIWY3AkAzmFZYHIoBQJfZwNaumgNAvCwQAGh4A0DNYd\u002fZovADQMDAyI4ubgpA6CaLCHgPBEBfwnSNH0QDQKO1S5lk\u002fQFAtd+PzY1T3D8Ar0q0tX\u002fxP0uOv4lD4gdAe0ceoyMb\u002fD8MY0qF54IDQGOijpbk5\u002f4\u002fpLjXYatYAkAq0BKkIIT+P6qkP9K1iPc\u002f"},"y":{"dtype":"f8","bdata":"6KK9GAMzAMCKppVyeXYBwLgkUoOeGP+\u002feAuq3XZ\u002fAMAiUOJpo8ADwNQTAME5R9m\u002f+hhM5+J3AsDMkZIyYTjlv2qCYfDpq6w\u002fGHhFIW23BMAd3vBgCovtv7qC+7PFyMG\u002fUlhAfZ25+b8Su\u002f19T04BwIT1qK0hOgDAI17zATkztL\u002f\u002fZ33Uu24BwPRDXVHVRro\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2023","Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2023","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2023","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2023","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2023","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2023"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity (6)","showlegend":false,"x":{"dtype":"f8","bdata":"yxQApui0\u002fj+3iSBBdjYDQEKs2IQFDQRAPlHN8BhmBUDBNCfL1jT1P2CPkZI4KgRA"},"y":{"dtype":"f8","bdata":"Vpdgk4x3AMD9Um7\u002frgbwvwDthNFqYfC\u002fJHGAHbNw9b+KtHZbu8cBwJQSQIyBS\u002fS\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2023","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2023","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2023","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2023","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value (15)","showlegend":false,"x":{"dtype":"f8","bdata":"qOrsXgW3CEAobSJ2qjIGQKtM2EkwEgdAvgKjNyhiBkCwbJyaxVoEQO2gM0TBZwZAHXNORRT4\u002fz\u002fMB\u002fR8CioFQByHphef1c4\u002fzbLR7U\u002f1A0BBiJEg2rMDQAdzpzlznv0\u002fPVEjuSwtCEDT6paCW0v\u002fP7ESskK2nQJA"},"y":{"dtype":"f8","bdata":"npVq\u002fpyU3b\u002fkGP52UNrov\u002fXj13wPiOK\u002fuESbkST51L8NnjEZbmPhvxNI08tZpeG\u002f9DLNZ\u002fLe\u002fr9VyxqkjNXjv16P75sxH\u002fS\u002f3lxcO1Nw4b\u002fYxgW2QMzvv4YzNJYiQ\u002fi\u002fGS9evjRG478II7hQOqEAwBOYE+G0AeC\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias (19)","showlegend":false,"x":{"dtype":"f8","bdata":"CUwWEXARCEDAwMiOLm4KQLelLXmJaPU\u002fXx0NLo4q\u002fD\u002fId+lXf+34P3uIaEll1AFAlKaoeqqz9j+jtUuZZP0BQEuOv4lD4gdAy2vb+fzv8T97Rx6jIxv8P1bWR1ydGf0\u002f1f3JyHgqBUC+JhQHbArtP6I9tkKNywZAfxZOVFh9AEA46qAWZKLMP2JeJwXQWOw\u002fr85VTijOCEA="},"y":{"dtype":"f8","bdata":"85G\u002fJbuj4z\u002fUEwDBOUfZv55lANVLGM2\u002fNWmD+ecS9r+qSB\u002fKCJXLv9+9kZrwYdK\u002fTeqVGCQI1b9qgmHw6ausP7qC+7PFyMG\u002f5Kroj2+jqj9SWEB9nbn5vyoMucxXufW\u002fm6+j8LgU9D+6vZIwj3jMv+BJOFqTaOI\u002ffgUnDzET+D+oxcqZg4n2v2AewQ\u002fkT\u002fG\u002feMUArJXz6j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2024","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2024","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2024","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2024","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2024"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural (30)","showlegend":false,"x":{"dtype":"f8","bdata":"PANz+WA0tT\u002fMkEr9e5HIPxZ9lOs89AhAgnfLXs\u002f4AEAJTBYRcBEIQI8m34X1QwBAPysnTGR9B0DgyVS9dP8CQFUHo8l78AZARMgrGcgiCEDdhOYC6pgHQMC2TxxZiQpAwMDIji5uCkC3pS15iWj1P2hypbIyUvU\u002fX8J0jR9EA0CUpqh6qrP2P6I9tkKNywZAxGgHtpmh1z9uDO\u002fGIIbDP+jjhSjBWdk\u002fk7mgm0\u002fNCEAy8D\u002fPAZ8JQK48IbaiiARAurlZVCEiCUCU7eAuiBn5P6qkP9K1iPc\u002fswdWBONMBkC9hoQ\u002fBqUIQAoOFeuhGL+\u002f"},"y":{"dtype":"f8","bdata":"IcS987S1278rLDTGpQ\u002fTv6eKXHlmF9o\u002f0SPvq6JK67\u002fzkb8lu6PjP6dEV+T8uOY\u002fjKRMcLAI8j\u002fABOQNCsveP1geyef7l+A\u002fcHH5y+Ww8D\u002fEHqyCWY3xP1XCZ\u002f9u0O8\u002f1BMAwTlH2b+eZQDVSxjNv3nCWE8Umu6\u002fzJGSMmE45b9N6pUYJAjVv+BJOFqTaOI\u002fsJTZtm598r9uWc8vvmvKv92qJ0gipuU\u002f4Pb+V10l9j\u002fT8FhRqDPiPzHCXTzeYdo\u002f6gsvXjB+4z9ApCAq7u38P\u002fRDXVHVRro\u002fs5ksZbYy2j+ucP0VTlTjP9o385uH8eU\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2024","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2024","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2024"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture (3)","showlegend":false,"x":{"dtype":"f8","bdata":"HkaH6SzQBED4whb82pkIQDRTF5b3OANA"},"y":{"dtype":"f8","bdata":"rAmnZhVI9z9NzeIUjAfpP\u002fpU87fsYfI\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2024","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2024","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2024"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics (14)","showlegend":false,"x":{"dtype":"f8","bdata":"gSES7qOp3j95VUFJ7G8BQHDND3nLWgVAGvRCdJEaAUDId+lXf+34P3uIaEll1AFAo7VLmWT9AUBLjr+JQ+IHQMtr2\u002fn87\u002fE\u002f2Mb70RLL9T\u002fV\u002fcnIeCoFQK\u002fOVU4ozghATiceAb94BECkuNdhq1gCQA=="},"y":{"dtype":"f8","bdata":"4Kpha5vRnz9Fubht0o3+P\u002fpRA8PX5wBAbByX+r\u002fM+T+qSB\u002fKCJXLv9+9kZrwYdK\u002faoJh8OmrrD+6gvuzxcjBv+Sq6I9vo6o\u002fyVyg49nSAUCbr6PwuBT0P3jFAKyV8+o\u002f2s56TUG4\u002fD8jXvMBOTO0vw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2024","Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2024","Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2024","Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2024","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2024","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2024","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity (10)","showlegend":false,"x":{"dtype":"f8","bdata":"TXaRBjZA9j+MlQGzHgHFP1q9beiI8u8\u002fg+o8T29q9j9BxOVSm+fqPz5ycPrxgfE\u002fIemNpGuk4T\u002fYxvvREsv1P38WTlRYfQBA6OOFKMFZ2T8="},"y":{"dtype":"f8","bdata":"Amc4iz1B1b9uqs7gtd7Kv4Nv4b\u002fpGQdAZRIs8oL9BEBwCsQsaPwBQECmLZcvLdE\u002f8Y\u002fTYj\u002fdyr\u002fJXKDj2dIBQH4FJw8xE\u002fg\u002f3aonSCKm5T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical (6)","showlegend":false,"x":{"dtype":"f8","bdata":"0V46T3FK8D9TNRmahsHpP2CQQXJVrOo\u002fAK9KtLV\u002f8T+qpD\u002fStYj3PxrgZZRaV+o\u002f"},"y":{"dtype":"f8","bdata":"Mzi9HDZpBUC4hmWl\u002f1kHQJxKjwphJQhAHd7wYAqL7b\u002f0Q11R1Ua6P0yFkBk1VwhA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2024","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality (21)","showlegend":false,"x":{"dtype":"f8","bdata":"GuJ+gWdK2T+uEcA1ilnZP7cITzog4t8\u002fTPgcQP4o0D+Y9ERJZAbQv7eGx8t7Quc\u002fUC4t8EwVzL98qWyrpVywv6ZyNm0Tj8O\u002fyEU5XYedp78+J\u002fDhxtnmP91TrH1jCNs\u002fviYUB2wK7T9AhIEA+ILSP9N2MUGFyNM\u002fxKDxMLu+7j\u002flDWXPMKbUP4gm0nrlfeY\u002fujsumOBM5T+U7eAuiBn5P8xGruAeUrm\u002f"},"y":{"dtype":"f8","bdata":"gYRV4RS6B0D4U1Q\u002f4xkGQLujw5FW6AxAFOsLNEuFCUC7AWj2r8AKQChf+EBPXsU\u002fLFf3aQHGAkDda5iV7fAJQFDn97MBVQ5A6DtlhDZACkDejD41QJXhv4hRZlgcSgdAur2SMI94zL\u002fQm2FVkkYGQK6oFPVaEQVAOAMOFw7eCUCSluy6gIoNQKLAiqDw2glAd4i8MyF7B0BApCAq7u38PwD\u002fOo0nRgpA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2024"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"XmBFETQ01r8="},"y":{"dtype":"f8","bdata":"LMpP6jeOB0A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2024","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2024","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general (69)","showlegend":false,"x":{"dtype":"f8","bdata":"WiXGkyVp87+2O6lnZqnyv5YK6LDXs\u002fe\u002fpnikSWxp8L\u002fRhBhmgmP3v+YkhswTXPO\u002f9RN+9AF58L\u002f\u002fb\u002faYH5f2v06sPZk5HPu\u002fhyWaN5vs8r8jXmEX\u002fIv0v+7a5jUhlvK\u002fjtBLkfuN+L\u002fmkeTEc4bsv3FiMqvwoum\u002fmHPFOqaY7b+kD0ZOwDP2v49kYLuB5vG\u002fmkNrFb1G8b+6lHoQXUzwv\u002fhCvTU\u002fQuy\u002fTrt0K9YD4r8pvnngxqb3v8P2dGuW2\u002fW\u002fbBZccZHU9b8UiqVucKbyv41PobXaHvW\u002f\u002fBZ7Cu2A87\u002f5jzrN9iTxv+ZWCnXGBO6\u002fu8xjvHaI8L+IaYMR0wbzvxiFmC1Ywfm\u002fpG0rKqW\u002f3L+U\u002fezC5JX7v3aASoG7RvG\u002fqrZRn54m+r82sj62UXr9v1SmfVHAkvO\u002fIQDO1NIL9L8xnX7kLI7yv6SZnlJbUvO\u002fL72Kzxrl9L\u002fWIMwFDejzv9hW+9zVbva\u002foBwaVvuVAMBmDawGfFH3v3T7DHFLUPC\u002feXz6gxEk+L\u002f1u0aI3KP2v+dXMmNAdPO\u002faok2eCxM978GNEfu6M72v0Xg4CFMTfy\u002fsXDG5uwv97\u002f3Prp06of0vzJE9JIbrPO\u002fA3sJE7jZ87+2HL+sIlj0v+MMj7Q6ofK\u002fgInoaJ5W7r8k1LYbsc4AwOmYRh14IPa\u002fCtx\u002f0+kM979CA3z92BPpv7IHx+rP\u002fvm\u002flYKPxEDg9b+GIT2pNLzEvwb8sa4yBvG\u002f"},"y":{"dtype":"f8","bdata":"dxO7zeoqBkATp7d+ibgFQEi62LQeSQRAHQovHnNPBUDkGM5RinIDQLZ+0Wb2TANAF2jEb6mrA0BmxEgRvZADQDSGvGVmZAVAWZwjKEMFCEBDQZmp8BcFQB\u002fQdoUxWAdAKDraCfTgBUCEhYywlOUDQKiPMI9zXQhAfc\u002f\u002fEawLBEC2GQBtAx4DQPjTQei2LgNA\u002fUXtbxT7BkCa3ZJo6A0EQEeStvq2oQVAhiUjBU+fCkBYkT1UWOACQFoFkNzVggFArs9VpPL4BkAxzXKsp4IFQJbDScUOcgZAlUee32rEAkAiJrztPFYDQJEaLQBh7QNAlIaDJfg2CUBNO77AQ9YGQMPuLlxliQRAigBMSmafAkCPeqCUmQEFQBro49VZ3QdAYeTmAAkUCkCCRiUUAbsAQCvLelp4kwdABdtQYCBOBUDDDkw6Kv8BQEsXw+DtTQNA0PGpdcoKB0C8R\u002fOp39oFQPY7E6nJZQdApoBVWbKg9j\u002fSMGNTw\u002f0FQMi6CH+OBQpAaQuzGn32BUB\u002fN6gSw+0GQFZzCqlfuwRADfH7R9+6CUDSe1TVZzEEQFFBgecYsAhAIWsyGgDWBEDvg9DVtbAGQK0aOw1XLQVAWor\u002fVPOGAUA5UWPC\u002fpkHQIi5aciuNgdAysCuxRUMCEBjt4+L1+IDQEbmvtNUkwhAo\u002fXbiulzBkCXpaRsAtQDQEAPjiISRQVAngZq4juEA0C2gxkXb6zGv6ZCpjL4NAZA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2024"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate (1)","showlegend":false,"x":{"dtype":"f8","bdata":"UBFDMdJv5L8="},"y":{"dtype":"f8","bdata":"WO5zTbOwtT8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2024"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor (1)","showlegend":false,"x":{"dtype":"f8","bdata":"ELyQxKpZAcA="},"y":{"dtype":"f8","bdata":"rDQB0Vi6\u002fT8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2024","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2024","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2024","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2024"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language (4)","showlegend":false,"x":{"dtype":"f8","bdata":"5anFOYP\u002fBMAhlfNLQOYDwNkXGchm2QbACg4V66EYv78="},"y":{"dtype":"f8","bdata":"Sc\u002f8MMvP9T9Atod3FUP2PyrF6uCrueM\u002f2jfzm4fx5T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2024"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal (1)","showlegend":false,"x":{"dtype":"f8","bdata":"3P74mldVA8A="},"y":{"dtype":"f8","bdata":"ncm355lo0z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2024"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length (1)","showlegend":false,"x":{"dtype":"f8","bdata":"oBwaVvuVAMA="},"y":{"dtype":"f8","bdata":"poBVWbKg9j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2024","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2024","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral (20)","showlegend":false,"x":{"dtype":"f8","bdata":"Zrxybwz1BcA8HbroZRDwv0l0JUvcWgjAPANz+WA0tT9RwWP47REIwBrBQQOTAAbAu54trD6UA8C3pS15iWj1P5SmqHqqs\u002fY\u002fbgzvxiCGwz846qAWZKLMP+jjhSjBWdk\u002fYl4nBdBY7D90PAa883QIwEfixnCsZgjAvgBjMGdPCcAVv7k7QzAJwByHphef1c4\u002fygYsZvs8BcA5akQChRQHwA=="},"y":{"dtype":"f8","bdata":"GJHNP4A99r86FKHfLFz9v9JwUjQBGfW\u002fIcS987S127+CZFZNLaD7v9JttXoYyei\u002fwHpg+B2J8L+eZQDVSxjNv03qlRgkCNW\u002fblnPL75ryr+oxcqZg4n2v92qJ0gipuU\u002fYB7BD+RP8b9a0QTzwH70v0pjduMG0\u002fK\u002f4xRpNZzs9r8sh8ZFx775v16P75sxH\u002fS\u002famz5iYhH6r9mh7wxyYzwvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2024","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2024","Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual (6)","showlegend":false,"x":{"dtype":"f8","bdata":"bfez8jWj579TnnS+yogBwMyQSv17kcg\u002f+9Ld9WRxAsDEaAe2maHXPyYLXEilGAPA"},"y":{"dtype":"f8","bdata":"zKn8XvmlBMCyN10cYAn4vyssNMalD9O\u002fmE2\u002fJu8d\u002fr+wlNm2bn3yv\u002fudSqmYu\u002fy\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2024"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"j9a6sVj0\u002fb8="},"y":{"dtype":"f8","bdata":"zZ\u002f\u002fK6GvAsA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions (4)","showlegend":false,"x":{"dtype":"f8","bdata":"gSES7qOp3j\u002fId+lXf+34P7Xfj82NU9w\u002fy2vb+fzv8T8="},"y":{"dtype":"f8","bdata":"4Kpha5vRnz+qSB\u002fKCJXLvxh4RSFttwTA5Kroj2+jqj8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2024","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2024","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2024","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization (31)","showlegend":false,"x":{"dtype":"f8","bdata":"nXSVvLM\u002f0T+MlQGzHgHFP8DBQ0SSRe+\u002fcjuwsWpW0j9T4sHFTjjjvyGdk2T67OC\u002faHKlsjJS9T\u002fgy41mTx7hvyoXrZOyOeG\u002fIemNpGuk4T8Ar0q0tX\u002fxP2CaefHZiLK\u002fEYCWzBxW3b+MNOtbilzYv5Jc5nuJ5+W\u002fhu0myONR4L\u002f6t3CO8MvIv+IErKN3neS\u002fPMJ4iibD6r82Qo3VNADHv4vg7ZoJbum\u002fAqfkMPLqzb9sV98oDtPXvzApy5L45uy\u002fYeaj0+Gp8L\u002fZRZeFJzvbv1KQpwkkw8e\u002fnhORi4uC2L9mFyg2hh\u002fVv6qkP9K1iPc\u002fIePBPWUT5b8="},"y":{"dtype":"f8","bdata":"cFg8Kbr5BMBuqs7gtd7Kv5yunLmeNgbAYcwuoFwGB8BcS7E9OrkGwKr9IPTW4AbAecJYTxSa7r+w9SAs6wYIwHKFbyu\u002f5AjA8Y\u002fTYj\u002fdyr8d3vBgCovtv7DH2inNBg3A9FniRWeQCMBj0LtnPY8GwJfmGoVFeAnA9w3ZL2LgCMBBJFENbKAKwKhsz9kbQQfA0iOPm4IRB8Ad4qm988YIwIgpEw+P\u002fwfAdD4Pp6BICcC6fLtXSA8HwN5vkf6gzgXAfYZqDaY3BsAVVFE4zHUIwH+QnigokArAFNSa2UCDBcB+VXUAu9MIwPRDXVHVRro\u002fs7n6t\u002fIkDMA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2024"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political (6)","showlegend":false,"x":{"dtype":"f8","bdata":"Xx0NLo4q\u002fD97Rx6jIxv8P1bWR1ydGf0\u002fviYUB2wK7T846qAWZKLMP7XAuhHWw8G\u002f"},"y":{"dtype":"f8","bdata":"NWmD+ecS9r9SWEB9nbn5vyoMucxXufW\u002fur2SMI94zL+oxcqZg4n2vxngBwb9qwvA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2024","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2024","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2024","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2024","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2024","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2024","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2024","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2024","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2024","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2024","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2024","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety (62)","showlegend":false,"x":{"dtype":"f8","bdata":"PB266GUQ8L9t97PyNaPnv510lbyzP9E\u002ftC8+8X839j9NdpEGNkD2P8sUAKbotP4\u002fgnfLXs\u002f4AEASwgh4KBbqPxYDIxwy4+4\u002fAWcByWf95j+di5v3xNbxP1K6n1jbDug\u002f0q3u7+Ry9z9itYKx6HLlP8jmeCLuwPA\u002fDK8\u002fOAOq1T9QEUMx0m\u002fkv7eGx8t7Quc\u002fI8+8YRxH6T\u002f0CDyZX4j1P8XKfemeFOo\u002fK\u002fKdwY619j8+cnD68YHxP+Fz2JKVrd0\u002fZE9cSK6i5T97iGhJZdQBQPRFo0Q2hOw\u002fdzm8uIKn7T9cbrXrMf3rP8lm2BUtyOU\u002fhJZkNIUK7z+By+e562jgP+BigaAbqNo\u002fPifw4cbZ5j8XLOFLFprqP8RoB7aZodc\u002f03W8WOs39j99VuZfhGDpP1u3QWzAPvE\u002f+DlKSyoY8D+iD+D9EqDUP5FRilyR1Ok\u002fwA\u002fTQ7ZX8T\u002fg5vIOAifoP3CY+4bXxOQ\u002fHXNORRT4\u002fz89iBngAdjyP9U\u002ffvgckew\u002fepz4iJn89j9mEQmZQPXtPwpWtvi4ReU\u002fFPjCO3732z8Hc6c5c579P3HGkOEgw+8\u002fhlEj+t939D8W4p7cn7TXP+TcJoSLP\u002fA\u002f0+qWgltL\u002fz\u002fBNCfL1jT1Pw8at58C1eM\u002fhiE9qTS8xL\u002fK\u002f8pmpx3ePw=="},"y":{"dtype":"f8","bdata":"OhSh3yxc\u002fb\u002fMqfxe+aUEwHBYPCm6+QTAb7P\u002fwLBbBcACZziLPUHVv1aXYJOMdwDA0SPvq6JK679GyGnBBXgFwOy+ScpYhAjAExR9bIQABsBsQOxkZrIFwO8K3T1OsAfAoFGpzF1jBcDgLyEQU0cJwMSKZh+BFQzAZutsuxs+B8BY7nNNs7C1Pyhf+EBPXsU\u002fQRPAsOmUAcB3CX86ypIDwDbPwQXnfATAWZMudEhjCsBApi2XLy3RP14aZSlMUQbAr95+qdjlA8DfvZGa8GHSv+4TzqGyFQfAjAf8IvM7AsA0qYu4Ub4DwCphTKTBrgvAv+HNL5w5CcBmOtsh6R0HwK5EzJ4LMQfA3ow+NUCV4b\u002fxleS4NH0FwLCU2bZuffK\u002fLNz6fx3sBcBLOPOsdH0BwELA854uEQXApoIwhHbVA8D6sTGrpl8FwKsdiT1\u002fZQjAwTn5F11UCMCLvS25EUgGwKe7oGe98gXA9DLNZ\u002fLe\u002fr8GG7WoymAJwMtQdwzfDAbA2R0pxCB8BMDdmk\u002fCPL0KwPxumIGv7AXA4XcwB6B5BsCGMzSWIkP4v+s4vQLevwjAhGdBmQjVB8AqJ1JmetMFwJ6CvIjD5AnACCO4UDqhAMCKtHZbu8cBwBATCTnsbwbAtoMZF2+sxr9D+O64n0AHwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism (1)","showlegend":false,"x":{"dtype":"f8","bdata":"Yl4nBdBY7D8="},"y":{"dtype":"f8","bdata":"YB7BD+RP8b8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2024","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2024"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social (18)","showlegend":false,"x":{"dtype":"f8","bdata":"f7UQIWY3AkAzmFZYHIoBQJfZwNaumgNAvCwQAGh4A0DNYd\u002fZovADQMDAyI4ubgpA6CaLCHgPBEBfwnSNH0QDQKO1S5lk\u002fQFAtd+PzY1T3D8Ar0q0tX\u002fxP0uOv4lD4gdAe0ceoyMb\u002fD8MY0qF54IDQGOijpbk5\u002f4\u002fpLjXYatYAkAq0BKkIIT+P6qkP9K1iPc\u002f"},"y":{"dtype":"f8","bdata":"6KK9GAMzAMCKppVyeXYBwLgkUoOeGP+\u002feAuq3XZ\u002fAMAiUOJpo8ADwNQTAME5R9m\u002f+hhM5+J3AsDMkZIyYTjlv2qCYfDpq6w\u002fGHhFIW23BMAd3vBgCovtv7qC+7PFyMG\u002fUlhAfZ25+b8Su\u002f19T04BwIT1qK0hOgDAI17zATkztL\u002f\u002fZ33Uu24BwPRDXVHVRro\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2024","Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2024","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity (6)","showlegend":false,"x":{"dtype":"f8","bdata":"yxQApui0\u002fj+3iSBBdjYDQEKs2IQFDQRAPlHN8BhmBUDBNCfL1jT1P2CPkZI4KgRA"},"y":{"dtype":"f8","bdata":"Vpdgk4x3AMD9Um7\u002frgbwvwDthNFqYfC\u002fJHGAHbNw9b+KtHZbu8cBwJQSQIyBS\u002fS\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2024","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2024","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2024","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2024","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value (15)","showlegend":false,"x":{"dtype":"f8","bdata":"qOrsXgW3CEAobSJ2qjIGQKtM2EkwEgdAvgKjNyhiBkCwbJyaxVoEQO2gM0TBZwZAHXNORRT4\u002fz\u002fMB\u002fR8CioFQByHphef1c4\u002fzbLR7U\u002f1A0BBiJEg2rMDQAdzpzlznv0\u002fPVEjuSwtCEDT6paCW0v\u002fP7ESskK2nQJA"},"y":{"dtype":"f8","bdata":"npVq\u002fpyU3b\u002fkGP52UNrov\u002fXj13wPiOK\u002fuESbkST51L8NnjEZbmPhvxNI08tZpeG\u002f9DLNZ\u002fLe\u002fr9VyxqkjNXjv16P75sxH\u002fS\u002f3lxcO1Nw4b\u002fYxgW2QMzvv4YzNJYiQ\u002fi\u002fGS9evjRG478II7hQOqEAwBOYE+G0AeC\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2025","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2025","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2025","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2025","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2025","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2025","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2025","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2025","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2025","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2025","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2025"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias (19)","showlegend":false,"x":{"dtype":"f8","bdata":"CUwWEXARCEDAwMiOLm4KQLelLXmJaPU\u002fXx0NLo4q\u002fD\u002fId+lXf+34P3uIaEll1AFAlKaoeqqz9j+jtUuZZP0BQEuOv4lD4gdAy2vb+fzv8T97Rx6jIxv8P1bWR1ydGf0\u002f1f3JyHgqBUC+JhQHbArtP6I9tkKNywZAfxZOVFh9AEA46qAWZKLMP2JeJwXQWOw\u002fr85VTijOCEA="},"y":{"dtype":"f8","bdata":"85G\u002fJbuj4z\u002fUEwDBOUfZv55lANVLGM2\u002fNWmD+ecS9r+qSB\u002fKCJXLv9+9kZrwYdK\u002fTeqVGCQI1b9qgmHw6ausP7qC+7PFyMG\u002f5Kroj2+jqj9SWEB9nbn5vyoMucxXufW\u002fm6+j8LgU9D+6vZIwj3jMv+BJOFqTaOI\u002ffgUnDzET+D+oxcqZg4n2v2AewQ\u002fkT\u002fG\u002feMUArJXz6j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2025","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2025","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2025","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2025","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2025","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2025","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2025","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2025"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural (30)","showlegend":false,"x":{"dtype":"f8","bdata":"PANz+WA0tT\u002fMkEr9e5HIPxZ9lOs89AhAgnfLXs\u002f4AEAJTBYRcBEIQI8m34X1QwBAPysnTGR9B0DgyVS9dP8CQFUHo8l78AZARMgrGcgiCEDdhOYC6pgHQMC2TxxZiQpAwMDIji5uCkC3pS15iWj1P2hypbIyUvU\u002fX8J0jR9EA0CUpqh6qrP2P6I9tkKNywZAxGgHtpmh1z9uDO\u002fGIIbDP+jjhSjBWdk\u002fk7mgm0\u002fNCEAy8D\u002fPAZ8JQK48IbaiiARAurlZVCEiCUCU7eAuiBn5P6qkP9K1iPc\u002fswdWBONMBkC9hoQ\u002fBqUIQAoOFeuhGL+\u002f"},"y":{"dtype":"f8","bdata":"IcS987S1278rLDTGpQ\u002fTv6eKXHlmF9o\u002f0SPvq6JK67\u002fzkb8lu6PjP6dEV+T8uOY\u002fjKRMcLAI8j\u002fABOQNCsveP1geyef7l+A\u002fcHH5y+Ww8D\u002fEHqyCWY3xP1XCZ\u002f9u0O8\u002f1BMAwTlH2b+eZQDVSxjNv3nCWE8Umu6\u002fzJGSMmE45b9N6pUYJAjVv+BJOFqTaOI\u002fsJTZtm598r9uWc8vvmvKv92qJ0gipuU\u002f4Pb+V10l9j\u002fT8FhRqDPiPzHCXTzeYdo\u002f6gsvXjB+4z9ApCAq7u38P\u002fRDXVHVRro\u002fs5ksZbYy2j+ucP0VTlTjP9o385uH8eU\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture (3)","showlegend":false,"x":{"dtype":"f8","bdata":"HkaH6SzQBED4whb82pkIQDRTF5b3OANA"},"y":{"dtype":"f8","bdata":"rAmnZhVI9z9NzeIUjAfpP\u002fpU87fsYfI\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2025","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2025","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2025","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2025","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2025","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2025"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics (14)","showlegend":false,"x":{"dtype":"f8","bdata":"gSES7qOp3j95VUFJ7G8BQHDND3nLWgVAGvRCdJEaAUDId+lXf+34P3uIaEll1AFAo7VLmWT9AUBLjr+JQ+IHQMtr2\u002fn87\u002fE\u002f2Mb70RLL9T\u002fV\u002fcnIeCoFQK\u002fOVU4ozghATiceAb94BECkuNdhq1gCQA=="},"y":{"dtype":"f8","bdata":"4Kpha5vRnz9Fubht0o3+P\u002fpRA8PX5wBAbByX+r\u002fM+T+qSB\u002fKCJXLv9+9kZrwYdK\u002faoJh8OmrrD+6gvuzxcjBv+Sq6I9vo6o\u002fyVyg49nSAUCbr6PwuBT0P3jFAKyV8+o\u002f2s56TUG4\u002fD8jXvMBOTO0vw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2025","Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2025","Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2025","Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2025","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2025","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2025","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2025","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2025"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity (10)","showlegend":false,"x":{"dtype":"f8","bdata":"TXaRBjZA9j+MlQGzHgHFP1q9beiI8u8\u002fg+o8T29q9j9BxOVSm+fqPz5ycPrxgfE\u002fIemNpGuk4T\u002fYxvvREsv1P38WTlRYfQBA6OOFKMFZ2T8="},"y":{"dtype":"f8","bdata":"Amc4iz1B1b9uqs7gtd7Kv4Nv4b\u002fpGQdAZRIs8oL9BEBwCsQsaPwBQECmLZcvLdE\u002f8Y\u002fTYj\u002fdyr\u002fJXKDj2dIBQH4FJw8xE\u002fg\u002f3aonSCKm5T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical (6)","showlegend":false,"x":{"dtype":"f8","bdata":"0V46T3FK8D9TNRmahsHpP2CQQXJVrOo\u002fAK9KtLV\u002f8T+qpD\u002fStYj3PxrgZZRaV+o\u002f"},"y":{"dtype":"f8","bdata":"Mzi9HDZpBUC4hmWl\u002f1kHQJxKjwphJQhAHd7wYAqL7b\u002f0Q11R1Ua6P0yFkBk1VwhA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2025","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2025","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2025","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2025","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality (21)","showlegend":false,"x":{"dtype":"f8","bdata":"GuJ+gWdK2T+uEcA1ilnZP7cITzog4t8\u002fTPgcQP4o0D+Y9ERJZAbQv7eGx8t7Quc\u002fUC4t8EwVzL98qWyrpVywv6ZyNm0Tj8O\u002fyEU5XYedp78+J\u002fDhxtnmP91TrH1jCNs\u002fviYUB2wK7T9AhIEA+ILSP9N2MUGFyNM\u002fxKDxMLu+7j\u002flDWXPMKbUP4gm0nrlfeY\u002fujsumOBM5T+U7eAuiBn5P8xGruAeUrm\u002f"},"y":{"dtype":"f8","bdata":"gYRV4RS6B0D4U1Q\u002f4xkGQLujw5FW6AxAFOsLNEuFCUC7AWj2r8AKQChf+EBPXsU\u002fLFf3aQHGAkDda5iV7fAJQFDn97MBVQ5A6DtlhDZACkDejD41QJXhv4hRZlgcSgdAur2SMI94zL\u002fQm2FVkkYGQK6oFPVaEQVAOAMOFw7eCUCSluy6gIoNQKLAiqDw2glAd4i8MyF7B0BApCAq7u38PwD\u002fOo0nRgpA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2025"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"XmBFETQ01r8="},"y":{"dtype":"f8","bdata":"LMpP6jeOB0A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2025","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2025","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general (69)","showlegend":false,"x":{"dtype":"f8","bdata":"WiXGkyVp87+2O6lnZqnyv5YK6LDXs\u002fe\u002fpnikSWxp8L\u002fRhBhmgmP3v+YkhswTXPO\u002f9RN+9AF58L\u002f\u002fb\u002faYH5f2v06sPZk5HPu\u002fhyWaN5vs8r8jXmEX\u002fIv0v+7a5jUhlvK\u002fjtBLkfuN+L\u002fmkeTEc4bsv3FiMqvwoum\u002fmHPFOqaY7b+kD0ZOwDP2v49kYLuB5vG\u002fmkNrFb1G8b+6lHoQXUzwv\u002fhCvTU\u002fQuy\u002fTrt0K9YD4r8pvnngxqb3v8P2dGuW2\u002fW\u002fbBZccZHU9b8UiqVucKbyv41PobXaHvW\u002f\u002fBZ7Cu2A87\u002f5jzrN9iTxv+ZWCnXGBO6\u002fu8xjvHaI8L+IaYMR0wbzvxiFmC1Ywfm\u002fpG0rKqW\u002f3L+U\u002fezC5JX7v3aASoG7RvG\u002fqrZRn54m+r82sj62UXr9v1SmfVHAkvO\u002fIQDO1NIL9L8xnX7kLI7yv6SZnlJbUvO\u002fL72Kzxrl9L\u002fWIMwFDejzv9hW+9zVbva\u002foBwaVvuVAMBmDawGfFH3v3T7DHFLUPC\u002feXz6gxEk+L\u002f1u0aI3KP2v+dXMmNAdPO\u002faok2eCxM978GNEfu6M72v0Xg4CFMTfy\u002fsXDG5uwv97\u002f3Prp06of0vzJE9JIbrPO\u002fA3sJE7jZ87+2HL+sIlj0v+MMj7Q6ofK\u002fgInoaJ5W7r8k1LYbsc4AwOmYRh14IPa\u002fCtx\u002f0+kM979CA3z92BPpv7IHx+rP\u002fvm\u002flYKPxEDg9b+GIT2pNLzEvwb8sa4yBvG\u002f"},"y":{"dtype":"f8","bdata":"dxO7zeoqBkATp7d+ibgFQEi62LQeSQRAHQovHnNPBUDkGM5RinIDQLZ+0Wb2TANAF2jEb6mrA0BmxEgRvZADQDSGvGVmZAVAWZwjKEMFCEBDQZmp8BcFQB\u002fQdoUxWAdAKDraCfTgBUCEhYywlOUDQKiPMI9zXQhAfc\u002f\u002fEawLBEC2GQBtAx4DQPjTQei2LgNA\u002fUXtbxT7BkCa3ZJo6A0EQEeStvq2oQVAhiUjBU+fCkBYkT1UWOACQFoFkNzVggFArs9VpPL4BkAxzXKsp4IFQJbDScUOcgZAlUee32rEAkAiJrztPFYDQJEaLQBh7QNAlIaDJfg2CUBNO77AQ9YGQMPuLlxliQRAigBMSmafAkCPeqCUmQEFQBro49VZ3QdAYeTmAAkUCkCCRiUUAbsAQCvLelp4kwdABdtQYCBOBUDDDkw6Kv8BQEsXw+DtTQNA0PGpdcoKB0C8R\u002fOp39oFQPY7E6nJZQdApoBVWbKg9j\u002fSMGNTw\u002f0FQMi6CH+OBQpAaQuzGn32BUB\u002fN6gSw+0GQFZzCqlfuwRADfH7R9+6CUDSe1TVZzEEQFFBgecYsAhAIWsyGgDWBEDvg9DVtbAGQK0aOw1XLQVAWor\u002fVPOGAUA5UWPC\u002fpkHQIi5aciuNgdAysCuxRUMCEBjt4+L1+IDQEbmvtNUkwhAo\u002fXbiulzBkCXpaRsAtQDQEAPjiISRQVAngZq4juEA0C2gxkXb6zGv6ZCpjL4NAZA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2025"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate (1)","showlegend":false,"x":{"dtype":"f8","bdata":"UBFDMdJv5L8="},"y":{"dtype":"f8","bdata":"WO5zTbOwtT8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2025"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor (1)","showlegend":false,"x":{"dtype":"f8","bdata":"ELyQxKpZAcA="},"y":{"dtype":"f8","bdata":"rDQB0Vi6\u002fT8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2025"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language (4)","showlegend":false,"x":{"dtype":"f8","bdata":"5anFOYP\u002fBMAhlfNLQOYDwNkXGchm2QbACg4V66EYv78="},"y":{"dtype":"f8","bdata":"Sc\u002f8MMvP9T9Atod3FUP2PyrF6uCrueM\u002f2jfzm4fx5T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2025"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal (1)","showlegend":false,"x":{"dtype":"f8","bdata":"3P74mldVA8A="},"y":{"dtype":"f8","bdata":"ncm355lo0z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2025"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length (1)","showlegend":false,"x":{"dtype":"f8","bdata":"oBwaVvuVAMA="},"y":{"dtype":"f8","bdata":"poBVWbKg9j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2025","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2025","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2025","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2025","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2025","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral (20)","showlegend":false,"x":{"dtype":"f8","bdata":"Zrxybwz1BcA8HbroZRDwv0l0JUvcWgjAPANz+WA0tT9RwWP47REIwBrBQQOTAAbAu54trD6UA8C3pS15iWj1P5SmqHqqs\u002fY\u002fbgzvxiCGwz846qAWZKLMP+jjhSjBWdk\u002fYl4nBdBY7D90PAa883QIwEfixnCsZgjAvgBjMGdPCcAVv7k7QzAJwByHphef1c4\u002fygYsZvs8BcA5akQChRQHwA=="},"y":{"dtype":"f8","bdata":"GJHNP4A99r86FKHfLFz9v9JwUjQBGfW\u002fIcS987S127+CZFZNLaD7v9JttXoYyei\u002fwHpg+B2J8L+eZQDVSxjNv03qlRgkCNW\u002fblnPL75ryr+oxcqZg4n2v92qJ0gipuU\u002fYB7BD+RP8b9a0QTzwH70v0pjduMG0\u002fK\u002f4xRpNZzs9r8sh8ZFx775v16P75sxH\u002fS\u002famz5iYhH6r9mh7wxyYzwvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2025","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2025","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2025","Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2025","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2025","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2025"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual (6)","showlegend":false,"x":{"dtype":"f8","bdata":"bfez8jWj579TnnS+yogBwMyQSv17kcg\u002f+9Ld9WRxAsDEaAe2maHXPyYLXEilGAPA"},"y":{"dtype":"f8","bdata":"zKn8XvmlBMCyN10cYAn4vyssNMalD9O\u002fmE2\u002fJu8d\u002fr+wlNm2bn3yv\u002fudSqmYu\u002fy\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2025"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"j9a6sVj0\u002fb8="},"y":{"dtype":"f8","bdata":"zZ\u002f\u002fK6GvAsA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2025","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2025","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions (4)","showlegend":false,"x":{"dtype":"f8","bdata":"gSES7qOp3j\u002fId+lXf+34P7Xfj82NU9w\u002fy2vb+fzv8T8="},"y":{"dtype":"f8","bdata":"4Kpha5vRnz+qSB\u002fKCJXLvxh4RSFttwTA5Kroj2+jqj8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2025","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2025","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2025","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2025","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2025","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization (31)","showlegend":false,"x":{"dtype":"f8","bdata":"nXSVvLM\u002f0T+MlQGzHgHFP8DBQ0SSRe+\u002fcjuwsWpW0j9T4sHFTjjjvyGdk2T67OC\u002faHKlsjJS9T\u002fgy41mTx7hvyoXrZOyOeG\u002fIemNpGuk4T8Ar0q0tX\u002fxP2CaefHZiLK\u002fEYCWzBxW3b+MNOtbilzYv5Jc5nuJ5+W\u002fhu0myONR4L\u002f6t3CO8MvIv+IErKN3neS\u002fPMJ4iibD6r82Qo3VNADHv4vg7ZoJbum\u002fAqfkMPLqzb9sV98oDtPXvzApy5L45uy\u002fYeaj0+Gp8L\u002fZRZeFJzvbv1KQpwkkw8e\u002fnhORi4uC2L9mFyg2hh\u002fVv6qkP9K1iPc\u002fIePBPWUT5b8="},"y":{"dtype":"f8","bdata":"cFg8Kbr5BMBuqs7gtd7Kv5yunLmeNgbAYcwuoFwGB8BcS7E9OrkGwKr9IPTW4AbAecJYTxSa7r+w9SAs6wYIwHKFbyu\u002f5AjA8Y\u002fTYj\u002fdyr8d3vBgCovtv7DH2inNBg3A9FniRWeQCMBj0LtnPY8GwJfmGoVFeAnA9w3ZL2LgCMBBJFENbKAKwKhsz9kbQQfA0iOPm4IRB8Ad4qm988YIwIgpEw+P\u002fwfAdD4Pp6BICcC6fLtXSA8HwN5vkf6gzgXAfYZqDaY3BsAVVFE4zHUIwH+QnigokArAFNSa2UCDBcB+VXUAu9MIwPRDXVHVRro\u002fs7n6t\u002fIkDMA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2025","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2025","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2025","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2025","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2025","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2025"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political (6)","showlegend":false,"x":{"dtype":"f8","bdata":"Xx0NLo4q\u002fD97Rx6jIxv8P1bWR1ydGf0\u002fviYUB2wK7T846qAWZKLMP7XAuhHWw8G\u002f"},"y":{"dtype":"f8","bdata":"NWmD+ecS9r9SWEB9nbn5vyoMucxXufW\u002fur2SMI94zL+oxcqZg4n2vxngBwb9qwvA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2025","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2025","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2025","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2025","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2025","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2025","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2025","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2025","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2025","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2025","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2025","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2025","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2025","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety (62)","showlegend":false,"x":{"dtype":"f8","bdata":"PB266GUQ8L9t97PyNaPnv510lbyzP9E\u002ftC8+8X839j9NdpEGNkD2P8sUAKbotP4\u002fgnfLXs\u002f4AEASwgh4KBbqPxYDIxwy4+4\u002fAWcByWf95j+di5v3xNbxP1K6n1jbDug\u002f0q3u7+Ry9z9itYKx6HLlP8jmeCLuwPA\u002fDK8\u002fOAOq1T9QEUMx0m\u002fkv7eGx8t7Quc\u002fI8+8YRxH6T\u002f0CDyZX4j1P8XKfemeFOo\u002fK\u002fKdwY619j8+cnD68YHxP+Fz2JKVrd0\u002fZE9cSK6i5T97iGhJZdQBQPRFo0Q2hOw\u002fdzm8uIKn7T9cbrXrMf3rP8lm2BUtyOU\u002fhJZkNIUK7z+By+e562jgP+BigaAbqNo\u002fPifw4cbZ5j8XLOFLFprqP8RoB7aZodc\u002f03W8WOs39j99VuZfhGDpP1u3QWzAPvE\u002f+DlKSyoY8D+iD+D9EqDUP5FRilyR1Ok\u002fwA\u002fTQ7ZX8T\u002fg5vIOAifoP3CY+4bXxOQ\u002fHXNORRT4\u002fz89iBngAdjyP9U\u002ffvgckew\u002fepz4iJn89j9mEQmZQPXtPwpWtvi4ReU\u002fFPjCO3732z8Hc6c5c579P3HGkOEgw+8\u002fhlEj+t939D8W4p7cn7TXP+TcJoSLP\u002fA\u002f0+qWgltL\u002fz\u002fBNCfL1jT1Pw8at58C1eM\u002fhiE9qTS8xL\u002fK\u002f8pmpx3ePw=="},"y":{"dtype":"f8","bdata":"OhSh3yxc\u002fb\u002fMqfxe+aUEwHBYPCm6+QTAb7P\u002fwLBbBcACZziLPUHVv1aXYJOMdwDA0SPvq6JK679GyGnBBXgFwOy+ScpYhAjAExR9bIQABsBsQOxkZrIFwO8K3T1OsAfAoFGpzF1jBcDgLyEQU0cJwMSKZh+BFQzAZutsuxs+B8BY7nNNs7C1Pyhf+EBPXsU\u002fQRPAsOmUAcB3CX86ypIDwDbPwQXnfATAWZMudEhjCsBApi2XLy3RP14aZSlMUQbAr95+qdjlA8DfvZGa8GHSv+4TzqGyFQfAjAf8IvM7AsA0qYu4Ub4DwCphTKTBrgvAv+HNL5w5CcBmOtsh6R0HwK5EzJ4LMQfA3ow+NUCV4b\u002fxleS4NH0FwLCU2bZuffK\u002fLNz6fx3sBcBLOPOsdH0BwELA854uEQXApoIwhHbVA8D6sTGrpl8FwKsdiT1\u002fZQjAwTn5F11UCMCLvS25EUgGwKe7oGe98gXA9DLNZ\u002fLe\u002fr8GG7WoymAJwMtQdwzfDAbA2R0pxCB8BMDdmk\u002fCPL0KwPxumIGv7AXA4XcwB6B5BsCGMzSWIkP4v+s4vQLevwjAhGdBmQjVB8AqJ1JmetMFwJ6CvIjD5AnACCO4UDqhAMCKtHZbu8cBwBATCTnsbwbAtoMZF2+sxr9D+O64n0AHwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2025"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism (1)","showlegend":false,"x":{"dtype":"f8","bdata":"Yl4nBdBY7D8="},"y":{"dtype":"f8","bdata":"YB7BD+RP8b8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2025","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2025","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2025","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2025","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2025","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2025","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social (18)","showlegend":false,"x":{"dtype":"f8","bdata":"f7UQIWY3AkAzmFZYHIoBQJfZwNaumgNAvCwQAGh4A0DNYd\u002fZovADQMDAyI4ubgpA6CaLCHgPBEBfwnSNH0QDQKO1S5lk\u002fQFAtd+PzY1T3D8Ar0q0tX\u002fxP0uOv4lD4gdAe0ceoyMb\u002fD8MY0qF54IDQGOijpbk5\u002f4\u002fpLjXYatYAkAq0BKkIIT+P6qkP9K1iPc\u002f"},"y":{"dtype":"f8","bdata":"6KK9GAMzAMCKppVyeXYBwLgkUoOeGP+\u002feAuq3XZ\u002fAMAiUOJpo8ADwNQTAME5R9m\u002f+hhM5+J3AsDMkZIyYTjlv2qCYfDpq6w\u002fGHhFIW23BMAd3vBgCovtv7qC+7PFyMG\u002fUlhAfZ25+b8Su\u002f19T04BwIT1qK0hOgDAI17zATkztL\u002f\u002fZ33Uu24BwPRDXVHVRro\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2025","Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2025","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2025","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2025","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2025","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2025"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity (6)","showlegend":false,"x":{"dtype":"f8","bdata":"yxQApui0\u002fj+3iSBBdjYDQEKs2IQFDQRAPlHN8BhmBUDBNCfL1jT1P2CPkZI4KgRA"},"y":{"dtype":"f8","bdata":"Vpdgk4x3AMD9Um7\u002frgbwvwDthNFqYfC\u002fJHGAHbNw9b+KtHZbu8cBwJQSQIyBS\u002fS\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2025","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2025","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value (15)","showlegend":false,"x":{"dtype":"f8","bdata":"qOrsXgW3CEAobSJ2qjIGQKtM2EkwEgdAvgKjNyhiBkCwbJyaxVoEQO2gM0TBZwZAHXNORRT4\u002fz\u002fMB\u002fR8CioFQByHphef1c4\u002fzbLR7U\u002f1A0BBiJEg2rMDQAdzpzlznv0\u002fPVEjuSwtCEDT6paCW0v\u002fP7ESskK2nQJA"},"y":{"dtype":"f8","bdata":"npVq\u002fpyU3b\u002fkGP52UNrov\u002fXj13wPiOK\u002fuESbkST51L8NnjEZbmPhvxNI08tZpeG\u002f9DLNZ\u002fLe\u002fr9VyxqkjNXjv16P75sxH\u002fS\u002f3lxcO1Nw4b\u002fYxgW2QMzvv4YzNJYiQ\u002fi\u002fGS9evjRG478II7hQOqEAwBOYE+G0AeC\u002f"},"type":"scatter"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scattermap":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermap"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"font":{"size":16},"text":"Multi-label Clusters (All Years)"},"xaxis":{"range":[-4.5,4.5],"title":{"text":""},"showgrid":true,"gridcolor":"lightgray"},"yaxis":{"range":[-4.5,4.5],"title":{"text":""},"showgrid":true,"gridcolor":"lightgray","scaleanchor":"x","scaleratio":1},"height":800,"width":1000,"hovermode":"closest"},                        {"responsive": true}                    )                };            </script>        </div>
</body>
</html>