<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />   <!--It is necessary to use the UTF-8 encoding with plotly graphics to get e.g. negative signs to render correctly -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Visualisation of Alignment Survey</title>
</head>

<body>
    <h1>Visualisation of Alignment Survey</h1>
    <h2>Papers from each year (2022-2025)</h2>
    <div>                        <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.3.1.min.js" integrity="sha256-4rD3fugVb/nVJYUv5Ky3v+fYXoouHaBSP20WIJuEiWg=" crossorigin="anonymous"></script>                <div id="f9909d71-d197-4254-921d-43cc84b19ef8" class="plotly-graph-div" style="height:700px; width:900px;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("f9909d71-d197-4254-921d-43cc84b19ef8")) {                    Plotly.newPlot(                        "f9909d71-d197-4254-921d-43cc84b19ef8",                        [{"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"bias","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"cultural","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"culture","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"demographics","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"diversity","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"ethical","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"factuality","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"faithfulness","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"general","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"hate","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"humor","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"language","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"legal","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"length","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"moral","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"multilingual","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"offensiveness","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"opinions","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"personalization","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"political","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"safety","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"sexism","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"social","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"toxicity","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"size":10},"mode":"markers","name":"value","showlegend":true,"x":[null],"y":[null],"type":"scatter","visible":true},{"hoverinfo":"text","hovertext":["Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2022"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity","showlegend":false,"visible":true,"x":{"dtype":"f8","bdata":"slodSUjA9T8="},"y":{"dtype":"f8","bdata":"V1bCiFOGB0A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general","showlegend":false,"visible":true,"x":{"dtype":"f8","bdata":"KqFhQzEs9b\u002fKUvHfJnntv4BqHWqmyfq\u002f12BW8vgb878="},"y":{"dtype":"f8","bdata":"xDnx+NzmBUBeQ181EjMGQLLv6VypiQNAzVAnTW8CCkA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral","showlegend":false,"visible":true,"x":{"dtype":"f8","bdata":"+grNw6wfC8A="},"y":{"dtype":"f8","bdata":"Yi09sgBx6r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization","showlegend":false,"visible":true,"x":{"dtype":"f8","bdata":"boqDWDMw7L8="},"y":{"dtype":"f8","bdata":"ZyjqLOIgBsA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"GKwznqOgBEA="},"y":{"dtype":"f8","bdata":"tD6CAeSt5z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2023"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"w+34TevN9z8="},"y":{"dtype":"f8","bdata":"IY7dqD0XAUA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"nvkfKC231T8="},"y":{"dtype":"f8","bdata":"6k5qoOF3DEA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"VkfXaWX\u002f9b+zy6B0Z1D2vzyWbpUfK+2\u002fhOFf72K39b81YtRL+jvyv8wIU7Xe+v2\u002f\u002fs67mdBC+7+qGMV4Wa\u002f4v1rrsS9GYfO\u002fvowl7HfK9r+SB1bxB+bzvw=="},"y":{"dtype":"f8","bdata":"4mORuSDBB0AfgUMeuHkJQCSD03L7iAVA9Hah7eY0CkBlQvU3AkcFQOs0aGVQTQdAM\u002fmGY+LvBEDVLh8lXLYEQOwndJo0BQVAhAHTneTnBEAPwgzlPGcEQA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"Fnq7U8nhCsA="},"y":{"dtype":"f8","bdata":"KHSm9dEw7r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"MDzYCJLn178="},"y":{"dtype":"f8","bdata":"DP71Nxy3CMA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"Qrq45os7A0D\u002f00eGSV3tPyw\u002fiOqiNfQ\u002fDgZP4C7B7D\u002fDkNa4Hf8BQNed\u002f6+B3+w\u002fIZ+ixb3bBEAv8YxU8VcCQOiChQXyrvI\u002fkB7y1GsK\u002fD93LoJCzcP7P4hcL7S1fwdAOuEMhIvI8T\u002fPE+W+D2gHQIi3Qga\u002fxQBAd54AeTJ\u002fwT\u002f6As5TErHXP8DOfT7hBQdA"},"y":{"dtype":"f8","bdata":"jFpgXjti27\u002fo5Ark8XHRv3EDkrADqPq\u002fx267kWrm0r\u002fd6q8EQU\u002fdv7KNgAwPaM6\u002f5EV2WKy92L+u1cBEm\u002fGzvy3qgU0KaOa\u002fyNscmW3H\u002fb9ew7F02b34v1olLiwIafI\u002fT1FIF70yzT97DHrRkCHCP8qYHM0hQ\u002fY\u002fumXbPJTN9L\u002fcX9M\u002fLY72v0EWC2\u002fv8Ow\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2024","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2024"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"FAxgyNLdCEDmoFpZ2VUIQCEn5nD4iQVAQrq45os7A0D\u002f00eGSV3tP95wCrU7oe0\u002fp83KD8UCA0DXnf+vgd\u002fsP88T5b4PaAdA6xnzar3G5T\u002fwtQ4whTV2v1wKL2rS1Mo\u002fzSUvvFFqCECTJ5DvHfoHQCKoBWj6e6K\u002f"},"y":{"dtype":"f8","bdata":"JKMNm1Hd5D\u002fY+ose3+voP5UgsHtSw9g\u002fjFpgXjti27\u002fo5Ark8XHRv8xqTqLR9vO\u002fpAmRImxt67+yjYAMD2jOv3sMetGQIcI\u002fspNDn6LR87\u002fhoWrHg3jbv0lOSDiMju8\u002fYYSni6p64j\u002fgAfnyg2nfP3bZnNTUJuk\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2024","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"bVBLImXoBEAOBk\u002fgLsHsP8OQ1rgd\u002fwFAIZ+ixb3bBEAv8YxU8VcCQOiChQXyrvI\u002fsiwvxNYa+j+IXC+0tX8HQMDOfT7hBQdA"},"y":{"dtype":"f8","bdata":"dIEneZVZBEDHbruRaubSv93qrwRBT92\u002f5EV2WKy92L+u1cBEm\u002fGzvy3qgU0KaOa\u002f6W0d2hrc\u002fj9aJS4sCGnyP0EWC2\u002fv8Ow\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2024","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2024","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2024","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"+J5WFr7eAECoMJAjSd\u002f3P\u002fA+cBStdLw\u002fsiwvxNYa+j+It0IGv8UAQFwKL2rS1Mo\u002f"},"y":{"dtype":"f8","bdata":"SPm8iEBwAUA8mPsgI\u002fyuP0y\u002ftdtvm8w\u002f6W0d2hrc\u002fj\u002fKmBzNIUP2P0lOSDiMju8\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"pqUgTDkC8z+aQBq0V6PrPw=="},"y":{"dtype":"f8","bdata":"1BI6qV4s7b\u002fo5\u002fcaRgYCQA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"fh8PFOQi4j\u002faZ1UNnTnmPyOlDGkDkuE\u002f52AnHTxouz8e\u002fPOjjzXOP6Ktd+bXDrA\u002fSDwGkrFCzT8cELISA9rkPzbcByi38N8\u002fOuEMhIvI8T+ImOTbE8nKPyP036FlAOQ\u002f1fI+UVeW2r\u002fpF0WzKL3hP72RscJghtI\u002f"},"y":{"dtype":"f8","bdata":"KpLxIw+MBUAGUKwe8RwJQCr1beIr\u002ftW\u002f04JNISk0CEAPDp2BRLwHQDbfvjilPgtAqORSt8p5BEA6KPMcyGirvwO0mmdVZgpAT1FIF70yzT92tHboddYIQOCgntH4UwVAamwYE1S\u002fCUAMianhckAIQIw0IaMiFQdA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2024","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"5y1ssa3s+b9Q0JEjhiD3vxG2LHiGavG\u002f2aXyCcQE+b\u002feP2IDrkH0v5tBYjPP5va\u002fR5RO4L5F8L9ub3woPuf1v16aIG4FX\u002fi\u002fMNojzoVv7r+JJfDQsEL1v7lSJAMOI\u002fC\u002fGrQ002hA+L8QNGXOHlr4v\u002fgLvBwLsvK\u002fm6eTS3iQ9r8S1garkw75vzQc8t264O2\u002f+NWucr3g8b9ajP+77\u002fj4v4nC8WPuNfG\u002f6cbWENcC0b+63mZ+uEv0vw=="},"y":{"dtype":"f8","bdata":"7hnKxJdRBUAOJGTOQcYFQHWFOL0R6AZAurAteINZCECuBCMq7G8DQM2tabOkIgRAmJCI7osJAkDTVYIR\u002f1AHQEtXUtqnUQVAuu0S72znBkBdMS5Z22UHQCzyDnJxVgdAchEktZwpBEBA5RLRMcEFQL+ue2e6WQNAu7+jgfLDBEDhtgI9JNIFQFlNsfwuOwNA2EsN\u002fkE6BUCtfwME7F4IQJr84KJTFANAcPAPrKlR5b9aUL4j3PQFQA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2024"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"+oPkGL1l5r8="},"y":{"dtype":"f8","bdata":"3HxNgyuj1L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2024"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"WOgGo6uxB8A="},"y":{"dtype":"f8","bdata":"uFBf\u002fgdR\u002fT8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2024"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"IqgFaPp7or8="},"y":{"dtype":"f8","bdata":"dtmc1NQm6T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"T6MWHXqrBsD\u002f00eGSV3tP9ed\u002f6+B3+w\u002f8LUOMIU1dr93ngB5Mn\u002fBP1wKL2rS1Mo\u002f+gLOUxKx1z\u002f1AwrUnBQJwM+oK8lKVgXA"},"y":{"dtype":"f8","bdata":"2FyERxEj97\u002fo5Ark8XHRv7KNgAwPaM6\u002f4aFqx4N427+6Zds8lM30v0lOSDiMju8\u002f3F\u002fTPy2O9r84rRdw6ATqv0YZE1mu9uq\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"Ex+WD4vwAsDrGfNqvcblPwvyZPhzgwbA"},"y":{"dtype":"f8","bdata":"8tYxZUX3+b+yk0OfotHzv4Kqrn3kvvi\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2024"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"vQUUUkLA+L8="},"y":{"dtype":"f8","bdata":"KDHFwPwf\u002fL8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"DgZP4C7B7D+M\u002f4Btw2+6P+iChQXyrvI\u002f"},"y":{"dtype":"f8","bdata":"x267kWrm0r\u002fYRv+qlgkEwC3qgU0KaOa\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2024","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"tIkjpA967r\u002fecAq1O6HtP\u002fRyLuoxi+G\u002fcBmRN7Alsz\u002fwPnAUrXS8P6alIEw5AvM\u002fpAdprZfD1r+nzhIrMf7pv9tBV3e1A+C\u002f"},"y":{"dtype":"f8","bdata":"l3t4xuMvCsDMak6i0fbzv8RcLyRG9wXAYgM1ZAB0B8BMv7Xbb5vMP9QSOqleLO2\u002fWnGtwrVuCMAbsje+iEoJwLPhQp0euQvA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2024"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"LD+I6qI19D+QHvLUawr8P3cugkLNw\u002fs\u002fOuEMhIvI8T93ngB5Mn\u002fBPxurjxNpAOC\u002f"},"y":{"dtype":"f8","bdata":"cQOSsAOo+r\u002fI2xyZbcf9v17DsXTZvfi\u002fT1FIF70yzT+6Zds8lM30vwfr7yjlgQbA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2024","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2024","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2024","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2024","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"ku4UjDl08D\u002f4yMQn8tPoPwOERLby3Oc\u002fGEewQAEa4D+vXNMyQY3rP8WIVHn+mvM\u002fzUuLhWFh6T\u002f6g+QYvWXmvyOlDGkDkuE\u002f\u002f2nKgQtg+T9ih93iz5f4P0J7Xlv2Auc\u002fLlQqbNdg8T+oMJAjSd\u002f3P7yCRBl\u002fPPA\u002fqWP82raI7j\u002fDkNa4Hf8BQN802vhsm\u002fI\u002fS2s6t5377T\u002fjotKmcSDxPxBy9KtJUuY\u002fMXlcZ6\u002fV7D++6hfwNOf5PzdGopByDPU\u002fHBCyEgPa5D+Or5\u002fLs+rmP+sZ82q9xuU\u002fKpauDpa+9D97htYeFgXlPwNdI+1Fmeo\u002fzdf3b8gG3j9TspHmMhEAQPOfdGCqdv4\u002fkOjeVHmX1D\u002fpxtYQ1wLRvycT\u002fD\u002f91Oc\u002f"},"y":{"dtype":"f8","bdata":"SCBP6ExcBMD0HfFinYQGwHBJB69KJQLAikRV3MZwCMAiipbXBM0GwAFBc7ZReQXAyINEO0jTB8DcfE2DK6PUvyr1beIr\u002ftW\u002fuKiPw76SA8C0wqCQO0sGwPKvb4aY2wjAkOAsiNe6CsA8mPsgI\u002fyuP0u84B8PQgLAgv7CZMNwB8Dd6q8EQU\u002fdv2KLiQL4hQXAHX6ZaiWVCMCbywlVXJkGwFQLKcyfmQPAOHH8J\u002fhfBcDFh8Ayky4GwPpI6ocDrQfAOijzHMhoq7+EPJ6hHXkJwLKTQ5+i0fO\u002fVU3yrGB0B8BPp0IC+J4KwGJVW+1fCgnARIZ36KFHB8CH104cc6P8v0I0E3YX5v+\u002fIraefsB8A8Bw8A+sqVHlvxPqVQ1kygbA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"+gLOUxKx1z8="},"y":{"dtype":"f8","bdata":"3F\u002fTPy2O9r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"Qrq45os7A0BaVl55mx4AQKfNyg\u002fFAgNAIZ+ixb3bBECM\u002f4Btw2+6P6alIEw5AvM\u002fL\u002fGMVPFXAkCQHvLUawr8Pw=="},"y":{"dtype":"f8","bdata":"jFpgXjti2785adNpP5gAwKQJkSJsbeu\u002f5EV2WKy92L\u002fYRv+qlgkEwNQSOqleLO2\u002frtXARJvxs7\u002fI2xyZbcf9vw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2024","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"\u002fP6U1G18CUCgHvPhRQIGQN4OAZMMfAVA8590YKp2\u002fj+WMGA0uEYDQA=="},"y":{"dtype":"f8","bdata":"Hg7kTqZK\u002f7\u002fk6u6e4DTtv\u002fSsU9o\u002fc\u002fm\u002fQjQTdhfm\u002f79yNbubox7\u002fvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2024","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"U7KR5jIRAECqws0rWWkCQA=="},"y":{"dtype":"f8","bdata":"h9dOHHOj\u002fL8+RsnOFRTxvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"+4kHxE7hCEA="},"y":{"dtype":"f8","bdata":"aPE1E0XSpz8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2025","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2025","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"ZM4Z34pP0j\u002frluBFsgfAPzBGi+k4swJA8S2qazyV\u002fD\u002f7iQfETuEIQFIqPsgrJghAXD2YRGL7CkB9alXxqfgIQDiICafxlgZAwe7rMGs2B0AOiXuY37kJQClRwsDDwAJAQfrEUdYa\u002fD+7uwYWLBf2Pw=="},"y":{"dtype":"f8","bdata":"dxt2xNEE4L\u002fyVknIuPPgv562x5dbEug\u002frXT4u0TU8r9o8TUTRdKnP1EDx\u002fXI+uo\u002fMhVY64iH6T\u002f7gUXk9m7UP6pIl2CKaOk\u002f9ew8sCqG7D9fKFeOiOTwPwja2IjdL\u002fM\u002ffNaL++Nb+j\u002fBz5taguTivw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"384DF8QnBkBRJaDcb5UEQGoOQt5SrANA"},"y":{"dtype":"f8","bdata":"L0OmXs0K8z+DwzuOd+vyP+6mbjmK\u002fPc\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2025","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2025"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"7oLxE9\u002fx4D8+VEOI1KkGQClWseaVoAFAPcqs3T\u002f3+T9kP2OgfgUEQA=="},"y":{"dtype":"f8","bdata":"25UyQPuK4L9hxIuHpmf8PyjwoB1xkPw\u002fW83Sq4CRAECINDNNg6+TPw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2025"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"AlqLeg4w8z\u002fWDyKPNmnpPw=="},"y":{"dtype":"f8","bdata":"cskoS7bQyr\u002fAGB0Lke7APw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"EoIE8FM22j8NHa1egx3wPxZ2RZO6d9c\u002fu7sGFiwX9j8="},"y":{"dtype":"f8","bdata":"g0ZnoiOqCECEXckPoy8HQOOq3DOdZQhAwc+bWoLk4r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2025"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"u81a6oge0j+KPC4KqbvHv2r9E8vB39I\u002fMYZiraohxj9B+sRR1hr8Pw=="},"y":{"dtype":"f8","bdata":"fGhpML8VBkBcUmLoLHsKQC4BN\u002fvlNQpAYGNY83q\u002fBkB81ov741v6Pw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2025"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"qQYTXz3P3b8="},"y":{"dtype":"f8","bdata":"7TzjXxlBDUA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2025","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"F3j0p55l8r90P\u002fbc8Yr3v7+tMDIIqPq\u002fbmAQ1qLG9L\u002fwUQ0+GfLuv4UlttvWlfS\u002f3tT510yg9b+IKEtDEAv+v5IpJRCX4e2\u002fNN7A86I19L\u002f1KtFpNfbiv+Sq+B0XzADASkhFesuw9L9dpheP1mf3v97dLIUpZ\u002fG\u002f8k8ucxxg878FtC7OU+QAwJp5KDruVfC\u002fV4vItzp18r9RUiV7UnP1v\u002fGag0A+1\u002fe\u002fYk84Zkk89r\u002fVCV4naQEAwFfU7Qaelvu\u002fp+50SU7m97\u002frr7N55afzv89\u002f1ZR0OPO\u002fWEftOjtU+L8VWQaOYzvmv8SiDBFP7vu\u002fnDQvJgKq7r8="},"y":{"dtype":"f8","bdata":"Nx31P3L0CEBLjriCRsgJQHydjxcIqQRA78BPxWOtBUDO\u002fzb3ICwIQFMCONz+UgVAkCZF9jo2A0Bk9OO1Xg4FQN+OG32D5gRAG4\u002fJo7LnAkCHUyPo1nIGQDj6YZm6fvY\u002fGJn3tJHzCEA+Iq74rYQHQE76jFgSIgNAd0fl4jeyBEDZaVy6hO0FQC8RHmwhyAVAIwWBLhNPBEDfEnOgHjcIQARlNKVX\u002fwhAoybFXROHBECgUclwng0EQLyv2GO8ewZAR7CZn0J0AkBVZ4XxoFgEQEfdW6xFKQRAQont7x6kA0BaCEfX4U8IQGBNiKzOVwdAUIbMfDrHA0A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"qD\u002fMN+0qBsBPbH0XKnQDwO7uIc20hwbA"},"y":{"dtype":"f8","bdata":"vNll2UFj5z\u002fD1SXIvrrxPyT9iWPQMew\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2025"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"d5o9JtNJDcA="},"y":{"dtype":"f8","bdata":"gEaqzubZiT8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2025"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"5Kr4HRfMAMA="},"y":{"dtype":"f8","bdata":"OPphmbp+9j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2025","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2025"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"68a3T6jlBMCq6kxMUT7vvwU2Trdf3QTAZM4Z34pP0j\u002fFfTwVMuwIwIw\u002fwSWDdwfA1rsYs3cPA8Araltgp+IFwBSZ0lujT9c\u002f"},"y":{"dtype":"f8","bdata":"3QC14EyZ7r9uOfrH6lMCwFNqqc\u002flQPC\u002fdxt2xNEE4L\u002faqU+7\u002fnH2v\u002fj2UO7Xg\u002fW\u002fp9FcVCYq7b81RiGVYAXuv+OPWUrs2Oy\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2025","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2025","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2025"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"auG2nAEV4b+WB0QxRNn7v+uW4EWyB8A\u002f"},"y":{"dtype":"f8","bdata":"8Sp+ww6hAsBdCtmKRKoDwPJWSci48+C\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2025"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"7oLxE9\u002fx4D8="},"y":{"dtype":"f8","bdata":"25UyQPuK4L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2025","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2025","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"wQang4AWvD\u002fWDyKPNmnpP4mLlRKcqOi\u002fhiQqDjo2578q8B7fdBPuv2K9fLviWea\u002feFK5l5Rk8L8wes18yQ+iv8uSE8EA+eW\u002fAO0Czgw36L\u002fSjwKLF7bnvwz2i2zITOe\u002fhqmHU9mn3L9Ij+xS5hrOv0g7U9RJZuu\u002fzbvnE7qG3L+UmoIzC7jAvyRV+HH1Q+e\u002f3+LvQfeU3r+7uwYWLBf2Pw=="},"y":{"dtype":"f8","bdata":"thiDDQ8wBsDAGB0Lke7APw+f6Dr64gXARI9rsOKoCMBAybVf60QKwBFQV\u002flxWwXAhgaGZS58A8CzGBbm1j0KwHg7BbdkxwXAgqJae3zwCMAeBHWgQXcFwBrUS7QfyQTAK\u002fhnKdB1CMAGQ7eEjUsJwD5I5TIBGQnAdQcm8W7rBMA7NLUZVEkHwKFtSBqRngXA4865gpzYBsDBz5taguTivw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2025","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2025","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2025","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2025","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2025","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"qupMTFE+779q4bacARXhv8EGp4OAFrw\u002ffi35kJr98D8CWot6DjDzP1X8P5lHs\u002f8\u002f8S2qazyV\u002fD+RP1E2zVvrP\u002fpM9voOOug\u002f\u002fyBg0\u002fZV7T8R3jEj0u\u002fpP8XZzGIP9eU\u002f6o\u002faB56F2D9+KnV6mAHoPxFxyTYy9+U\u002f0jcLz\u002fhZ9T8Jx367fUv\u002fPyymoV2kmPM\u002fp7n\u002fQX1k6D87KnhXXQrnP0qUvm8+G\u002fE\u002fNV3prAUK8j9r9hR1FpLcPyUYQ0zLO\u002fk\u002fttCI+miG7j8N0EYlMFz8Pw=="},"y":{"dtype":"f8","bdata":"bjn6x+pTAsDxKn7DDqECwLYYgw0PMAbA9\u002fj8u59KCcByyShLttDKvySecUhJ5QHArXT4u0TU8r97SKy5W50KwJrtOFrz\u002fQfAO6\u002fFfqDKBcAnChMKfTkDwKktV8rN7wnAHBDXMlkuBsD2mPBTJ90BwKnVIIos+QXAf2csQUrAA8C5H3tLnQz\u002fv4y\u002fjo9\u002fLwXA3u+ST5TqB8AuGRKdqGAGwAtyzqllygbAg3w8y6h2CsC72P97HLkFwKt+YkFOT\u002fq\u002ff1FNwxklBsCAa0m\u002fszMIwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2025","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"xCMnWA9XAECilwv8MS8AQD0\u002f3FYRNgFAynAF79Do+T907UctEVEDQEyXVOQZRgRAuEC5CxBaA0BkP2OgfgUEQKg6aroG1gFAu7sGFiwX9j8="},"y":{"dtype":"f8","bdata":"nSehjsBzAsCpUCA2Lxb\u002fv88uOyFwBALAdacq6LwFAcASWtdcKTYEwISgWjeqCf2\u002fJS+EczV4\u002f7+INDNNg6+TP7bfcfnFFgLAwc+bWoLk4r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2025"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"Vfw\u002fmUez\u002fz8="},"y":{"dtype":"f8","bdata":"JJ5xSEnlAcA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2025","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value","showlegend":false,"visible":false,"x":{"dtype":"f8","bdata":"FzBL5HEtCECDaTho\u002fekHQHC94UNuBAVA0Sz9j5PWBUCenfDNaDIKQH0BOPhgqQNACcd+u31L\u002fz9xeGQSRigHQBSZ0lujT9c\u002fUIhHKyLnBkAWZ3tFF34IQCUYQ0zLO\u002fk\u002ffIXs4tSGBEA="},"y":{"dtype":"f8","bdata":"qoBhFTat47\u002fcf+og00ztvyOStN\u002fbT9y\u002f2oPxC4Jd5r+0TJF6lw3wvzAe8SpGeuK\u002fuR97S50M\u002f7\u002fkMxCEbTbdv+OPWUrs2Oy\u002fkZa\u002f1GnC4b9PM5oM9Gnnv6t+YkFOT\u002fq\u002fkWPoTbF5678="},"type":"scatter"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scattermap":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermap"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"font":{"size":16},"text":"Multi-label Clusters for each Year"},"xaxis":{"range":[-4.5,4.5],"title":{"text":""},"showgrid":true,"gridcolor":"lightgray"},"yaxis":{"range":[-4.5,4.5],"title":{"text":""},"showgrid":true,"gridcolor":"lightgray","scaleanchor":"x","scaleratio":1},"height":700,"width":900,"hovermode":"closest","sliders":[{"active":0,"currentvalue":{"prefix":"Year: ","visible":true,"xanchor":"center"},"len":0.9,"pad":{"b":10,"t":50},"steps":[{"args":[{"visible":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false]}],"label":"2022","method":"update"},{"args":[{"visible":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false]}],"label":"2023","method":"update"},{"args":[{"visible":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false]}],"label":"2024","method":"update"},{"args":[{"visible":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true]}],"label":"2025","method":"update"}],"x":0.0,"xanchor":"left","y":-0.1,"yanchor":"top"}],"showlegend":true},                        {"responsive": true}                    )                };            </script>        </div>
    <br>    
    <h2>All papers</h2>
    <div>                        <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.3.1.min.js" integrity="sha256-4rD3fugVb/nVJYUv5Ky3v+fYXoouHaBSP20WIJuEiWg=" crossorigin="anonymous"></script>                <div id="11c25b0d-4a36-45e7-aecb-59aeaa8d1ec9" class="plotly-graph-div" style="height:800px; width:1000px;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("11c25b0d-4a36-45e7-aecb-59aeaa8d1ec9")) {                    Plotly.newPlot(                        "11c25b0d-4a36-45e7-aecb-59aeaa8d1ec9",                        [{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2022","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2022","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2022","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2022","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2022","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2022","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2022","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2022","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2022","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2022","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2022","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2022","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2022"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias (19)","showlegend":true,"x":{"dtype":"f8","bdata":"+4kHxE7hCEBCurjmizsDQP\u002fTR4ZJXe0\u002fLD+I6qI19D8OBk\u002fgLsHsP8OQ1rgd\u002fwFA153\u002fr4Hf7D8hn6LFvdsEQC\u002fxjFTxVwJA6IKFBfKu8j+QHvLUawr8P3cugkLNw\u002fs\u002fiFwvtLV\u002fB0A64QyEi8jxP88T5b4PaAdAiLdCBr\u002fFAEB3ngB5Mn\u002fBP\u002foCzlMSsdc\u002fwM59PuEFB0A="},"y":{"dtype":"f8","bdata":"aPE1E0XSpz+MWmBeO2Lbv+jkCuTxcdG\u002fcQOSsAOo+r\u002fHbruRaubSv93qrwRBT92\u002fso2ADA9ozr\u002fkRXZYrL3Yv67VwESb8bO\u002fLeqBTQpo5r\u002fI2xyZbcf9v17DsXTZvfi\u002fWiUuLAhp8j9PUUgXvTLNP3sMetGQIcI\u002fypgczSFD9j+6Zds8lM30v9xf0z8tjva\u002fQRYLb+\u002fw7D8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2022","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2022","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2022","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2022","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2022","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2022","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2022","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2022","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2022","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2022","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2022","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2022","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2022","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2022","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2022"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural (30)","showlegend":true,"x":{"dtype":"f8","bdata":"ZM4Z34pP0j\u002frluBFsgfAPzBGi+k4swJA8S2qazyV\u002fD\u002f7iQfETuEIQFIqPsgrJghAXD2YRGL7CkB9alXxqfgIQBQMYMjS3QhA5qBaWdlVCEAhJ+Zw+IkFQBisM56joARAQrq45os7A0D\u002f00eGSV3tP95wCrU7oe0\u002fp83KD8UCA0DXnf+vgd\u002fsP88T5b4PaAdA6xnzar3G5T\u002fwtQ4whTV2v1wKL2rS1Mo\u002fOIgJp\u002fGWBkDB7uswazYHQA6Je5jfuQlAKVHCwMPAAkBB+sRR1hr8P7u7BhYsF\u002fY\u002fzSUvvFFqCECTJ5DvHfoHQCKoBWj6e6K\u002f"},"y":{"dtype":"f8","bdata":"dxt2xNEE4L\u002fyVknIuPPgv562x5dbEug\u002frXT4u0TU8r9o8TUTRdKnP1EDx\u002fXI+uo\u002fMhVY64iH6T\u002f7gUXk9m7UPySjDZtR3eQ\u002f2PqLHt\u002fr6D+VILB7UsPYP7Q+ggHkrec\u002fjFpgXjti27\u002fo5Ark8XHRv8xqTqLR9vO\u002fpAmRImxt67+yjYAMD2jOv3sMetGQIcI\u002fspNDn6LR87\u002fhoWrHg3jbv0lOSDiMju8\u002fqkiXYIpo6T\u002f17DywKobsP18oV46I5PA\u002fCNrYiN0v8z981ov741v6P8HPm1qC5OK\u002fYYSni6p64j\u002fgAfnyg2nfP3bZnNTUJuk\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2022","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2022","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2022"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture (3)","showlegend":true,"x":{"dtype":"f8","bdata":"384DF8QnBkBRJaDcb5UEQGoOQt5SrANA"},"y":{"dtype":"f8","bdata":"L0OmXs0K8z+DwzuOd+vyP+6mbjmK\u002fPc\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2022","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2022","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2022","Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2022","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2022","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2022","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2022","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2022","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2022","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2022"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics (14)","showlegend":true,"x":{"dtype":"f8","bdata":"7oLxE9\u002fx4D8+VEOI1KkGQClWseaVoAFAbVBLImXoBEAOBk\u002fgLsHsP8OQ1rgd\u002fwFAIZ+ixb3bBEAv8YxU8VcCQOiChQXyrvI\u002fsiwvxNYa+j+IXC+0tX8HQMDOfT7hBQdAPcqs3T\u002f3+T9kP2OgfgUEQA=="},"y":{"dtype":"f8","bdata":"25UyQPuK4L9hxIuHpmf8PyjwoB1xkPw\u002fdIEneZVZBEDHbruRaubSv93qrwRBT92\u002f5EV2WKy92L+u1cBEm\u002fGzvy3qgU0KaOa\u002f6W0d2hrc\u002fj9aJS4sCGnyP0EWC2\u002fv8Ow\u002fW83Sq4CRAECINDNNg6+TPw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2022","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2022","Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2022","Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2022","Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2022","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2022","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2022","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2022","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2022","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2022"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity (10)","showlegend":true,"x":{"dtype":"f8","bdata":"AlqLeg4w8z\u002fWDyKPNmnpP\u002fieVha+3gBAw+34TevN9z+yWh1JSMD1P6gwkCNJ3\u002fc\u002f8D5wFK10vD+yLC\u002fE1hr6P4i3Qga\u002fxQBAXAovatLUyj8="},"y":{"dtype":"f8","bdata":"cskoS7bQyr\u002fAGB0Lke7AP0j5vIhAcAFAIY7dqD0XAUBXVsKIU4YHQDyY+yAj\u002fK4\u002fTL+122+bzD\u002fpbR3aGtz+P8qYHM0hQ\u002fY\u002fSU5IOIyO7z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2022","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2022","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2022","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2022","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2022","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2022"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical (6)","showlegend":true,"x":{"dtype":"f8","bdata":"EoIE8FM22j8NHa1egx3wPxZ2RZO6d9c\u002fpqUgTDkC8z+7uwYWLBf2P5pAGrRXo+s\u002f"},"y":{"dtype":"f8","bdata":"g0ZnoiOqCECEXckPoy8HQOOq3DOdZQhA1BI6qV4s7b\u002fBz5taguTiv+jn9xpGBgJA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2022","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2022","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2022","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2022","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2022"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality (21)","showlegend":true,"x":{"dtype":"f8","bdata":"u81a6oge0j+KPC4KqbvHv575Hygtt9U\u002ffh8PFOQi4j\u002faZ1UNnTnmPyOlDGkDkuE\u002f52AnHTxouz8e\u002fPOjjzXOP6Ktd+bXDrA\u002fSDwGkrFCzT8cELISA9rkPzbcByi38N8\u002fOuEMhIvI8T+ImOTbE8nKPyP036FlAOQ\u002f1fI+UVeW2r\u002fpF0WzKL3hP2r9E8vB39I\u002fMYZiraohxj9B+sRR1hr8P72RscJghtI\u002f"},"y":{"dtype":"f8","bdata":"fGhpML8VBkBcUmLoLHsKQOpOaqDhdwxAKpLxIw+MBUAGUKwe8RwJQCr1beIr\u002ftW\u002f04JNISk0CEAPDp2BRLwHQDbfvjilPgtAqORSt8p5BEA6KPMcyGirvwO0mmdVZgpAT1FIF70yzT92tHboddYIQOCgntH4UwVAamwYE1S\u002fCUAMianhckAIQC4BN\u002fvlNQpAYGNY83q\u002fBkB81ov741v6P4w0IaMiFQdA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2022"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness (1)","showlegend":true,"x":{"dtype":"f8","bdata":"qQYTXz3P3b8="},"y":{"dtype":"f8","bdata":"7TzjXxlBDUA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2022","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2022","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2022"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general (69)","showlegend":true,"x":{"dtype":"f8","bdata":"F3j0p55l8r90P\u002fbc8Yr3v7+tMDIIqPq\u002fbmAQ1qLG9L\u002fwUQ0+GfLuv4UlttvWlfS\u002f3tT510yg9b+IKEtDEAv+v+ctbLGt7Pm\u002fUNCRI4Yg978Rtix4hmrxv9ml8gnEBPm\u002f3j9iA65B9L+bQWIzz+b2v0eUTuC+RfC\u002fbm98KD7n9b9emiBuBV\u002f4v1ZH12ll\u002f\u002fW\u002fs8ugdGdQ9r88lm6VHyvtv4ThX+9it\u002fW\u002fNWLUS\u002fo78r\u002fMCFO13vr9v\u002f7Ou5nQQvu\u002fqhjFeFmv+L9a67EvRmHzv76MJex3yva\u002fkgdW8Qfm878qoWFDMSz1v8pS8d8mee2\u002fgGodaqbJ+r\u002fXYFby+BvzvzDaI86Fb+6\u002fiSXw0LBC9b+5UiQDDiPwvxq0NNNoQPi\u002fEDRlzh5a+L\u002f4C7wcC7Lyv5unk0t4kPa\u002fEtYGq5MO+b80HPLduuDtv\u002fjVrnK94PG\u002fkiklEJfh7b803sDzojX0v\u002fUq0Wk19uK\u002f5Kr4HRfMAMBKSEV6y7D0v12mF4\u002fWZ\u002fe\u002f3t0shSln8b\u002fyTy5zHGDzvwW0Ls5T5ADAmnkoOu5V8L9Xi8i3OnXyv1FSJXtSc\u002fW\u002f8ZqDQD7X979iTzhmSTz2v9UJXidpAQDAV9TtBp6W+7+n7nRJTub3v+uvs3nlp\u002fO\u002fz3\u002fVlHQ4879YR+06O1T4vxVZBo5jO+a\u002fxKIMEU\u002fu+7+cNC8mAqruv1qM\u002f7vv+Pi\u002ficLxY+418b\u002fpxtYQ1wLRv7reZn64S\u002fS\u002f"},"y":{"dtype":"f8","bdata":"Nx31P3L0CEBLjriCRsgJQHydjxcIqQRA78BPxWOtBUDO\u002fzb3ICwIQFMCONz+UgVAkCZF9jo2A0Bk9OO1Xg4FQO4ZysSXUQVADiRkzkHGBUB1hTi9EegGQLqwLXiDWQhArgQjKuxvA0DNrWmzpCIEQJiQiO6LCQJA01WCEf9QB0BLV1Lap1EFQOJjkbkgwQdAH4FDHrh5CUAkg9Ny+4gFQPR2oe3mNApAZUL1NwJHBUDrNGhlUE0HQDP5hmPi7wRA1S4fJVy2BEDsJ3SaNAUFQIQB053k5wRAD8IM5TxnBEDEOfH43OYFQF5DXzUSMwZAsu\u002fpXKmJA0DNUCdNbwIKQLrtEu9s5wZAXTEuWdtlB0As8g5ycVYHQHIRJLWcKQRAQOUS0THBBUC\u002frntnulkDQLu\u002fo4HywwRA4bYCPSTSBUBZTbH8LjsDQNhLDf5BOgVA344bfYPmBEAbj8mjsucCQIdTI+jWcgZAOPphmbp+9j8Ymfe0kfMIQD4irvithAdATvqMWBIiA0B3R+XiN7IEQNlpXLqE7QVALxEebCHIBUAjBYEuE08EQN8Sc6AeNwhABGU0pVf\u002fCECjJsVdE4cEQKBRyXCeDQRAvK\u002fYY7x7BkBHsJmfQnQCQFVnhfGgWARAR91brEUpBEBCie3vHqQDQFoIR9fhTwhAYE2IrM5XB0BQhsx8OscDQK1\u002fAwTsXghAmvzgolMUA0Bw8A+sqVHlv1pQviPc9AVA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2022"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate (1)","showlegend":true,"x":{"dtype":"f8","bdata":"+oPkGL1l5r8="},"y":{"dtype":"f8","bdata":"3HxNgyuj1L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2022"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor (1)","showlegend":true,"x":{"dtype":"f8","bdata":"WOgGo6uxB8A="},"y":{"dtype":"f8","bdata":"uFBf\u002fgdR\u002fT8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2022","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2022","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2022","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2022"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language (4)","showlegend":true,"x":{"dtype":"f8","bdata":"qD\u002fMN+0qBsBPbH0XKnQDwO7uIc20hwbAIqgFaPp7or8="},"y":{"dtype":"f8","bdata":"vNll2UFj5z\u002fD1SXIvrrxPyT9iWPQMew\u002fdtmc1NQm6T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2022"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal (1)","showlegend":true,"x":{"dtype":"f8","bdata":"d5o9JtNJDcA="},"y":{"dtype":"f8","bdata":"gEaqzubZiT8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2022"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length (1)","showlegend":true,"x":{"dtype":"f8","bdata":"5Kr4HRfMAMA="},"y":{"dtype":"f8","bdata":"OPphmbp+9j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2022","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2022","Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2022","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2022","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2022","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2022","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2022","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2022","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2022"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral (20)","showlegend":true,"x":{"dtype":"f8","bdata":"68a3T6jlBMCq6kxMUT7vvwU2Trdf3QTAZM4Z34pP0j9PoxYdeqsGwBZ6u1PJ4QrA+grNw6wfC8D\u002f00eGSV3tP9ed\u002f6+B3+w\u002f8LUOMIU1dr93ngB5Mn\u002fBP1wKL2rS1Mo\u002f+gLOUxKx1z\u002fFfTwVMuwIwIw\u002fwSWDdwfA1rsYs3cPA8Araltgp+IFwBSZ0lujT9c\u002f9QMK1JwUCcDPqCvJSlYFwA=="},"y":{"dtype":"f8","bdata":"3QC14EyZ7r9uOfrH6lMCwFNqqc\u002flQPC\u002fdxt2xNEE4L\u002fYXIRHESP3vyh0pvXRMO6\u002fYi09sgBx6r\u002fo5Ark8XHRv7KNgAwPaM6\u002f4aFqx4N427+6Zds8lM30v0lOSDiMju8\u002f3F\u002fTPy2O9r\u002faqU+7\u002fnH2v\u002fj2UO7Xg\u002fW\u002fp9FcVCYq7b81RiGVYAXuv+OPWUrs2Oy\u002fOK0XcOgE6r9GGRNZrvbqvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2022","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2022","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2022","Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2022","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2022","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2022"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual (6)","showlegend":true,"x":{"dtype":"f8","bdata":"auG2nAEV4b+WB0QxRNn7v+uW4EWyB8A\u002fEx+WD4vwAsDrGfNqvcblPwvyZPhzgwbA"},"y":{"dtype":"f8","bdata":"8Sp+ww6hAsBdCtmKRKoDwPJWSci48+C\u002f8tYxZUX3+b+yk0OfotHzv4Kqrn3kvvi\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2022"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness (1)","showlegend":true,"x":{"dtype":"f8","bdata":"vQUUUkLA+L8="},"y":{"dtype":"f8","bdata":"KDHFwPwf\u002fL8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2022","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2022","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2022"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions (4)","showlegend":true,"x":{"dtype":"f8","bdata":"7oLxE9\u002fx4D8OBk\u002fgLsHsP4z\u002fgG3Db7o\u002f6IKFBfKu8j8="},"y":{"dtype":"f8","bdata":"25UyQPuK4L\u002fHbruRaubSv9hG\u002f6qWCQTALeqBTQpo5r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2022","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2022","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2022","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2022","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2022","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2022","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2022"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization (31)","showlegend":true,"x":{"dtype":"f8","bdata":"wQang4AWvD\u002fWDyKPNmnpP4mLlRKcqOi\u002ftIkjpA967r8wPNgIkufXv26Kg1gzMOy\u002f3nAKtTuh7T\u002f0ci7qMYvhv3AZkTewJbM\u002f8D5wFK10vD+mpSBMOQLzP6QHaa2Xw9a\u002fp84SKzH+6b+GJCoOOjbnvyrwHt90E+6\u002fYr18u+JZ5r94UrmXlGTwvzB6zXzJD6K\u002fy5ITwQD55b8A7QLODDfov9KPAosXtue\u002fDPaLbMhM57+GqYdT2afcv0iP7FLmGs6\u002fSDtT1Elm67\u002fNu+cTuobcv5SagjMLuMC\u002fJFX4cfVD57\u002ff4u9B95Tev7u7BhYsF\u002fY\u002f20FXd7UD4L8="},"y":{"dtype":"f8","bdata":"thiDDQ8wBsDAGB0Lke7APw+f6Dr64gXAl3t4xuMvCsAM\u002fvU3HLcIwGco6iziIAbAzGpOotH287\u002fEXC8kRvcFwGIDNWQAdAfATL+122+bzD\u002fUEjqpXiztv1pxrcK1bgjAG7I3vohKCcBEj2uw4qgIwEDJtV\u002frRArAEVBX+XFbBcCGBoZlLnwDwLMYFubWPQrAeDsFt2THBcCColp7fPAIwB4EdaBBdwXAGtRLtB\u002fJBMAr+Gcp0HUIwAZDt4SNSwnAPkjlMgEZCcB1BybxbusEwDs0tRlUSQfAoW1IGpGeBcDjzrmCnNgGwMHPm1qC5OK\u002fs+FCnR65C8A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2022","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2022","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2022","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2022","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2022","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2022"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political (6)","showlegend":true,"x":{"dtype":"f8","bdata":"LD+I6qI19D+QHvLUawr8P3cugkLNw\u002fs\u002fOuEMhIvI8T93ngB5Mn\u002fBPxurjxNpAOC\u002f"},"y":{"dtype":"f8","bdata":"cQOSsAOo+r\u002fI2xyZbcf9v17DsXTZvfi\u002fT1FIF70yzT+6Zds8lM30vwfr7yjlgQbA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2022","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2022","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2022","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2022","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2022","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2022","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2022","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2022","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2022","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2022","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2022","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2022","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2022","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2022","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2022","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2022","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2022","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2022"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety (62)","showlegend":true,"x":{"dtype":"f8","bdata":"qupMTFE+779q4bacARXhv8EGp4OAFrw\u002ffi35kJr98D8CWot6DjDzP1X8P5lHs\u002f8\u002f8S2qazyV\u002fD+RP1E2zVvrP\u002fpM9voOOug\u002fku4UjDl08D\u002f4yMQn8tPoPwOERLby3Oc\u002fGEewQAEa4D+vXNMyQY3rP8WIVHn+mvM\u002fzUuLhWFh6T\u002f6g+QYvWXmvyOlDGkDkuE\u002f\u002f2nKgQtg+T9ih93iz5f4P0J7Xlv2Auc\u002fLlQqbNdg8T+oMJAjSd\u002f3P7yCRBl\u002fPPA\u002fqWP82raI7j\u002fDkNa4Hf8BQN802vhsm\u002fI\u002fS2s6t5377T\u002fjotKmcSDxPxBy9KtJUuY\u002fMXlcZ6\u002fV7D++6hfwNOf5PzdGopByDPU\u002fHBCyEgPa5D+Or5\u002fLs+rmP+sZ82q9xuU\u002fKpauDpa+9D97htYeFgXlP\u002f8gYNP2Ve0\u002fEd4xI9Lv6T\u002fF2cxiD\u002fXlP+qP2geehdg\u002ffip1epgB6D8Rcck2MvflP9I3C8\u002f4WfU\u002fCcd+u31L\u002fz8spqFdpJjzP6e5\u002f0F9ZOg\u002fOyp4V10K5z9KlL5vPhvxPzVd6awFCvI\u002fa\u002fYUdRaS3D8lGENMyzv5P7bQiPpohu4\u002fDdBGJTBc\u002fD8DXSPtRZnqP83X92\u002fIBt4\u002fU7KR5jIRAEDzn3Rgqnb+P5Do3lR5l9Q\u002f6cbWENcC0b8nE\u002fw\u002f\u002fdTnPw=="},"y":{"dtype":"f8","bdata":"bjn6x+pTAsDxKn7DDqECwLYYgw0PMAbA9\u002fj8u59KCcByyShLttDKvySecUhJ5QHArXT4u0TU8r97SKy5W50KwJrtOFrz\u002fQfASCBP6ExcBMD0HfFinYQGwHBJB69KJQLAikRV3MZwCMAiipbXBM0GwAFBc7ZReQXAyINEO0jTB8DcfE2DK6PUvyr1beIr\u002ftW\u002fuKiPw76SA8C0wqCQO0sGwPKvb4aY2wjAkOAsiNe6CsA8mPsgI\u002fyuP0u84B8PQgLAgv7CZMNwB8Dd6q8EQU\u002fdv2KLiQL4hQXAHX6ZaiWVCMCbywlVXJkGwFQLKcyfmQPAOHH8J\u002fhfBcDFh8Ayky4GwPpI6ocDrQfAOijzHMhoq7+EPJ6hHXkJwLKTQ5+i0fO\u002fVU3yrGB0B8BPp0IC+J4KwDuvxX6gygXAJwoTCn05A8CpLVfKze8JwBwQ1zJZLgbA9pjwUyfdAcCp1SCKLPkFwH9nLEFKwAPAuR97S50M\u002f7+Mv46Pfy8FwN7vkk+U6gfALhkSnahgBsALcs6pZcoGwIN8PMuodgrAu9j\u002fexy5BcCrfmJBTk\u002f6v39RTcMZJQbAgGtJv7MzCMBiVVvtXwoJwESGd+ihRwfAh9dOHHOj\u002fL9CNBN2F+b\u002fvyK2nn7AfAPAcPAPrKlR5b8T6lUNZMoGwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2022"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism (1)","showlegend":true,"x":{"dtype":"f8","bdata":"+gLOUxKx1z8="},"y":{"dtype":"f8","bdata":"3F\u002fTPy2O9r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2022","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2022","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2022","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2022","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2022","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2022","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2022","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2022","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2022"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social (18)","showlegend":true,"x":{"dtype":"f8","bdata":"xCMnWA9XAECilwv8MS8AQD0\u002f3FYRNgFAynAF79Do+T907UctEVEDQEK6uOaLOwNAWlZeeZseAECnzcoPxQIDQCGfosW92wRAjP+AbcNvuj+mpSBMOQLzPy\u002fxjFTxVwJAkB7y1GsK\u002fD9Ml1TkGUYEQLhAuQsQWgNAZD9joH4FBECoOmq6BtYBQLu7BhYsF\u002fY\u002f"},"y":{"dtype":"f8","bdata":"nSehjsBzAsCpUCA2Lxb\u002fv88uOyFwBALAdacq6LwFAcASWtdcKTYEwIxaYF47Ytu\u002fOWnTaT+YAMCkCZEibG3rv+RFdlisvdi\u002f2Eb\u002fqpYJBMDUEjqpXiztv67VwESb8bO\u002fyNscmW3H\u002fb+EoFo3qgn9vyUvhHM1eP+\u002fiDQzTYOvkz+233H5xRYCwMHPm1qC5OK\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2022","Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2022","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2022","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2022","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2022","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2022"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity (6)","showlegend":true,"x":{"dtype":"f8","bdata":"Vfw\u002fmUez\u002fz\u002f8\u002fpTUbXwJQKAe8+FFAgZA3g4Bkwx8BUDzn3Rgqnb+P5YwYDS4RgNA"},"y":{"dtype":"f8","bdata":"JJ5xSEnlAcAeDuROpkr\u002fv+Tq7p7gNO2\u002f9KxT2j9z+b9CNBN2F+b\u002fv3I1u5ujHv+\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2022","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2022","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2022","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2022","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2022"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value (15)","showlegend":true,"x":{"dtype":"f8","bdata":"FzBL5HEtCECDaTho\u002fekHQHC94UNuBAVA0Sz9j5PWBUCenfDNaDIKQH0BOPhgqQNACcd+u31L\u002fz9xeGQSRigHQBSZ0lujT9c\u002fUIhHKyLnBkAWZ3tFF34IQCUYQ0zLO\u002fk\u002ffIXs4tSGBEBTspHmMhEAQKrCzStZaQJA"},"y":{"dtype":"f8","bdata":"qoBhFTat47\u002fcf+og00ztvyOStN\u002fbT9y\u002f2oPxC4Jd5r+0TJF6lw3wvzAe8SpGeuK\u002fuR97S50M\u002f7\u002fkMxCEbTbdv+OPWUrs2Oy\u002fkZa\u002f1GnC4b9PM5oM9Gnnv6t+YkFOT\u002fq\u002fkWPoTbF567+H104cc6P8vz5Gyc4VFPG\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2023","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2023","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2023","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2023","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2023","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2023","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2023","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2023","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2023","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2023","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2023","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2023"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias (19)","showlegend":false,"x":{"dtype":"f8","bdata":"+4kHxE7hCEBCurjmizsDQP\u002fTR4ZJXe0\u002fLD+I6qI19D8OBk\u002fgLsHsP8OQ1rgd\u002fwFA153\u002fr4Hf7D8hn6LFvdsEQC\u002fxjFTxVwJA6IKFBfKu8j+QHvLUawr8P3cugkLNw\u002fs\u002fiFwvtLV\u002fB0A64QyEi8jxP88T5b4PaAdAiLdCBr\u002fFAEB3ngB5Mn\u002fBP\u002foCzlMSsdc\u002fwM59PuEFB0A="},"y":{"dtype":"f8","bdata":"aPE1E0XSpz+MWmBeO2Lbv+jkCuTxcdG\u002fcQOSsAOo+r\u002fHbruRaubSv93qrwRBT92\u002fso2ADA9ozr\u002fkRXZYrL3Yv67VwESb8bO\u002fLeqBTQpo5r\u002fI2xyZbcf9v17DsXTZvfi\u002fWiUuLAhp8j9PUUgXvTLNP3sMetGQIcI\u002fypgczSFD9j+6Zds8lM30v9xf0z8tjva\u002fQRYLb+\u002fw7D8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2023","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2023","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2023","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2023","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2023","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2023","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2023","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2023","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2023","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2023","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2023","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2023","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2023","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2023"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural (30)","showlegend":false,"x":{"dtype":"f8","bdata":"ZM4Z34pP0j\u002frluBFsgfAPzBGi+k4swJA8S2qazyV\u002fD\u002f7iQfETuEIQFIqPsgrJghAXD2YRGL7CkB9alXxqfgIQBQMYMjS3QhA5qBaWdlVCEAhJ+Zw+IkFQBisM56joARAQrq45os7A0D\u002f00eGSV3tP95wCrU7oe0\u002fp83KD8UCA0DXnf+vgd\u002fsP88T5b4PaAdA6xnzar3G5T\u002fwtQ4whTV2v1wKL2rS1Mo\u002fOIgJp\u002fGWBkDB7uswazYHQA6Je5jfuQlAKVHCwMPAAkBB+sRR1hr8P7u7BhYsF\u002fY\u002fzSUvvFFqCECTJ5DvHfoHQCKoBWj6e6K\u002f"},"y":{"dtype":"f8","bdata":"dxt2xNEE4L\u002fyVknIuPPgv562x5dbEug\u002frXT4u0TU8r9o8TUTRdKnP1EDx\u002fXI+uo\u002fMhVY64iH6T\u002f7gUXk9m7UPySjDZtR3eQ\u002f2PqLHt\u002fr6D+VILB7UsPYP7Q+ggHkrec\u002fjFpgXjti27\u002fo5Ark8XHRv8xqTqLR9vO\u002fpAmRImxt67+yjYAMD2jOv3sMetGQIcI\u002fspNDn6LR87\u002fhoWrHg3jbv0lOSDiMju8\u002fqkiXYIpo6T\u002f17DywKobsP18oV46I5PA\u002fCNrYiN0v8z981ov741v6P8HPm1qC5OK\u002fYYSni6p64j\u002fgAfnyg2nfP3bZnNTUJuk\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2023","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2023","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2023"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture (3)","showlegend":false,"x":{"dtype":"f8","bdata":"384DF8QnBkBRJaDcb5UEQGoOQt5SrANA"},"y":{"dtype":"f8","bdata":"L0OmXs0K8z+DwzuOd+vyP+6mbjmK\u002fPc\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2023","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2023","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2023","Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2023","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2023","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2023","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2023","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2023","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2023","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2023"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics (14)","showlegend":false,"x":{"dtype":"f8","bdata":"7oLxE9\u002fx4D8+VEOI1KkGQClWseaVoAFAbVBLImXoBEAOBk\u002fgLsHsP8OQ1rgd\u002fwFAIZ+ixb3bBEAv8YxU8VcCQOiChQXyrvI\u002fsiwvxNYa+j+IXC+0tX8HQMDOfT7hBQdAPcqs3T\u002f3+T9kP2OgfgUEQA=="},"y":{"dtype":"f8","bdata":"25UyQPuK4L9hxIuHpmf8PyjwoB1xkPw\u002fdIEneZVZBEDHbruRaubSv93qrwRBT92\u002f5EV2WKy92L+u1cBEm\u002fGzvy3qgU0KaOa\u002f6W0d2hrc\u002fj9aJS4sCGnyP0EWC2\u002fv8Ow\u002fW83Sq4CRAECINDNNg6+TPw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2023","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2023","Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2023","Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2023","Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2023","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2023","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2023","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2023","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2023","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2023"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity (10)","showlegend":false,"x":{"dtype":"f8","bdata":"AlqLeg4w8z\u002fWDyKPNmnpP\u002fieVha+3gBAw+34TevN9z+yWh1JSMD1P6gwkCNJ3\u002fc\u002f8D5wFK10vD+yLC\u002fE1hr6P4i3Qga\u002fxQBAXAovatLUyj8="},"y":{"dtype":"f8","bdata":"cskoS7bQyr\u002fAGB0Lke7AP0j5vIhAcAFAIY7dqD0XAUBXVsKIU4YHQDyY+yAj\u002fK4\u002fTL+122+bzD\u002fpbR3aGtz+P8qYHM0hQ\u002fY\u002fSU5IOIyO7z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2023","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2023","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2023","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2023","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2023","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2023"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical (6)","showlegend":false,"x":{"dtype":"f8","bdata":"EoIE8FM22j8NHa1egx3wPxZ2RZO6d9c\u002fpqUgTDkC8z+7uwYWLBf2P5pAGrRXo+s\u002f"},"y":{"dtype":"f8","bdata":"g0ZnoiOqCECEXckPoy8HQOOq3DOdZQhA1BI6qV4s7b\u002fBz5taguTiv+jn9xpGBgJA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2023","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2023","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2023","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2023","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2023"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality (21)","showlegend":false,"x":{"dtype":"f8","bdata":"u81a6oge0j+KPC4KqbvHv575Hygtt9U\u002ffh8PFOQi4j\u002faZ1UNnTnmPyOlDGkDkuE\u002f52AnHTxouz8e\u002fPOjjzXOP6Ktd+bXDrA\u002fSDwGkrFCzT8cELISA9rkPzbcByi38N8\u002fOuEMhIvI8T+ImOTbE8nKPyP036FlAOQ\u002f1fI+UVeW2r\u002fpF0WzKL3hP2r9E8vB39I\u002fMYZiraohxj9B+sRR1hr8P72RscJghtI\u002f"},"y":{"dtype":"f8","bdata":"fGhpML8VBkBcUmLoLHsKQOpOaqDhdwxAKpLxIw+MBUAGUKwe8RwJQCr1beIr\u002ftW\u002f04JNISk0CEAPDp2BRLwHQDbfvjilPgtAqORSt8p5BEA6KPMcyGirvwO0mmdVZgpAT1FIF70yzT92tHboddYIQOCgntH4UwVAamwYE1S\u002fCUAMianhckAIQC4BN\u002fvlNQpAYGNY83q\u002fBkB81ov741v6P4w0IaMiFQdA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2023"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"qQYTXz3P3b8="},"y":{"dtype":"f8","bdata":"7TzjXxlBDUA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2023","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2023","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2023"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general (69)","showlegend":false,"x":{"dtype":"f8","bdata":"F3j0p55l8r90P\u002fbc8Yr3v7+tMDIIqPq\u002fbmAQ1qLG9L\u002fwUQ0+GfLuv4UlttvWlfS\u002f3tT510yg9b+IKEtDEAv+v+ctbLGt7Pm\u002fUNCRI4Yg978Rtix4hmrxv9ml8gnEBPm\u002f3j9iA65B9L+bQWIzz+b2v0eUTuC+RfC\u002fbm98KD7n9b9emiBuBV\u002f4v1ZH12ll\u002f\u002fW\u002fs8ugdGdQ9r88lm6VHyvtv4ThX+9it\u002fW\u002fNWLUS\u002fo78r\u002fMCFO13vr9v\u002f7Ou5nQQvu\u002fqhjFeFmv+L9a67EvRmHzv76MJex3yva\u002fkgdW8Qfm878qoWFDMSz1v8pS8d8mee2\u002fgGodaqbJ+r\u002fXYFby+BvzvzDaI86Fb+6\u002fiSXw0LBC9b+5UiQDDiPwvxq0NNNoQPi\u002fEDRlzh5a+L\u002f4C7wcC7Lyv5unk0t4kPa\u002fEtYGq5MO+b80HPLduuDtv\u002fjVrnK94PG\u002fkiklEJfh7b803sDzojX0v\u002fUq0Wk19uK\u002f5Kr4HRfMAMBKSEV6y7D0v12mF4\u002fWZ\u002fe\u002f3t0shSln8b\u002fyTy5zHGDzvwW0Ls5T5ADAmnkoOu5V8L9Xi8i3OnXyv1FSJXtSc\u002fW\u002f8ZqDQD7X979iTzhmSTz2v9UJXidpAQDAV9TtBp6W+7+n7nRJTub3v+uvs3nlp\u002fO\u002fz3\u002fVlHQ4879YR+06O1T4vxVZBo5jO+a\u002fxKIMEU\u002fu+7+cNC8mAqruv1qM\u002f7vv+Pi\u002ficLxY+418b\u002fpxtYQ1wLRv7reZn64S\u002fS\u002f"},"y":{"dtype":"f8","bdata":"Nx31P3L0CEBLjriCRsgJQHydjxcIqQRA78BPxWOtBUDO\u002fzb3ICwIQFMCONz+UgVAkCZF9jo2A0Bk9OO1Xg4FQO4ZysSXUQVADiRkzkHGBUB1hTi9EegGQLqwLXiDWQhArgQjKuxvA0DNrWmzpCIEQJiQiO6LCQJA01WCEf9QB0BLV1Lap1EFQOJjkbkgwQdAH4FDHrh5CUAkg9Ny+4gFQPR2oe3mNApAZUL1NwJHBUDrNGhlUE0HQDP5hmPi7wRA1S4fJVy2BEDsJ3SaNAUFQIQB053k5wRAD8IM5TxnBEDEOfH43OYFQF5DXzUSMwZAsu\u002fpXKmJA0DNUCdNbwIKQLrtEu9s5wZAXTEuWdtlB0As8g5ycVYHQHIRJLWcKQRAQOUS0THBBUC\u002frntnulkDQLu\u002fo4HywwRA4bYCPSTSBUBZTbH8LjsDQNhLDf5BOgVA344bfYPmBEAbj8mjsucCQIdTI+jWcgZAOPphmbp+9j8Ymfe0kfMIQD4irvithAdATvqMWBIiA0B3R+XiN7IEQNlpXLqE7QVALxEebCHIBUAjBYEuE08EQN8Sc6AeNwhABGU0pVf\u002fCECjJsVdE4cEQKBRyXCeDQRAvK\u002fYY7x7BkBHsJmfQnQCQFVnhfGgWARAR91brEUpBEBCie3vHqQDQFoIR9fhTwhAYE2IrM5XB0BQhsx8OscDQK1\u002fAwTsXghAmvzgolMUA0Bw8A+sqVHlv1pQviPc9AVA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2023"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate (1)","showlegend":false,"x":{"dtype":"f8","bdata":"+oPkGL1l5r8="},"y":{"dtype":"f8","bdata":"3HxNgyuj1L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2023"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor (1)","showlegend":false,"x":{"dtype":"f8","bdata":"WOgGo6uxB8A="},"y":{"dtype":"f8","bdata":"uFBf\u002fgdR\u002fT8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2023","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2023","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2023","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2023"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language (4)","showlegend":false,"x":{"dtype":"f8","bdata":"qD\u002fMN+0qBsBPbH0XKnQDwO7uIc20hwbAIqgFaPp7or8="},"y":{"dtype":"f8","bdata":"vNll2UFj5z\u002fD1SXIvrrxPyT9iWPQMew\u002fdtmc1NQm6T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2023"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal (1)","showlegend":false,"x":{"dtype":"f8","bdata":"d5o9JtNJDcA="},"y":{"dtype":"f8","bdata":"gEaqzubZiT8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2023"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length (1)","showlegend":false,"x":{"dtype":"f8","bdata":"5Kr4HRfMAMA="},"y":{"dtype":"f8","bdata":"OPphmbp+9j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2023","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2023","Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2023","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2023","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2023","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2023","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2023","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2023","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2023"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral (20)","showlegend":false,"x":{"dtype":"f8","bdata":"68a3T6jlBMCq6kxMUT7vvwU2Trdf3QTAZM4Z34pP0j9PoxYdeqsGwBZ6u1PJ4QrA+grNw6wfC8D\u002f00eGSV3tP9ed\u002f6+B3+w\u002f8LUOMIU1dr93ngB5Mn\u002fBP1wKL2rS1Mo\u002f+gLOUxKx1z\u002fFfTwVMuwIwIw\u002fwSWDdwfA1rsYs3cPA8Araltgp+IFwBSZ0lujT9c\u002f9QMK1JwUCcDPqCvJSlYFwA=="},"y":{"dtype":"f8","bdata":"3QC14EyZ7r9uOfrH6lMCwFNqqc\u002flQPC\u002fdxt2xNEE4L\u002fYXIRHESP3vyh0pvXRMO6\u002fYi09sgBx6r\u002fo5Ark8XHRv7KNgAwPaM6\u002f4aFqx4N427+6Zds8lM30v0lOSDiMju8\u002f3F\u002fTPy2O9r\u002faqU+7\u002fnH2v\u002fj2UO7Xg\u002fW\u002fp9FcVCYq7b81RiGVYAXuv+OPWUrs2Oy\u002fOK0XcOgE6r9GGRNZrvbqvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2023","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2023","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2023","Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2023","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2023","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2023"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual (6)","showlegend":false,"x":{"dtype":"f8","bdata":"auG2nAEV4b+WB0QxRNn7v+uW4EWyB8A\u002fEx+WD4vwAsDrGfNqvcblPwvyZPhzgwbA"},"y":{"dtype":"f8","bdata":"8Sp+ww6hAsBdCtmKRKoDwPJWSci48+C\u002f8tYxZUX3+b+yk0OfotHzv4Kqrn3kvvi\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2023"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"vQUUUkLA+L8="},"y":{"dtype":"f8","bdata":"KDHFwPwf\u002fL8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2023","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2023","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2023"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions (4)","showlegend":false,"x":{"dtype":"f8","bdata":"7oLxE9\u002fx4D8OBk\u002fgLsHsP4z\u002fgG3Db7o\u002f6IKFBfKu8j8="},"y":{"dtype":"f8","bdata":"25UyQPuK4L\u002fHbruRaubSv9hG\u002f6qWCQTALeqBTQpo5r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2023","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2023","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2023","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2023","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2023","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2023","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2023"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization (31)","showlegend":false,"x":{"dtype":"f8","bdata":"wQang4AWvD\u002fWDyKPNmnpP4mLlRKcqOi\u002ftIkjpA967r8wPNgIkufXv26Kg1gzMOy\u002f3nAKtTuh7T\u002f0ci7qMYvhv3AZkTewJbM\u002f8D5wFK10vD+mpSBMOQLzP6QHaa2Xw9a\u002fp84SKzH+6b+GJCoOOjbnvyrwHt90E+6\u002fYr18u+JZ5r94UrmXlGTwvzB6zXzJD6K\u002fy5ITwQD55b8A7QLODDfov9KPAosXtue\u002fDPaLbMhM57+GqYdT2afcv0iP7FLmGs6\u002fSDtT1Elm67\u002fNu+cTuobcv5SagjMLuMC\u002fJFX4cfVD57\u002ff4u9B95Tev7u7BhYsF\u002fY\u002f20FXd7UD4L8="},"y":{"dtype":"f8","bdata":"thiDDQ8wBsDAGB0Lke7APw+f6Dr64gXAl3t4xuMvCsAM\u002fvU3HLcIwGco6iziIAbAzGpOotH287\u002fEXC8kRvcFwGIDNWQAdAfATL+122+bzD\u002fUEjqpXiztv1pxrcK1bgjAG7I3vohKCcBEj2uw4qgIwEDJtV\u002frRArAEVBX+XFbBcCGBoZlLnwDwLMYFubWPQrAeDsFt2THBcCColp7fPAIwB4EdaBBdwXAGtRLtB\u002fJBMAr+Gcp0HUIwAZDt4SNSwnAPkjlMgEZCcB1BybxbusEwDs0tRlUSQfAoW1IGpGeBcDjzrmCnNgGwMHPm1qC5OK\u002fs+FCnR65C8A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2023","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2023","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2023","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2023","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2023","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2023"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political (6)","showlegend":false,"x":{"dtype":"f8","bdata":"LD+I6qI19D+QHvLUawr8P3cugkLNw\u002fs\u002fOuEMhIvI8T93ngB5Mn\u002fBPxurjxNpAOC\u002f"},"y":{"dtype":"f8","bdata":"cQOSsAOo+r\u002fI2xyZbcf9v17DsXTZvfi\u002fT1FIF70yzT+6Zds8lM30vwfr7yjlgQbA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2023","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2023","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2023","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2023","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2023","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2023","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2023","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2023","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2023","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2023","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2023","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2023","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2023","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2023","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2023","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2023","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2023","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2023"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety (62)","showlegend":false,"x":{"dtype":"f8","bdata":"qupMTFE+779q4bacARXhv8EGp4OAFrw\u002ffi35kJr98D8CWot6DjDzP1X8P5lHs\u002f8\u002f8S2qazyV\u002fD+RP1E2zVvrP\u002fpM9voOOug\u002fku4UjDl08D\u002f4yMQn8tPoPwOERLby3Oc\u002fGEewQAEa4D+vXNMyQY3rP8WIVHn+mvM\u002fzUuLhWFh6T\u002f6g+QYvWXmvyOlDGkDkuE\u002f\u002f2nKgQtg+T9ih93iz5f4P0J7Xlv2Auc\u002fLlQqbNdg8T+oMJAjSd\u002f3P7yCRBl\u002fPPA\u002fqWP82raI7j\u002fDkNa4Hf8BQN802vhsm\u002fI\u002fS2s6t5377T\u002fjotKmcSDxPxBy9KtJUuY\u002fMXlcZ6\u002fV7D++6hfwNOf5PzdGopByDPU\u002fHBCyEgPa5D+Or5\u002fLs+rmP+sZ82q9xuU\u002fKpauDpa+9D97htYeFgXlP\u002f8gYNP2Ve0\u002fEd4xI9Lv6T\u002fF2cxiD\u002fXlP+qP2geehdg\u002ffip1epgB6D8Rcck2MvflP9I3C8\u002f4WfU\u002fCcd+u31L\u002fz8spqFdpJjzP6e5\u002f0F9ZOg\u002fOyp4V10K5z9KlL5vPhvxPzVd6awFCvI\u002fa\u002fYUdRaS3D8lGENMyzv5P7bQiPpohu4\u002fDdBGJTBc\u002fD8DXSPtRZnqP83X92\u002fIBt4\u002fU7KR5jIRAEDzn3Rgqnb+P5Do3lR5l9Q\u002f6cbWENcC0b8nE\u002fw\u002f\u002fdTnPw=="},"y":{"dtype":"f8","bdata":"bjn6x+pTAsDxKn7DDqECwLYYgw0PMAbA9\u002fj8u59KCcByyShLttDKvySecUhJ5QHArXT4u0TU8r97SKy5W50KwJrtOFrz\u002fQfASCBP6ExcBMD0HfFinYQGwHBJB69KJQLAikRV3MZwCMAiipbXBM0GwAFBc7ZReQXAyINEO0jTB8DcfE2DK6PUvyr1beIr\u002ftW\u002fuKiPw76SA8C0wqCQO0sGwPKvb4aY2wjAkOAsiNe6CsA8mPsgI\u002fyuP0u84B8PQgLAgv7CZMNwB8Dd6q8EQU\u002fdv2KLiQL4hQXAHX6ZaiWVCMCbywlVXJkGwFQLKcyfmQPAOHH8J\u002fhfBcDFh8Ayky4GwPpI6ocDrQfAOijzHMhoq7+EPJ6hHXkJwLKTQ5+i0fO\u002fVU3yrGB0B8BPp0IC+J4KwDuvxX6gygXAJwoTCn05A8CpLVfKze8JwBwQ1zJZLgbA9pjwUyfdAcCp1SCKLPkFwH9nLEFKwAPAuR97S50M\u002f7+Mv46Pfy8FwN7vkk+U6gfALhkSnahgBsALcs6pZcoGwIN8PMuodgrAu9j\u002fexy5BcCrfmJBTk\u002f6v39RTcMZJQbAgGtJv7MzCMBiVVvtXwoJwESGd+ihRwfAh9dOHHOj\u002fL9CNBN2F+b\u002fvyK2nn7AfAPAcPAPrKlR5b8T6lUNZMoGwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2023"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism (1)","showlegend":false,"x":{"dtype":"f8","bdata":"+gLOUxKx1z8="},"y":{"dtype":"f8","bdata":"3F\u002fTPy2O9r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2023","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2023","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2023","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2023","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2023","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2023","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2023","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2023","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2023"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social (18)","showlegend":false,"x":{"dtype":"f8","bdata":"xCMnWA9XAECilwv8MS8AQD0\u002f3FYRNgFAynAF79Do+T907UctEVEDQEK6uOaLOwNAWlZeeZseAECnzcoPxQIDQCGfosW92wRAjP+AbcNvuj+mpSBMOQLzPy\u002fxjFTxVwJAkB7y1GsK\u002fD9Ml1TkGUYEQLhAuQsQWgNAZD9joH4FBECoOmq6BtYBQLu7BhYsF\u002fY\u002f"},"y":{"dtype":"f8","bdata":"nSehjsBzAsCpUCA2Lxb\u002fv88uOyFwBALAdacq6LwFAcASWtdcKTYEwIxaYF47Ytu\u002fOWnTaT+YAMCkCZEibG3rv+RFdlisvdi\u002f2Eb\u002fqpYJBMDUEjqpXiztv67VwESb8bO\u002fyNscmW3H\u002fb+EoFo3qgn9vyUvhHM1eP+\u002fiDQzTYOvkz+233H5xRYCwMHPm1qC5OK\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2023","Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2023","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2023","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2023","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2023","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2023"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity (6)","showlegend":false,"x":{"dtype":"f8","bdata":"Vfw\u002fmUez\u002fz\u002f8\u002fpTUbXwJQKAe8+FFAgZA3g4Bkwx8BUDzn3Rgqnb+P5YwYDS4RgNA"},"y":{"dtype":"f8","bdata":"JJ5xSEnlAcAeDuROpkr\u002fv+Tq7p7gNO2\u002f9KxT2j9z+b9CNBN2F+b\u002fv3I1u5ujHv+\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2023","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2023","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2023","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2023","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2023"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value (15)","showlegend":false,"x":{"dtype":"f8","bdata":"FzBL5HEtCECDaTho\u002fekHQHC94UNuBAVA0Sz9j5PWBUCenfDNaDIKQH0BOPhgqQNACcd+u31L\u002fz9xeGQSRigHQBSZ0lujT9c\u002fUIhHKyLnBkAWZ3tFF34IQCUYQ0zLO\u002fk\u002ffIXs4tSGBEBTspHmMhEAQKrCzStZaQJA"},"y":{"dtype":"f8","bdata":"qoBhFTat47\u002fcf+og00ztvyOStN\u002fbT9y\u002f2oPxC4Jd5r+0TJF6lw3wvzAe8SpGeuK\u002fuR97S50M\u002f7\u002fkMxCEbTbdv+OPWUrs2Oy\u002fkZa\u002f1GnC4b9PM5oM9Gnnv6t+YkFOT\u002fq\u002fkWPoTbF567+H104cc6P8vz5Gyc4VFPG\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias (19)","showlegend":false,"x":{"dtype":"f8","bdata":"+4kHxE7hCEBCurjmizsDQP\u002fTR4ZJXe0\u002fLD+I6qI19D8OBk\u002fgLsHsP8OQ1rgd\u002fwFA153\u002fr4Hf7D8hn6LFvdsEQC\u002fxjFTxVwJA6IKFBfKu8j+QHvLUawr8P3cugkLNw\u002fs\u002fiFwvtLV\u002fB0A64QyEi8jxP88T5b4PaAdAiLdCBr\u002fFAEB3ngB5Mn\u002fBP\u002foCzlMSsdc\u002fwM59PuEFB0A="},"y":{"dtype":"f8","bdata":"aPE1E0XSpz+MWmBeO2Lbv+jkCuTxcdG\u002fcQOSsAOo+r\u002fHbruRaubSv93qrwRBT92\u002fso2ADA9ozr\u002fkRXZYrL3Yv67VwESb8bO\u002fLeqBTQpo5r\u002fI2xyZbcf9v17DsXTZvfi\u002fWiUuLAhp8j9PUUgXvTLNP3sMetGQIcI\u002fypgczSFD9j+6Zds8lM30v9xf0z8tjva\u002fQRYLb+\u002fw7D8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2024","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2024","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2024","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2024","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2024","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2024"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural (30)","showlegend":false,"x":{"dtype":"f8","bdata":"ZM4Z34pP0j\u002frluBFsgfAPzBGi+k4swJA8S2qazyV\u002fD\u002f7iQfETuEIQFIqPsgrJghAXD2YRGL7CkB9alXxqfgIQBQMYMjS3QhA5qBaWdlVCEAhJ+Zw+IkFQBisM56joARAQrq45os7A0D\u002f00eGSV3tP95wCrU7oe0\u002fp83KD8UCA0DXnf+vgd\u002fsP88T5b4PaAdA6xnzar3G5T\u002fwtQ4whTV2v1wKL2rS1Mo\u002fOIgJp\u002fGWBkDB7uswazYHQA6Je5jfuQlAKVHCwMPAAkBB+sRR1hr8P7u7BhYsF\u002fY\u002fzSUvvFFqCECTJ5DvHfoHQCKoBWj6e6K\u002f"},"y":{"dtype":"f8","bdata":"dxt2xNEE4L\u002fyVknIuPPgv562x5dbEug\u002frXT4u0TU8r9o8TUTRdKnP1EDx\u002fXI+uo\u002fMhVY64iH6T\u002f7gUXk9m7UPySjDZtR3eQ\u002f2PqLHt\u002fr6D+VILB7UsPYP7Q+ggHkrec\u002fjFpgXjti27\u002fo5Ark8XHRv8xqTqLR9vO\u002fpAmRImxt67+yjYAMD2jOv3sMetGQIcI\u002fspNDn6LR87\u002fhoWrHg3jbv0lOSDiMju8\u002fqkiXYIpo6T\u002f17DywKobsP18oV46I5PA\u002fCNrYiN0v8z981ov741v6P8HPm1qC5OK\u002fYYSni6p64j\u002fgAfnyg2nfP3bZnNTUJuk\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2024","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2024","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2024"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture (3)","showlegend":false,"x":{"dtype":"f8","bdata":"384DF8QnBkBRJaDcb5UEQGoOQt5SrANA"},"y":{"dtype":"f8","bdata":"L0OmXs0K8z+DwzuOd+vyP+6mbjmK\u002fPc\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2024","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2024","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2024","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2024","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2024"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics (14)","showlegend":false,"x":{"dtype":"f8","bdata":"7oLxE9\u002fx4D8+VEOI1KkGQClWseaVoAFAbVBLImXoBEAOBk\u002fgLsHsP8OQ1rgd\u002fwFAIZ+ixb3bBEAv8YxU8VcCQOiChQXyrvI\u002fsiwvxNYa+j+IXC+0tX8HQMDOfT7hBQdAPcqs3T\u002f3+T9kP2OgfgUEQA=="},"y":{"dtype":"f8","bdata":"25UyQPuK4L9hxIuHpmf8PyjwoB1xkPw\u002fdIEneZVZBEDHbruRaubSv93qrwRBT92\u002f5EV2WKy92L+u1cBEm\u002fGzvy3qgU0KaOa\u002f6W0d2hrc\u002fj9aJS4sCGnyP0EWC2\u002fv8Ow\u002fW83Sq4CRAECINDNNg6+TPw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2024","Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2024","Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2024","Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2024","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2024","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2024","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity (10)","showlegend":false,"x":{"dtype":"f8","bdata":"AlqLeg4w8z\u002fWDyKPNmnpP\u002fieVha+3gBAw+34TevN9z+yWh1JSMD1P6gwkCNJ3\u002fc\u002f8D5wFK10vD+yLC\u002fE1hr6P4i3Qga\u002fxQBAXAovatLUyj8="},"y":{"dtype":"f8","bdata":"cskoS7bQyr\u002fAGB0Lke7AP0j5vIhAcAFAIY7dqD0XAUBXVsKIU4YHQDyY+yAj\u002fK4\u002fTL+122+bzD\u002fpbR3aGtz+P8qYHM0hQ\u002fY\u002fSU5IOIyO7z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2024"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical (6)","showlegend":false,"x":{"dtype":"f8","bdata":"EoIE8FM22j8NHa1egx3wPxZ2RZO6d9c\u002fpqUgTDkC8z+7uwYWLBf2P5pAGrRXo+s\u002f"},"y":{"dtype":"f8","bdata":"g0ZnoiOqCECEXckPoy8HQOOq3DOdZQhA1BI6qV4s7b\u002fBz5taguTiv+jn9xpGBgJA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2024","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2024"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality (21)","showlegend":false,"x":{"dtype":"f8","bdata":"u81a6oge0j+KPC4KqbvHv575Hygtt9U\u002ffh8PFOQi4j\u002faZ1UNnTnmPyOlDGkDkuE\u002f52AnHTxouz8e\u002fPOjjzXOP6Ktd+bXDrA\u002fSDwGkrFCzT8cELISA9rkPzbcByi38N8\u002fOuEMhIvI8T+ImOTbE8nKPyP036FlAOQ\u002f1fI+UVeW2r\u002fpF0WzKL3hP2r9E8vB39I\u002fMYZiraohxj9B+sRR1hr8P72RscJghtI\u002f"},"y":{"dtype":"f8","bdata":"fGhpML8VBkBcUmLoLHsKQOpOaqDhdwxAKpLxIw+MBUAGUKwe8RwJQCr1beIr\u002ftW\u002f04JNISk0CEAPDp2BRLwHQDbfvjilPgtAqORSt8p5BEA6KPMcyGirvwO0mmdVZgpAT1FIF70yzT92tHboddYIQOCgntH4UwVAamwYE1S\u002fCUAMianhckAIQC4BN\u002fvlNQpAYGNY83q\u002fBkB81ov741v6P4w0IaMiFQdA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2024"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"qQYTXz3P3b8="},"y":{"dtype":"f8","bdata":"7TzjXxlBDUA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2024","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2024","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2024"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general (69)","showlegend":false,"x":{"dtype":"f8","bdata":"F3j0p55l8r90P\u002fbc8Yr3v7+tMDIIqPq\u002fbmAQ1qLG9L\u002fwUQ0+GfLuv4UlttvWlfS\u002f3tT510yg9b+IKEtDEAv+v+ctbLGt7Pm\u002fUNCRI4Yg978Rtix4hmrxv9ml8gnEBPm\u002f3j9iA65B9L+bQWIzz+b2v0eUTuC+RfC\u002fbm98KD7n9b9emiBuBV\u002f4v1ZH12ll\u002f\u002fW\u002fs8ugdGdQ9r88lm6VHyvtv4ThX+9it\u002fW\u002fNWLUS\u002fo78r\u002fMCFO13vr9v\u002f7Ou5nQQvu\u002fqhjFeFmv+L9a67EvRmHzv76MJex3yva\u002fkgdW8Qfm878qoWFDMSz1v8pS8d8mee2\u002fgGodaqbJ+r\u002fXYFby+BvzvzDaI86Fb+6\u002fiSXw0LBC9b+5UiQDDiPwvxq0NNNoQPi\u002fEDRlzh5a+L\u002f4C7wcC7Lyv5unk0t4kPa\u002fEtYGq5MO+b80HPLduuDtv\u002fjVrnK94PG\u002fkiklEJfh7b803sDzojX0v\u002fUq0Wk19uK\u002f5Kr4HRfMAMBKSEV6y7D0v12mF4\u002fWZ\u002fe\u002f3t0shSln8b\u002fyTy5zHGDzvwW0Ls5T5ADAmnkoOu5V8L9Xi8i3OnXyv1FSJXtSc\u002fW\u002f8ZqDQD7X979iTzhmSTz2v9UJXidpAQDAV9TtBp6W+7+n7nRJTub3v+uvs3nlp\u002fO\u002fz3\u002fVlHQ4879YR+06O1T4vxVZBo5jO+a\u002fxKIMEU\u002fu+7+cNC8mAqruv1qM\u002f7vv+Pi\u002ficLxY+418b\u002fpxtYQ1wLRv7reZn64S\u002fS\u002f"},"y":{"dtype":"f8","bdata":"Nx31P3L0CEBLjriCRsgJQHydjxcIqQRA78BPxWOtBUDO\u002fzb3ICwIQFMCONz+UgVAkCZF9jo2A0Bk9OO1Xg4FQO4ZysSXUQVADiRkzkHGBUB1hTi9EegGQLqwLXiDWQhArgQjKuxvA0DNrWmzpCIEQJiQiO6LCQJA01WCEf9QB0BLV1Lap1EFQOJjkbkgwQdAH4FDHrh5CUAkg9Ny+4gFQPR2oe3mNApAZUL1NwJHBUDrNGhlUE0HQDP5hmPi7wRA1S4fJVy2BEDsJ3SaNAUFQIQB053k5wRAD8IM5TxnBEDEOfH43OYFQF5DXzUSMwZAsu\u002fpXKmJA0DNUCdNbwIKQLrtEu9s5wZAXTEuWdtlB0As8g5ycVYHQHIRJLWcKQRAQOUS0THBBUC\u002frntnulkDQLu\u002fo4HywwRA4bYCPSTSBUBZTbH8LjsDQNhLDf5BOgVA344bfYPmBEAbj8mjsucCQIdTI+jWcgZAOPphmbp+9j8Ymfe0kfMIQD4irvithAdATvqMWBIiA0B3R+XiN7IEQNlpXLqE7QVALxEebCHIBUAjBYEuE08EQN8Sc6AeNwhABGU0pVf\u002fCECjJsVdE4cEQKBRyXCeDQRAvK\u002fYY7x7BkBHsJmfQnQCQFVnhfGgWARAR91brEUpBEBCie3vHqQDQFoIR9fhTwhAYE2IrM5XB0BQhsx8OscDQK1\u002fAwTsXghAmvzgolMUA0Bw8A+sqVHlv1pQviPc9AVA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2024"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate (1)","showlegend":false,"x":{"dtype":"f8","bdata":"+oPkGL1l5r8="},"y":{"dtype":"f8","bdata":"3HxNgyuj1L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2024"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor (1)","showlegend":false,"x":{"dtype":"f8","bdata":"WOgGo6uxB8A="},"y":{"dtype":"f8","bdata":"uFBf\u002fgdR\u002fT8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2024","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2024","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2024","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2024"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language (4)","showlegend":false,"x":{"dtype":"f8","bdata":"qD\u002fMN+0qBsBPbH0XKnQDwO7uIc20hwbAIqgFaPp7or8="},"y":{"dtype":"f8","bdata":"vNll2UFj5z\u002fD1SXIvrrxPyT9iWPQMew\u002fdtmc1NQm6T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2024"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal (1)","showlegend":false,"x":{"dtype":"f8","bdata":"d5o9JtNJDcA="},"y":{"dtype":"f8","bdata":"gEaqzubZiT8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2024"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length (1)","showlegend":false,"x":{"dtype":"f8","bdata":"5Kr4HRfMAMA="},"y":{"dtype":"f8","bdata":"OPphmbp+9j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2024","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2024","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2024","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2024","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2024"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral (20)","showlegend":false,"x":{"dtype":"f8","bdata":"68a3T6jlBMCq6kxMUT7vvwU2Trdf3QTAZM4Z34pP0j9PoxYdeqsGwBZ6u1PJ4QrA+grNw6wfC8D\u002f00eGSV3tP9ed\u002f6+B3+w\u002f8LUOMIU1dr93ngB5Mn\u002fBP1wKL2rS1Mo\u002f+gLOUxKx1z\u002fFfTwVMuwIwIw\u002fwSWDdwfA1rsYs3cPA8Araltgp+IFwBSZ0lujT9c\u002f9QMK1JwUCcDPqCvJSlYFwA=="},"y":{"dtype":"f8","bdata":"3QC14EyZ7r9uOfrH6lMCwFNqqc\u002flQPC\u002fdxt2xNEE4L\u002fYXIRHESP3vyh0pvXRMO6\u002fYi09sgBx6r\u002fo5Ark8XHRv7KNgAwPaM6\u002f4aFqx4N427+6Zds8lM30v0lOSDiMju8\u002f3F\u002fTPy2O9r\u002faqU+7\u002fnH2v\u002fj2UO7Xg\u002fW\u002fp9FcVCYq7b81RiGVYAXuv+OPWUrs2Oy\u002fOK0XcOgE6r9GGRNZrvbqvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2024","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2024","Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2024"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual (6)","showlegend":false,"x":{"dtype":"f8","bdata":"auG2nAEV4b+WB0QxRNn7v+uW4EWyB8A\u002fEx+WD4vwAsDrGfNqvcblPwvyZPhzgwbA"},"y":{"dtype":"f8","bdata":"8Sp+ww6hAsBdCtmKRKoDwPJWSci48+C\u002f8tYxZUX3+b+yk0OfotHzv4Kqrn3kvvi\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2024"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"vQUUUkLA+L8="},"y":{"dtype":"f8","bdata":"KDHFwPwf\u002fL8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2024","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2024","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2024"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions (4)","showlegend":false,"x":{"dtype":"f8","bdata":"7oLxE9\u002fx4D8OBk\u002fgLsHsP4z\u002fgG3Db7o\u002f6IKFBfKu8j8="},"y":{"dtype":"f8","bdata":"25UyQPuK4L\u002fHbruRaubSv9hG\u002f6qWCQTALeqBTQpo5r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2024","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2024","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2024","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2024","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2024"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization (31)","showlegend":false,"x":{"dtype":"f8","bdata":"wQang4AWvD\u002fWDyKPNmnpP4mLlRKcqOi\u002ftIkjpA967r8wPNgIkufXv26Kg1gzMOy\u002f3nAKtTuh7T\u002f0ci7qMYvhv3AZkTewJbM\u002f8D5wFK10vD+mpSBMOQLzP6QHaa2Xw9a\u002fp84SKzH+6b+GJCoOOjbnvyrwHt90E+6\u002fYr18u+JZ5r94UrmXlGTwvzB6zXzJD6K\u002fy5ITwQD55b8A7QLODDfov9KPAosXtue\u002fDPaLbMhM57+GqYdT2afcv0iP7FLmGs6\u002fSDtT1Elm67\u002fNu+cTuobcv5SagjMLuMC\u002fJFX4cfVD57\u002ff4u9B95Tev7u7BhYsF\u002fY\u002f20FXd7UD4L8="},"y":{"dtype":"f8","bdata":"thiDDQ8wBsDAGB0Lke7APw+f6Dr64gXAl3t4xuMvCsAM\u002fvU3HLcIwGco6iziIAbAzGpOotH287\u002fEXC8kRvcFwGIDNWQAdAfATL+122+bzD\u002fUEjqpXiztv1pxrcK1bgjAG7I3vohKCcBEj2uw4qgIwEDJtV\u002frRArAEVBX+XFbBcCGBoZlLnwDwLMYFubWPQrAeDsFt2THBcCColp7fPAIwB4EdaBBdwXAGtRLtB\u002fJBMAr+Gcp0HUIwAZDt4SNSwnAPkjlMgEZCcB1BybxbusEwDs0tRlUSQfAoW1IGpGeBcDjzrmCnNgGwMHPm1qC5OK\u002fs+FCnR65C8A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2024","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2024","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2024","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2024"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political (6)","showlegend":false,"x":{"dtype":"f8","bdata":"LD+I6qI19D+QHvLUawr8P3cugkLNw\u002fs\u002fOuEMhIvI8T93ngB5Mn\u002fBPxurjxNpAOC\u002f"},"y":{"dtype":"f8","bdata":"cQOSsAOo+r\u002fI2xyZbcf9v17DsXTZvfi\u002fT1FIF70yzT+6Zds8lM30vwfr7yjlgQbA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2024","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2024","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2024","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2024","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2024","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2024","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2024","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2024","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2024","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2024","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2024","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2024","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2024","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2024","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2024","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2024"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety (62)","showlegend":false,"x":{"dtype":"f8","bdata":"qupMTFE+779q4bacARXhv8EGp4OAFrw\u002ffi35kJr98D8CWot6DjDzP1X8P5lHs\u002f8\u002f8S2qazyV\u002fD+RP1E2zVvrP\u002fpM9voOOug\u002fku4UjDl08D\u002f4yMQn8tPoPwOERLby3Oc\u002fGEewQAEa4D+vXNMyQY3rP8WIVHn+mvM\u002fzUuLhWFh6T\u002f6g+QYvWXmvyOlDGkDkuE\u002f\u002f2nKgQtg+T9ih93iz5f4P0J7Xlv2Auc\u002fLlQqbNdg8T+oMJAjSd\u002f3P7yCRBl\u002fPPA\u002fqWP82raI7j\u002fDkNa4Hf8BQN802vhsm\u002fI\u002fS2s6t5377T\u002fjotKmcSDxPxBy9KtJUuY\u002fMXlcZ6\u002fV7D++6hfwNOf5PzdGopByDPU\u002fHBCyEgPa5D+Or5\u002fLs+rmP+sZ82q9xuU\u002fKpauDpa+9D97htYeFgXlP\u002f8gYNP2Ve0\u002fEd4xI9Lv6T\u002fF2cxiD\u002fXlP+qP2geehdg\u002ffip1epgB6D8Rcck2MvflP9I3C8\u002f4WfU\u002fCcd+u31L\u002fz8spqFdpJjzP6e5\u002f0F9ZOg\u002fOyp4V10K5z9KlL5vPhvxPzVd6awFCvI\u002fa\u002fYUdRaS3D8lGENMyzv5P7bQiPpohu4\u002fDdBGJTBc\u002fD8DXSPtRZnqP83X92\u002fIBt4\u002fU7KR5jIRAEDzn3Rgqnb+P5Do3lR5l9Q\u002f6cbWENcC0b8nE\u002fw\u002f\u002fdTnPw=="},"y":{"dtype":"f8","bdata":"bjn6x+pTAsDxKn7DDqECwLYYgw0PMAbA9\u002fj8u59KCcByyShLttDKvySecUhJ5QHArXT4u0TU8r97SKy5W50KwJrtOFrz\u002fQfASCBP6ExcBMD0HfFinYQGwHBJB69KJQLAikRV3MZwCMAiipbXBM0GwAFBc7ZReQXAyINEO0jTB8DcfE2DK6PUvyr1beIr\u002ftW\u002fuKiPw76SA8C0wqCQO0sGwPKvb4aY2wjAkOAsiNe6CsA8mPsgI\u002fyuP0u84B8PQgLAgv7CZMNwB8Dd6q8EQU\u002fdv2KLiQL4hQXAHX6ZaiWVCMCbywlVXJkGwFQLKcyfmQPAOHH8J\u002fhfBcDFh8Ayky4GwPpI6ocDrQfAOijzHMhoq7+EPJ6hHXkJwLKTQ5+i0fO\u002fVU3yrGB0B8BPp0IC+J4KwDuvxX6gygXAJwoTCn05A8CpLVfKze8JwBwQ1zJZLgbA9pjwUyfdAcCp1SCKLPkFwH9nLEFKwAPAuR97S50M\u002f7+Mv46Pfy8FwN7vkk+U6gfALhkSnahgBsALcs6pZcoGwIN8PMuodgrAu9j\u002fexy5BcCrfmJBTk\u002f6v39RTcMZJQbAgGtJv7MzCMBiVVvtXwoJwESGd+ihRwfAh9dOHHOj\u002fL9CNBN2F+b\u002fvyK2nn7AfAPAcPAPrKlR5b8T6lUNZMoGwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2024"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism (1)","showlegend":false,"x":{"dtype":"f8","bdata":"+gLOUxKx1z8="},"y":{"dtype":"f8","bdata":"3F\u002fTPy2O9r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2024","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2024","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2024","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2024","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2024","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2024","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2024","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2024","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2024"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social (18)","showlegend":false,"x":{"dtype":"f8","bdata":"xCMnWA9XAECilwv8MS8AQD0\u002f3FYRNgFAynAF79Do+T907UctEVEDQEK6uOaLOwNAWlZeeZseAECnzcoPxQIDQCGfosW92wRAjP+AbcNvuj+mpSBMOQLzPy\u002fxjFTxVwJAkB7y1GsK\u002fD9Ml1TkGUYEQLhAuQsQWgNAZD9joH4FBECoOmq6BtYBQLu7BhYsF\u002fY\u002f"},"y":{"dtype":"f8","bdata":"nSehjsBzAsCpUCA2Lxb\u002fv88uOyFwBALAdacq6LwFAcASWtdcKTYEwIxaYF47Ytu\u002fOWnTaT+YAMCkCZEibG3rv+RFdlisvdi\u002f2Eb\u002fqpYJBMDUEjqpXiztv67VwESb8bO\u002fyNscmW3H\u002fb+EoFo3qgn9vyUvhHM1eP+\u002fiDQzTYOvkz+233H5xRYCwMHPm1qC5OK\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2024","Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2024","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2024"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity (6)","showlegend":false,"x":{"dtype":"f8","bdata":"Vfw\u002fmUez\u002fz\u002f8\u002fpTUbXwJQKAe8+FFAgZA3g4Bkwx8BUDzn3Rgqnb+P5YwYDS4RgNA"},"y":{"dtype":"f8","bdata":"JJ5xSEnlAcAeDuROpkr\u002fv+Tq7p7gNO2\u002f9KxT2j9z+b9CNBN2F+b\u002fv3I1u5ujHv+\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2024","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2024","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2024","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2024","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2024"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value (15)","showlegend":false,"x":{"dtype":"f8","bdata":"FzBL5HEtCECDaTho\u002fekHQHC94UNuBAVA0Sz9j5PWBUCenfDNaDIKQH0BOPhgqQNACcd+u31L\u002fz9xeGQSRigHQBSZ0lujT9c\u002fUIhHKyLnBkAWZ3tFF34IQCUYQ0zLO\u002fk\u002ffIXs4tSGBEBTspHmMhEAQKrCzStZaQJA"},"y":{"dtype":"f8","bdata":"qoBhFTat47\u002fcf+og00ztvyOStN\u002fbT9y\u002f2oPxC4Jd5r+0TJF6lw3wvzAe8SpGeuK\u002fuR97S50M\u002f7\u002fkMxCEbTbdv+OPWUrs2Oy\u002fkZa\u002f1GnC4b9PM5oM9Gnnv6t+YkFOT\u002fq\u002fkWPoTbF567+H104cc6P8vz5Gyc4VFPG\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2025","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2025","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2025","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2025","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2025","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2025","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2025","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2025","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2025","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2025","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2025"],"legendgroup":"bias","marker":{"color":"rgb(48, 18, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"bias (19)","showlegend":false,"x":{"dtype":"f8","bdata":"+4kHxE7hCEBCurjmizsDQP\u002fTR4ZJXe0\u002fLD+I6qI19D8OBk\u002fgLsHsP8OQ1rgd\u002fwFA153\u002fr4Hf7D8hn6LFvdsEQC\u002fxjFTxVwJA6IKFBfKu8j+QHvLUawr8P3cugkLNw\u002fs\u002fiFwvtLV\u002fB0A64QyEi8jxP88T5b4PaAdAiLdCBr\u002fFAEB3ngB5Mn\u002fBP\u002foCzlMSsdc\u002fwM59PuEFB0A="},"y":{"dtype":"f8","bdata":"aPE1E0XSpz+MWmBeO2Lbv+jkCuTxcdG\u002fcQOSsAOo+r\u002fHbruRaubSv93qrwRBT92\u002fso2ADA9ozr\u002fkRXZYrL3Yv67VwESb8bO\u002fLeqBTQpo5r\u002fI2xyZbcf9v17DsXTZvfi\u002fWiUuLAhp8j9PUUgXvTLNP3sMetGQIcI\u002fypgczSFD9j+6Zds8lM30v9xf0z8tjva\u002fQRYLb+\u002fw7D8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2025","Paper: Self-Pluralising Culture Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: xu-etal-2025-self\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2025","Paper: Faux Polyglot: A Study on Information Disparity in\u003cbr\u003eMultilingual Large Language Models\u003cbr\u003eID: sharma-etal-2025-faux\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: {JAWAHER}: A Multidialectal Dataset of {A}rabic\u003cbr\u003eProverbs for {LLM} Benchmarking\u003cbr\u003eID: magdy-etal-2025-jawaher\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Towards Inclusive {A}rabic {LLM}s: A Culturally\u003cbr\u003eAligned Benchmark in {A}rabic Large Language Model\u003cbr\u003eEvaluation\u003cbr\u003eID: nacar-etal-2025-towards\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CALM}: Unleashing the Cross-Lingual Self-Aligning\u003cbr\u003eAbility of Language Model Question Answering\u003cbr\u003eID: wang-etal-2025-calm\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CDE}val: A Benchmark for Measuring the Cultural\u003cbr\u003eDimensions of Large Language Models\u003cbr\u003eID: wang-etal-2024-cdeval\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Are Generative Language Models Multicultural? A\u003cbr\u003eStudy on {H}ausa Culture and Emotions using\u003cbr\u003e{C}hat{GPT}\u003cbr\u003eID: ahmad-etal-2024-generative\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Investigating Cultural Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: alkhamissi-etal-2024-investigating\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Knowledge of cultural moral norms in large\u003cbr\u003elanguage models\u003cbr\u003eID: ramezani-xu-2023-knowledge\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2025","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2025","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2025","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: {S}usu Box or Piggy Bank: Assessing Cultural\u003cbr\u003eCommonsense Knowledge between {G}hana and the {US}\u003cbr\u003eID: acquaye-etal-2024-susu\u003cbr\u003eSubtopics: cultural, bias\u003cbr\u003eYear: 2025","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2025","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2025","Paper: Cultural Alignment in Large Language Models: An\u003cbr\u003eExplanatory Analysis Based on Hofstede{'}s\u003cbr\u003eCultural Dimensions\u003cbr\u003eID: masoud-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {CULTURALLY} {YOURS}: A Reading Assistant for\u003cbr\u003eCross-Cultural Content\u003cbr\u003eID: pandey-etal-2025-culturally\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Cultural Learning-Based Culture Adaptation of\u003cbr\u003eLanguage Models\u003cbr\u003eID: liu-etal-2025-cultural\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {C}ul{F}i{T}: A Fine-grained Cultural-aware {LLM}\u003cbr\u003eTraining Paradigm via Multilingual Critique Data\u003cbr\u003eSynthesis\u003cbr\u003eID: feng-etal-2025-culfit\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025","Paper: Musical Ethnocentrism in Large Language Models\u003cbr\u003eID: kruspe-2024-musical\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: Increasing the Difficulty of Automatically\u003cbr\u003eGenerated Questions via Reinforcement Learning\u003cbr\u003ewith Synthetic Preference for Cost-Effective\u003cbr\u003eCultural Heritage Dataset Generation\u003cbr\u003eID: thorne-etal-2024-increasing\u003cbr\u003eSubtopics: cultural\u003cbr\u003eYear: 2025","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2025"],"legendgroup":"cultural","marker":{"color":"rgb(58, 48, 124)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"cultural (30)","showlegend":false,"x":{"dtype":"f8","bdata":"ZM4Z34pP0j\u002frluBFsgfAPzBGi+k4swJA8S2qazyV\u002fD\u002f7iQfETuEIQFIqPsgrJghAXD2YRGL7CkB9alXxqfgIQBQMYMjS3QhA5qBaWdlVCEAhJ+Zw+IkFQBisM56joARAQrq45os7A0D\u002f00eGSV3tP95wCrU7oe0\u002fp83KD8UCA0DXnf+vgd\u002fsP88T5b4PaAdA6xnzar3G5T\u002fwtQ4whTV2v1wKL2rS1Mo\u002fOIgJp\u002fGWBkDB7uswazYHQA6Je5jfuQlAKVHCwMPAAkBB+sRR1hr8P7u7BhYsF\u002fY\u002fzSUvvFFqCECTJ5DvHfoHQCKoBWj6e6K\u002f"},"y":{"dtype":"f8","bdata":"dxt2xNEE4L\u002fyVknIuPPgv562x5dbEug\u002frXT4u0TU8r9o8TUTRdKnP1EDx\u002fXI+uo\u002fMhVY64iH6T\u002f7gUXk9m7UPySjDZtR3eQ\u002f2PqLHt\u002fr6D+VILB7UsPYP7Q+ggHkrec\u002fjFpgXjti27\u002fo5Ark8XHRv8xqTqLR9vO\u002fpAmRImxt67+yjYAMD2jOv3sMetGQIcI\u002fspNDn6LR87\u002fhoWrHg3jbv0lOSDiMju8\u002fqkiXYIpo6T\u002f17DywKobsP18oV46I5PA\u002fCNrYiN0v8z981ov741v6P8HPm1qC5OK\u002fYYSni6p64j\u002fgAfnyg2nfP3bZnNTUJuk\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Matina: A Culturally-Aligned {P}ersian Language\u003cbr\u003eModel Using Multiple {L}o{RA} Experts\u003cbr\u003eID: hosseinbeigi-etal-2025-matina-culturally\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025","Paper: {LLM} Alignment for the {A}rabs: A Homogenous\u003cbr\u003eCulture or Diverse Ones\u003cbr\u003eID: keleg-2025-llm\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025","Paper: Command {R}7{B} {A}rabic: a small, enterprise-\u003cbr\u003efocused, multilingual, and culturally aware\u003cbr\u003e{A}rabic {LLM}\u003cbr\u003eID: alnumay-etal-2025-command\u003cbr\u003eSubtopics: culture\u003cbr\u003eYear: 2025"],"legendgroup":"culture","marker":{"color":"rgb(66, 77, 182)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"culture (3)","showlegend":false,"x":{"dtype":"f8","bdata":"384DF8QnBkBRJaDcb5UEQGoOQt5SrANA"},"y":{"dtype":"f8","bdata":"L0OmXs0K8z+DwzuOd+vyP+6mbjmK\u002fPc\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2025","Paper: Rejected Dialects: Biases Against {A}frican\u003cbr\u003e{A}merican Language in Reward Models\u003cbr\u003eID: mire-etal-2025-rejected\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Aligning to What? Limits to {RLHF} Based Alignment\u003cbr\u003eID: barnhart-etal-2025-aligning\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Whose Emotions and Moral Sentiments do Language\u003cbr\u003eModels Reflect?\u003cbr\u003eID: he-etal-2024-whose\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2025","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2025","Paper: ``You Gotta be a Doctor, Lin'' : An Investigation\u003cbr\u003eof Name-Based Bias of Large Language Models in\u003cbr\u003eEmployment Recommendations\u003cbr\u003eID: nghiem-etal-2024-gotta\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2025","Paper: The Generation Gap: Exploring Age Bias in the\u003cbr\u003eValue Systems of Large Language Models\u003cbr\u003eID: liu-etal-2024-generation-gap\u003cbr\u003eSubtopics: demographics, bias\u003cbr\u003eYear: 2025","Paper: ``You are Beautiful, Body Image Stereotypes are\u003cbr\u003eUgly!'' {BIS}tereo: A Benchmark to Measure Body\u003cbr\u003eImage Stereotypes in Language Models\u003cbr\u003eID: asad-etal-2025-beautiful\u003cbr\u003eSubtopics: demographics\u003cbr\u003eYear: 2025","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2025"],"legendgroup":"demographics","marker":{"color":"rgb(69, 105, 220)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"demographics (14)","showlegend":false,"x":{"dtype":"f8","bdata":"7oLxE9\u002fx4D8+VEOI1KkGQClWseaVoAFAbVBLImXoBEAOBk\u002fgLsHsP8OQ1rgd\u002fwFAIZ+ixb3bBEAv8YxU8VcCQOiChQXyrvI\u002fsiwvxNYa+j+IXC+0tX8HQMDOfT7hBQdAPcqs3T\u002f3+T9kP2OgfgUEQA=="},"y":{"dtype":"f8","bdata":"25UyQPuK4L9hxIuHpmf8PyjwoB1xkPw\u002fdIEneZVZBEDHbruRaubSv93qrwRBT92\u002f5EV2WKy92L+u1cBEm\u002fGzvy3qgU0KaOa\u002f6W0d2hrc\u002fj9aJS4sCGnyP0EWC2\u002fv8Ow\u002fW83Sq4CRAECINDNNg6+TPw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2025","Paper: {S}ea{LLM}s - Large Language Models for\u003cbr\u003e{S}outheast {A}sia\u003cbr\u003eID: nguyen-etal-2024-seallms\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2025","Paper: Enabling Classifiers to Make Judgements Explicitly\u003cbr\u003eAligned with Human Values\u003cbr\u003eID: bang-etal-2023-enabling\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2025","Paper: The (Undesired) Attenuation of Human Biases by\u003cbr\u003eMultilinguality\u003cbr\u003eID: espana-bonet-barron-cedeno-2022-undesired\u003cbr\u003eSubtopics: diversity\u003cbr\u003eYear: 2025","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2025","Paper: Modular Pluralism: Pluralistic Alignment via\u003cbr\u003eMulti-{LLM} Collaboration\u003cbr\u003eID: feng-etal-2024-modular\u003cbr\u003eSubtopics: demographics, diversity\u003cbr\u003eYear: 2025","Paper: {GDPO}: Learning to Directly Align Language Models\u003cbr\u003ewith Diversity Using {GF}low{N}ets\u003cbr\u003eID: kwon-etal-2024-gdpo\u003cbr\u003eSubtopics: diversity, bias\u003cbr\u003eYear: 2025","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2025"],"legendgroup":"diversity","marker":{"color":"rgb(66, 132, 242)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"diversity (10)","showlegend":false,"x":{"dtype":"f8","bdata":"AlqLeg4w8z\u002fWDyKPNmnpP\u002fieVha+3gBAw+34TevN9z+yWh1JSMD1P6gwkCNJ3\u002fc\u002f8D5wFK10vD+yLC\u002fE1hr6P4i3Qga\u002fxQBAXAovatLUyj8="},"y":{"dtype":"f8","bdata":"cskoS7bQyr\u002fAGB0Lke7AP0j5vIhAcAFAIY7dqD0XAUBXVsKIU4YHQDyY+yAj\u002fK4\u002fTL+122+bzD\u002fpbR3aGtz+P8qYHM0hQ\u002fY\u002fSU5IOIyO7z8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {PROTECT}: Policy-Related Organizational Value\u003cbr\u003eTaxonomy for Ethical Compliance and Trust\u003cbr\u003eID: mittal-etal-2025-protect\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Anak Baik: A Low-Cost Approach to Curate\u003cbr\u003e{I}ndonesian Ethical and Unethical Instructions\u003cbr\u003eID: hakim-etal-2025-anak\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: Chat Bankman-Fried: an Exploration of {LLM}\u003cbr\u003eAlignment in Finance\u003cbr\u003eID: biancotti-etal-2025-chat\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025","Paper: Language Models are Alignable Decision-Makers:\u003cbr\u003eDataset and Application to the Medical Triage\u003cbr\u003eDomain\u003cbr\u003eID: hu-etal-2024-language\u003cbr\u003eSubtopics: ethical\u003cbr\u003eYear: 2025"],"legendgroup":"ethical","marker":{"color":"rgb(58, 158, 251)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"ethical (6)","showlegend":false,"x":{"dtype":"f8","bdata":"EoIE8FM22j8NHa1egx3wPxZ2RZO6d9c\u002fpqUgTDkC8z+7uwYWLBf2P5pAGrRXo+s\u002f"},"y":{"dtype":"f8","bdata":"g0ZnoiOqCECEXckPoy8HQOOq3DOdZQhA1BI6qV4s7b\u002fBz5taguTiv+jn9xpGBgJA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Verifiable by Design: Aligning Language Models to\u003cbr\u003eQuote from Pre-Training Data\u003cbr\u003eID: zhang-etal-2025-verifiable\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {PA}-{RAG}: {RAG} Alignment via Multi-Perspective\u003cbr\u003ePreference Optimization\u003cbr\u003eID: wu-etal-2025-pa\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Improving Factual Consistency for Knowledge-\u003cbr\u003eGrounded Dialogue Systems via Knowledge\u003cbr\u003eEnhancement and Alignment\u003cbr\u003eID: xue-etal-2023-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Learning to Trust Your Feelings: Leveraging Self-\u003cbr\u003eawareness in {LLM}s for Hallucination Mitigation\u003cbr\u003eID: liang-etal-2024-learning\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: A Grounded Preference Model for {LLM} Alignment\u003cbr\u003eID: naseem-etal-2024-grounded\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2025","Paper: When to Trust {LLM}s: Aligning Confidence with\u003cbr\u003eResponse Quality\u003cbr\u003eID: tao-etal-2024-trust\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {C}a{LM}: Contrasting Large and Small Language\u003cbr\u003eModels to Verify Grounded Generation\u003cbr\u003eID: hsu-etal-2024-calm\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Reformatted Alignment\u003cbr\u003eID: fan-etal-2024-reformatted\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Knowledge Editing in Language Models via Adapted\u003cbr\u003eDirect Preference Optimization\u003cbr\u003eID: rozner-etal-2024-knowledge\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2025","Paper: The Accuracy Paradox in {RLHF}: When Better Reward\u003cbr\u003eModels Don{'}t Yield Better Language Models\u003cbr\u003eID: chen-etal-2024-accuracy\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2025","Paper: Synchronous Faithfulness Monitoring for\u003cbr\u003eTrustworthy Retrieval-Augmented Generation\u003cbr\u003eID: wu-etal-2024-synchronous\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Enhancing Language Model Factuality via\u003cbr\u003eActivation-Based Confidence Calibration and Guided\u003cbr\u003eDecoding\u003cbr\u003eID: liu-etal-2024-enhancing-language\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Evidence-Focused Fact Summarization for Knowledge-\u003cbr\u003eAugmented Zero-Shot Question Answering\u003cbr\u003eID: ko-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Calibrating Language Models with Adaptive\u003cbr\u003eTemperature Scaling\u003cbr\u003eID: xie-etal-2024-calibrating\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: Improving Model Factuality with Fine-grained\u003cbr\u003eCritique-based Evaluator\u003cbr\u003eID: xie-etal-2025-improving\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: {L}o{GU}: Long-form Generation with Uncertainty\u003cbr\u003eExpressions\u003cbr\u003eID: yang-etal-2025-logu\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025","Paper: A Dual-Layered Evaluation of Geopolitical and\u003cbr\u003eCultural Bias in {LLM}s\u003cbr\u003eID: kim-kim-2025-dual\u003cbr\u003eSubtopics: cultural, factuality\u003cbr\u003eYear: 2025","Paper: Evidence-Driven Retrieval Augmented Response\u003cbr\u003eGeneration for Online Misinformation\u003cbr\u003eID: yue-etal-2024-evidence\u003cbr\u003eSubtopics: factuality\u003cbr\u003eYear: 2025"],"legendgroup":"factuality","marker":{"color":"rgb(42, 184, 232)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"factuality (21)","showlegend":false,"x":{"dtype":"f8","bdata":"u81a6oge0j+KPC4KqbvHv575Hygtt9U\u002ffh8PFOQi4j\u002faZ1UNnTnmPyOlDGkDkuE\u002f52AnHTxouz8e\u002fPOjjzXOP6Ktd+bXDrA\u002fSDwGkrFCzT8cELISA9rkPzbcByi38N8\u002fOuEMhIvI8T+ImOTbE8nKPyP036FlAOQ\u002f1fI+UVeW2r\u002fpF0WzKL3hP2r9E8vB39I\u002fMYZiraohxj9B+sRR1hr8P72RscJghtI\u002f"},"y":{"dtype":"f8","bdata":"fGhpML8VBkBcUmLoLHsKQOpOaqDhdwxAKpLxIw+MBUAGUKwe8RwJQCr1beIr\u002ftW\u002f04JNISk0CEAPDp2BRLwHQDbfvjilPgtAqORSt8p5BEA6KPMcyGirvwO0mmdVZgpAT1FIF70yzT92tHboddYIQOCgntH4UwVAamwYE1S\u002fCUAMianhckAIQC4BN\u002fvlNQpAYGNY83q\u002fBkB81ov741v6P4w0IaMiFQdA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Context-{DPO}: Aligning Language Models for\u003cbr\u003eContext-Faithfulness\u003cbr\u003eID: bi-etal-2025-context\u003cbr\u003eSubtopics: faithfulness\u003cbr\u003eYear: 2025"],"legendgroup":"faithfulness","marker":{"color":"rgb(28, 209, 208)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"faithfulness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"qQYTXz3P3b8="},"y":{"dtype":"f8","bdata":"7TzjXxlBDUA="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Diverse {AI} Feedback For Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: yu-etal-2025-diverse\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: One fish, two fish, but not the whole sea:\u003cbr\u003eAlignment reduces language models' conceptual\u003cbr\u003ediversity\u003cbr\u003eID: murthy-etal-2025-one\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Pipeline Analysis for Developing Instruct {LLM}s\u003cbr\u003ein Low-Resource Languages: A Case Study on\u003cbr\u003e{B}asque\u003cbr\u003eID: corral-etal-2025-pipeline\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Sentimatic: Sentiment-guided Automatic Generation\u003cbr\u003eof Preference Datasets for Customer Support\u003cbr\u003eDialogue System\u003cbr\u003eID: lee-han-2025-sentimatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: ({CPER}) From Guessing to Asking: An Approach to\u003cbr\u003eResolving Persona Knowledge Gap in {LLM}s during\u003cbr\u003eMulti-Turn Conversations\u003cbr\u003eID: baskar-etal-2025-cper\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: How Inclusively do {LM}s Perceive Social and Moral\u003cbr\u003eNorms?\u003cbr\u003eID: galarnyk-etal-2025-inclusively\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {M}eta{A}lign: Align Large Language Models with\u003cbr\u003eDiverse Preferences during Inference Time\u003cbr\u003eID: zhang-etal-2025-metaalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {SPICA}: Retrieving Scenarios for Pluralistic In-\u003cbr\u003eContext Alignment\u003cbr\u003eID: chen-etal-2025-spica\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Preference-Guided Reflective Sampling for Aligning\u003cbr\u003eLanguage Models\u003cbr\u003eID: ye-ng-2024-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Do {LLM}s Plan Like Human Writers? Comparing\u003cbr\u003eJournalist Coverage of Press Releases with {LLM}s\u003cbr\u003eID: spangher-etal-2024-llms\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: The Greatest Good Benchmark: Measuring {LLM}s'\u003cbr\u003eAlignment with Utilitarian Moral Dilemmas\u003cbr\u003eID: marraffini-etal-2024-greatest\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Value Alignment from Unstructured Text\u003cbr\u003eID: padhi-etal-2024-value\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Constructing Domain-Specific Evaluation Sets for\u003cbr\u003e{LLM}-as-a-judge\u003cbr\u003eID: raju-etal-2024-constructing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Arithmetic Control of {LLM}s for Diverse User\u003cbr\u003ePreferences: Directional Preference Alignment with\u003cbr\u003eMulti-Objective Rewards\u003cbr\u003eID: wang-etal-2024-arithmetic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Whose Preferences? Differences in Fairness\u003cbr\u003ePreferences and Their Impact on the Fairness of\u003cbr\u003e{AI} Utilizing Human Feedback\u003cbr\u003eID: lerner-etal-2024-whose\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning Large Language Models with Human\u003cbr\u003ePreferences through Representation Engineering\u003cbr\u003eID: liu-etal-2024-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Unintended Impacts of {LLM} Alignment on Global\u003cbr\u003eRepresentation\u003cbr\u003eID: ryan-etal-2024-unintended\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Reliability Check: An Analysis of {GPT}-3{'}s\u003cbr\u003eResponse to Sensitive Topics and Prompt Wording\u003cbr\u003eID: khatun-brown-2023-reliability\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Lauri Ingman at {S}em{E}val-2023 Task 4: A Chain\u003cbr\u003eClassifier for Identifying Human Values behind\u003cbr\u003eArguments\u003cbr\u003eID: paulissen-wendt-2023-lauri\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {R}eal{B}ehavior: A Framework for Faithfully\u003cbr\u003eCharacterizing Foundation Models' Human-like\u003cbr\u003eBehavior Mechanisms\u003cbr\u003eID: zhou-etal-2023-realbehavior\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {S}teer{LM}: Attribute Conditioned {SFT} as an\u003cbr\u003e(User-Steerable) Alternative to {RLHF}\u003cbr\u003eID: dong-etal-2023-steerlm\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Ethical Reasoning over Moral Alignment: A Case and\u003cbr\u003eFramework for In-Context Ethical Policies in\u003cbr\u003e{LLM}s\u003cbr\u003eID: rao-etal-2023-ethical\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: The Past, Present and Better Future of Feedback\u003cbr\u003eLearning in Large Language Models for Subjective\u003cbr\u003eHuman Preferences and Values\u003cbr\u003eID: kirk-etal-2023-past\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Learning Preference Model for {LLM}s via Automatic\u003cbr\u003ePreference Data Generation\u003cbr\u003eID: huang-etal-2023-learning-preference\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Axiomatic Preference Modeling for Longform\u003cbr\u003eQuestion Answering\u003cbr\u003eID: rosset-etal-2023-axiomatic\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Okapi: Instruction-tuned Large Language Models in\u003cbr\u003eMultiple Languages with Reinforcement Learning\u003cbr\u003efrom Human Feedback\u003cbr\u003eID: lai-etal-2023-okapi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Probing Pre-Trained Language Models for Cross-\u003cbr\u003eCultural Differences in Values\u003cbr\u003eID: arora-etal-2023-probing\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Towards Boosting the Open-Domain Chatbot with\u003cbr\u003eHuman Feedback\u003cbr\u003eID: lu-etal-2023-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Does Moral Code have a Moral Code? Probing\u003cbr\u003eDelphi{'}s Moral Philosophy\u003cbr\u003eID: fraser-etal-2022-moral\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Towards Socially Intelligent Agents with Mental\u003cbr\u003eState Transition and Human Value\u003cbr\u003eID: qiu-etal-2022-towards\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning to Social Norms and Values in Interactive\u003cbr\u003eNarratives\u003cbr\u003eID: ammanabrolu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning Generative Language Models with Human\u003cbr\u003eValues\u003cbr\u003eID: liu-etal-2022-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {LIRE}: listwise reward enhancement for preference\u003cbr\u003ealignment\u003cbr\u003eID: zhu-etal-2024-lire\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Multi-Objective Linguistic Control of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: nguyen-etal-2024-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Disentangling Length from Quality in Direct\u003cbr\u003ePreference Optimization\u003cbr\u003eID: park-etal-2024-disentangling\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Teaching Language Models to Self-Improve by\u003cbr\u003eLearning from Language Feedback\u003cbr\u003eID: hu-etal-2024-teaching\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {S}o{FA}: Shielded On-the-fly Alignment via\u003cbr\u003ePriority Rule Following\u003cbr\u003eID: lu-etal-2024-sofa\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Direct Preference Optimization with an Offset\u003cbr\u003eID: amini-etal-2024-direct\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {C}ycle{A}lign: Iterative Distillation from Black-\u003cbr\u003ebox {LLM} to White-box Models for Better Human\u003cbr\u003eAlignment\u003cbr\u003eID: hong-etal-2024-cyclealign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Eliminating Biased Length Reliance of Direct\u003cbr\u003ePreference Optimization via Down-Sampled {KL}\u003cbr\u003eDivergence\u003cbr\u003eID: lu-etal-2024-eliminating\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {WPO}: Enhancing {RLHF} with Weighted Preference\u003cbr\u003eOptimization\u003cbr\u003eID: zhou-etal-2024-wpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {BPO}: Staying Close to the Behavior {LLM} Creates\u003cbr\u003eBetter Online {LLM} Alignment\u003cbr\u003eID: xu-etal-2024-bpo\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Self-Steering Optimization: Autonomous Preference\u003cbr\u003eOptimization for Large Language Models\u003cbr\u003eID: xiang-etal-2025-self\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Well Begun is Half Done: Low-resource Preference\u003cbr\u003eAlignment by Weak-to-Strong Decoding\u003cbr\u003eID: song-etal-2025-well\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: ``{I} understand your perspective'': {LLM}\u003cbr\u003ePersuasion through the Lens of Communicative\u003cbr\u003eAction Theory\u003cbr\u003eID: donmez-falenska-2025-understand\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2025","Paper: Multi-perspective Preference Alignment of {LLM}s\u003cbr\u003efor Programming-Community Question Answering\u003cbr\u003eID: yang-etal-2025-multi\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Aligning Large Language Models with Human Opinions\u003cbr\u003ethrough Persona Selection and\u003cbr\u003eValue{--}Belief{--}Norm Reasoning\u003cbr\u003eID: do-etal-2025-aligning\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {COF}: Adaptive Chain of Feedback for Comparative\u003cbr\u003eOpinion Quintuple Extraction\u003cbr\u003eID: xu-etal-2025-cof\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Is my Meeting Summary Good? Estimating Quality\u003cbr\u003ewith a Multi-{LLM} Evaluator\u003cbr\u003eID: kirstein-etal-2025-meeting\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Bias in the Mirror : Are {LLM}s opinions robust to\u003cbr\u003etheir own adversarial attacks\u003cbr\u003eID: rennard-etal-2025-bias\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Semantic-Eval : A Semantic Comprehension\u003cbr\u003eEvaluation Framework for Large Language Models\u003cbr\u003eGeneration without Training\u003cbr\u003eID: li-etal-2025-semantic-eval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Frictional Agent Alignment Framework: Slow Down\u003cbr\u003eand Don{'}t Break Things\u003cbr\u003eID: nath-etal-2025-frictional\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Gradient-Adaptive Policy Optimization: Towards\u003cbr\u003eMulti-Objective Alignment of Large Language Models\u003cbr\u003eID: li-etal-2025-gradient\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Cheems: A Practical Guidance for Building and\u003cbr\u003eEvaluating {C}hinese Reward Models from Scratch\u003cbr\u003eID: wen-etal-2025-cheems\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {P}rox{A}nn: Use-Oriented Evaluations of Topic\u003cbr\u003eModels and Document Clustering\u003cbr\u003eID: hoyle-etal-2025-proxann\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {C}riti{Q}: Mining Data Quality Criteria from\u003cbr\u003eHuman Preferences\u003cbr\u003eID: guo-etal-2025-critiq\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {A}uto{M}ix{A}lign: Adaptive Data Mixing for\u003cbr\u003eMulti-Task Preference Optimization in {LLM}s\u003cbr\u003eID: corrado-etal-2025-automixalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {BIG}5-{CHAT}: Shaping {LLM} Personalities Through\u003cbr\u003eTraining on Human-Grounded Data\u003cbr\u003eID: li-etal-2025-big5\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {VITAL}: A New Dataset for Benchmarking\u003cbr\u003ePluralistic Alignment in Healthcare\u003cbr\u003eID: shetty-etal-2025-vital\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {D}e{AL}: Decoding-time Alignment for Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: huang-etal-2025-deal\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Bone Soups: A Seek-and-Soup Model Merging Approach\u003cbr\u003efor Controllable Multi-Objective Generation\u003cbr\u003eID: xie-etal-2025-bone\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {P}op{A}lign: Diversifying Contrasting Patterns\u003cbr\u003efor a More Comprehensive Alignment\u003cbr\u003eID: wang-etal-2025-popalign\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: $\\mathcal{A}^3$: Automatic Alignment Framework for\u003cbr\u003eAttributed Text Generation\u003cbr\u003eID: wang-etal-2025-a3\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {RUBRIC}-{MQM} : Span-Level {LLM}-as-judge in\u003cbr\u003eMachine Translation For High-End Models\u003cbr\u003eID: kim-2025-rubric\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {T}ele{C}hat: An Open-source Billingual Large\u003cbr\u003eLanguage Model\u003cbr\u003eID: wang-etal-2024-telechat\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: {I}nstruct{E}val: Towards Holistic Evaluation of\u003cbr\u003eInstruction-Tuned Large Language Models\u003cbr\u003eID: chia-etal-2024-instructeval\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2025","Paper: {Z}hu{J}iu-Knowledge: A Fairer Platform for\u003cbr\u003eEvaluating Multiple Knowledge Types in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: du-etal-2024-zhujiu\u003cbr\u003eSubtopics: general\u003cbr\u003eYear: 2025"],"legendgroup":"general","marker":{"color":"rgb(33, 226, 181)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"general (69)","showlegend":false,"x":{"dtype":"f8","bdata":"F3j0p55l8r90P\u002fbc8Yr3v7+tMDIIqPq\u002fbmAQ1qLG9L\u002fwUQ0+GfLuv4UlttvWlfS\u002f3tT510yg9b+IKEtDEAv+v+ctbLGt7Pm\u002fUNCRI4Yg978Rtix4hmrxv9ml8gnEBPm\u002f3j9iA65B9L+bQWIzz+b2v0eUTuC+RfC\u002fbm98KD7n9b9emiBuBV\u002f4v1ZH12ll\u002f\u002fW\u002fs8ugdGdQ9r88lm6VHyvtv4ThX+9it\u002fW\u002fNWLUS\u002fo78r\u002fMCFO13vr9v\u002f7Ou5nQQvu\u002fqhjFeFmv+L9a67EvRmHzv76MJex3yva\u002fkgdW8Qfm878qoWFDMSz1v8pS8d8mee2\u002fgGodaqbJ+r\u002fXYFby+BvzvzDaI86Fb+6\u002fiSXw0LBC9b+5UiQDDiPwvxq0NNNoQPi\u002fEDRlzh5a+L\u002f4C7wcC7Lyv5unk0t4kPa\u002fEtYGq5MO+b80HPLduuDtv\u002fjVrnK94PG\u002fkiklEJfh7b803sDzojX0v\u002fUq0Wk19uK\u002f5Kr4HRfMAMBKSEV6y7D0v12mF4\u002fWZ\u002fe\u002f3t0shSln8b\u002fyTy5zHGDzvwW0Ls5T5ADAmnkoOu5V8L9Xi8i3OnXyv1FSJXtSc\u002fW\u002f8ZqDQD7X979iTzhmSTz2v9UJXidpAQDAV9TtBp6W+7+n7nRJTub3v+uvs3nlp\u002fO\u002fz3\u002fVlHQ4879YR+06O1T4vxVZBo5jO+a\u002fxKIMEU\u002fu+7+cNC8mAqruv1qM\u002f7vv+Pi\u002ficLxY+418b\u002fpxtYQ1wLRv7reZn64S\u002fS\u002f"},"y":{"dtype":"f8","bdata":"Nx31P3L0CEBLjriCRsgJQHydjxcIqQRA78BPxWOtBUDO\u002fzb3ICwIQFMCONz+UgVAkCZF9jo2A0Bk9OO1Xg4FQO4ZysSXUQVADiRkzkHGBUB1hTi9EegGQLqwLXiDWQhArgQjKuxvA0DNrWmzpCIEQJiQiO6LCQJA01WCEf9QB0BLV1Lap1EFQOJjkbkgwQdAH4FDHrh5CUAkg9Ny+4gFQPR2oe3mNApAZUL1NwJHBUDrNGhlUE0HQDP5hmPi7wRA1S4fJVy2BEDsJ3SaNAUFQIQB053k5wRAD8IM5TxnBEDEOfH43OYFQF5DXzUSMwZAsu\u002fpXKmJA0DNUCdNbwIKQLrtEu9s5wZAXTEuWdtlB0As8g5ycVYHQHIRJLWcKQRAQOUS0THBBUC\u002frntnulkDQLu\u002fo4HywwRA4bYCPSTSBUBZTbH8LjsDQNhLDf5BOgVA344bfYPmBEAbj8mjsucCQIdTI+jWcgZAOPphmbp+9j8Ymfe0kfMIQD4irvithAdATvqMWBIiA0B3R+XiN7IEQNlpXLqE7QVALxEebCHIBUAjBYEuE08EQN8Sc6AeNwhABGU0pVf\u002fCECjJsVdE4cEQKBRyXCeDQRAvK\u002fYY7x7BkBHsJmfQnQCQFVnhfGgWARAR91brEUpBEBCie3vHqQDQFoIR9fhTwhAYE2IrM5XB0BQhsx8OscDQK1\u002fAwTsXghAmvzgolMUA0Bw8A+sqVHlv1pQviPc9AVA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2025"],"legendgroup":"hate","marker":{"color":"rgb(51, 240, 151)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"hate (1)","showlegend":false,"x":{"dtype":"f8","bdata":"+oPkGL1l5r8="},"y":{"dtype":"f8","bdata":"3HxNgyuj1L8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Are {U} a Joke Master? Pun Generation via Multi-\u003cbr\u003eStage Curriculum Learning towards a Humor {LLM}\u003cbr\u003eID: chen-etal-2024-u\u003cbr\u003eSubtopics: humor\u003cbr\u003eYear: 2025"],"legendgroup":"humor","marker":{"color":"rgb(87, 249, 118)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"humor (1)","showlegend":false,"x":{"dtype":"f8","bdata":"WOgGo6uxB8A="},"y":{"dtype":"f8","bdata":"uFBf\u002fgdR\u002fT8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Implicit Cross-Lingual Rewarding for Efficient\u003cbr\u003eMultilingual Preference Alignment\u003cbr\u003eID: yang-etal-2025-implicit\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: 7 Points to {T}singhua but 10 Points to ?\u003cbr\u003eAssessing Large Language Models in Agentic\u003cbr\u003eMultilingual National Bias\u003cbr\u003eID: liu-etal-2025-7\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: {REPA}: {R}ussian Error Types Annotation for\u003cbr\u003eEvaluating Text Generation and Judgment\u003cbr\u003eCapabilities\u003cbr\u003eID: pugachev-etal-2025-repa\u003cbr\u003eSubtopics: language\u003cbr\u003eYear: 2025","Paper: {A}ce{GPT}, Localizing Large Language Models in\u003cbr\u003e{A}rabic\u003cbr\u003eID: huang-etal-2024-acegpt\u003cbr\u003eSubtopics: language, cultural\u003cbr\u003eYear: 2025"],"legendgroup":"language","marker":{"color":"rgb(125, 252, 88)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"language (4)","showlegend":false,"x":{"dtype":"f8","bdata":"qD\u002fMN+0qBsBPbH0XKnQDwO7uIc20hwbAIqgFaPp7or8="},"y":{"dtype":"f8","bdata":"vNll2UFj5z\u002fD1SXIvrrxPyT9iWPQMew\u002fdtmc1NQm6T8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Aligning Language Models for {Icelandic} Legal\u003cbr\u003eText Summarization\u003cbr\u003eID: hardarson-etal-2025-aligning\u003cbr\u003eSubtopics: legal\u003cbr\u003eYear: 2025"],"legendgroup":"legal","marker":{"color":"rgb(164, 252, 59)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"legal (1)","showlegend":false,"x":{"dtype":"f8","bdata":"d5o9JtNJDcA="},"y":{"dtype":"f8","bdata":"gEaqzubZiT8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {MWPO}: Enhancing {LLM}s Performance through\u003cbr\u003eMulti-Weight Preference Strength and Length\u003cbr\u003eOptimization\u003cbr\u003eID: xu-etal-2025-mwpo\u003cbr\u003eSubtopics: length, general\u003cbr\u003eYear: 2025"],"legendgroup":"length","marker":{"color":"rgb(190, 240, 55)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"length (1)","showlegend":false,"x":{"dtype":"f8","bdata":"5Kr4HRfMAMA="},"y":{"dtype":"f8","bdata":"OPphmbp+9j8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {UA}lign: {LLM} Alignment Benchmark for the\u003cbr\u003e{U}krainian Language\u003cbr\u003eID: kravchenko-etal-2025-ualign\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2025","Paper: What Counts Underlying {LLM}s' Moral Dilemma\u003cbr\u003eJudgments?\u003cbr\u003eID: wu-deng-2025-counts\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: {HISTOIRESMORALES}: A {F}rench Dataset for\u003cbr\u003eAssessing Moral Alignment\u003cbr\u003eID: leteno-etal-2025-histoiresmorales\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: Does Cross-Cultural Alignment Change the\u003cbr\u003eCommonsense Morality of Language Models?\u003cbr\u003eID: jinnai-2024-cross\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: {M}oral{D}ial: A Framework to Train and Evaluate\u003cbr\u003eMoral Dialogue Systems via Moral Discussions\u003cbr\u003eID: sun-etal-2023-moraldial\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: A Corpus for Understanding and Generating Moral\u003cbr\u003eStories\u003cbr\u003eID: guan-etal-2022-corpus\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Ethical Reasoning and Moral Value Alignment of\u003cbr\u003e{LLM}s Depend on the Language We Prompt Them in\u003cbr\u003eID: agarwal-etal-2024-ethical\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: Evaluating Moral Beliefs across {LLM}s through a\u003cbr\u003ePluralistic Framework\u003cbr\u003eID: liu-etal-2024-evaluating-moral\u003cbr\u003eSubtopics: moral, cultural, bias\u003cbr\u003eYear: 2025","Paper: Story Morals: Surfacing value-driven narrative\u003cbr\u003eschemas using large language models\u003cbr\u003eID: hobson-etal-2024-story\u003cbr\u003eSubtopics: moral, cultural\u003cbr\u003eYear: 2025","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2025","Paper: {D}3{CODE}: Disentangling Disagreements in Data\u003cbr\u003eacross Cultures on Offensiveness Detection and\u003cbr\u003eEvaluation\u003cbr\u003eID: mostafazadeh-davani-etal-2024-d3code\u003cbr\u003eSubtopics: moral, cultural, diversity\u003cbr\u003eYear: 2025","Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2025","Paper: Probabilistic Aggregation and Targeted Embedding\u003cbr\u003eOptimization for Collective Moral Reasoning in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: yuan-etal-2025-probabilistic\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Comparing Moral Values in {W}estern {E}nglish-\u003cbr\u003espeaking societies and {LLM}s with Word\u003cbr\u003eAssociations\u003cbr\u003eID: xiang-etal-2025-comparing\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Deontological Keyword Bias: The Impact of Modal\u003cbr\u003eExpressions on Normative Judgments of Language\u003cbr\u003eModels\u003cbr\u003eID: park-etal-2025-deontological\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Exploring {LLM}s' Ability to Spontaneously and\u003cbr\u003eConditionally Modify Moral Expressions through\u003cbr\u003eText Manipulation\u003cbr\u003eID: greco-etal-2025-exploring\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2025","Paper: Moral Disagreement over Serious Matters:\u003cbr\u003eDiscovering the Knowledge Hidden in the\u003cbr\u003ePerspectives\u003cbr\u003eID: alvarez-nogales-araque-2024-moral\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025","Paper: {MOKA}: Moral Knowledge Augmentation for Moral\u003cbr\u003eEvent Extraction\u003cbr\u003eID: zhang-etal-2024-moka\u003cbr\u003eSubtopics: moral\u003cbr\u003eYear: 2025"],"legendgroup":"moral","marker":{"color":"rgb(215, 226, 53)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"moral (20)","showlegend":false,"x":{"dtype":"f8","bdata":"68a3T6jlBMCq6kxMUT7vvwU2Trdf3QTAZM4Z34pP0j9PoxYdeqsGwBZ6u1PJ4QrA+grNw6wfC8D\u002f00eGSV3tP9ed\u002f6+B3+w\u002f8LUOMIU1dr93ngB5Mn\u002fBP1wKL2rS1Mo\u002f+gLOUxKx1z\u002fFfTwVMuwIwIw\u002fwSWDdwfA1rsYs3cPA8Araltgp+IFwBSZ0lujT9c\u002f9QMK1JwUCcDPqCvJSlYFwA=="},"y":{"dtype":"f8","bdata":"3QC14EyZ7r9uOfrH6lMCwFNqqc\u002flQPC\u002fdxt2xNEE4L\u002fYXIRHESP3vyh0pvXRMO6\u002fYi09sgBx6r\u002fo5Ark8XHRv7KNgAwPaM6\u002f4aFqx4N427+6Zds8lM30v0lOSDiMju8\u002f3F\u002fTPy2O9r\u002faqU+7\u002fnH2v\u002fj2UO7Xg\u002fW\u002fp9FcVCYq7b81RiGVYAXuv+OPWUrs2Oy\u002fOK0XcOgE6r9GGRNZrvbqvw=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2025","Paper: Got Compute, but No Data: {Lessons} From Post-\u003cbr\u003etraining a {Finnish} {LLM}\u003cbr\u003eID: zosa-etal-2025-got\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2025","Paper: High-Dimension Human Value Representation in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: cahyawijaya-etal-2025-high\u003cbr\u003eSubtopics: cultural, multilingual\u003cbr\u003eYear: 2025","Paper: Reuse Your Rewards: Reward Model Transfer for\u003cbr\u003eZero-Shot Cross-Lingual Alignment\u003cbr\u003eID: wu-etal-2024-reuse\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2025","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2025","Paper: {RLHF} Can Speak Many Languages: Unlocking\u003cbr\u003eMultilingual Preference Optimization for {LLM}s\u003cbr\u003eID: dang-etal-2024-rlhf\u003cbr\u003eSubtopics: multilingual\u003cbr\u003eYear: 2025"],"legendgroup":"multilingual","marker":{"color":"rgb(235, 206, 57)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"multilingual (6)","showlegend":false,"x":{"dtype":"f8","bdata":"auG2nAEV4b+WB0QxRNn7v+uW4EWyB8A\u002fEx+WD4vwAsDrGfNqvcblPwvyZPhzgwbA"},"y":{"dtype":"f8","bdata":"8Sp+ww6hAsBdCtmKRKoDwPJWSci48+C\u002f8tYxZUX3+b+yk0OfotHzv4Kqrn3kvvi\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Exploring Boundaries and Intensities in Offensive\u003cbr\u003eand Hate Speech: Unveiling the Complex Spectrum of\u003cbr\u003eSocial Media Discourse\u003cbr\u003eID: ayele-etal-2024-exploring\u003cbr\u003eSubtopics: offensiveness\u003cbr\u003eYear: 2025"],"legendgroup":"offensiveness","marker":{"color":"rgb(247, 184, 54)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"offensiveness (1)","showlegend":false,"x":{"dtype":"f8","bdata":"vQUUUkLA+L8="},"y":{"dtype":"f8","bdata":"KDHFwPwf\u002fL8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Distributional Alignment of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: meister-etal-2025-benchmarking\u003cbr\u003eSubtopics: opinions, demographics\u003cbr\u003eYear: 2025","Paper: Evaluating Large Language Model Biases in Persona-\u003cbr\u003eSteered Generation\u003cbr\u003eID: liu-etal-2024-evaluating-large\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2025","Paper: {LLM} Tropes: Revealing Fine-Grained Values and\u003cbr\u003eOpinions in Large Language Models\u003cbr\u003eID: wright-etal-2024-llm\u003cbr\u003eSubtopics: demographics, opinions, bias\u003cbr\u003eYear: 2025"],"legendgroup":"opinions","marker":{"color":"rgb(253, 159, 46)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"opinions (4)","showlegend":false,"x":{"dtype":"f8","bdata":"7oLxE9\u002fx4D8OBk\u002fgLsHsP4z\u002fgG3Db7o\u002f6IKFBfKu8j8="},"y":{"dtype":"f8","bdata":"25UyQPuK4L\u002fHbruRaubSv9hG\u002f6qWCQTALeqBTQpo5r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2025","Paper: {C}om{PO}: Community Preferences for Language\u003cbr\u003eModel Personalization\u003cbr\u003eID: kumar-etal-2025-compo\u003cbr\u003eSubtopics: personalization, diversity\u003cbr\u003eYear: 2025","Paper: Beyond Excess and Deficiency: Adaptive Length Bias\u003cbr\u003eMitigation in Reward Models for {RLHF}\u003cbr\u003eID: bu-etal-2025-beyond\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {ABLE}: Personalized Disability Support with\u003cbr\u003ePoliteness and Empathy Integration\u003cbr\u003eID: mishra-etal-2024-able\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {D}ecipher{P}ref: Analyzing Influential Factors in\u003cbr\u003eHuman Preference Judgments via {GPT}-4\u003cbr\u003eID: hu-etal-2023-decipherpref\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Audience-Centric Natural Language Generation via\u003cbr\u003eStyle Infusion\u003cbr\u003eID: moorjani-etal-2022-audience\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Bridging Cultural Nuances in Dialogue Agents\u003cbr\u003ethrough Cultural Value Surveys\u003cbr\u003eID: cao-etal-2024-bridging\u003cbr\u003eSubtopics: cultural, personalization\u003cbr\u003eYear: 2025","Paper: From Tarzan to {T}olkien: Controlling the Language\u003cbr\u003eProficiency Level of {LLM}s for Content Generation\u003cbr\u003eID: malik-etal-2024-tarzan\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {BAPO}: Base-Anchored Preference Optimization for\u003cbr\u003eOvercoming Forgetting in Large Language Models\u003cbr\u003ePersonalization\u003cbr\u003eID: lee-etal-2024-bapo\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: On Diversified Preferences of Large Language Model\u003cbr\u003eAlignment\u003cbr\u003eID: zeng-etal-2024-diversified\u003cbr\u003eSubtopics: diversity, personalization\u003cbr\u003eYear: 2025","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2025","Paper: A User-Centric Multi-Intent Benchmark for\u003cbr\u003eEvaluating Large Language Models\u003cbr\u003eID: wang-etal-2024-user\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Learning Personalized Alignment for Evaluating\u003cbr\u003eOpen-ended Text Generation\u003cbr\u003eID: wang-etal-2024-learning-personalized\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Persona-judge: Personalized Alignment of Large\u003cbr\u003eLanguage Models via Token-level Self-judgment\u003cbr\u003eID: zhang-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: A Survey on Personalized {A}lignment{---}{T}he\u003cbr\u003eMissing Piece for Large Language Models in Real-\u003cbr\u003eWorld Applications\u003cbr\u003eID: guan-etal-2025-survey\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: The Reader is the Metric: How Textual Features and\u003cbr\u003eReader Profiles Explain Conflicting Evaluations of\u003cbr\u003e{AI} Creative Writing\u003cbr\u003eID: marco-etal-2025-reader\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Enhancing Persona Consistency for {LLM}s' Role-\u003cbr\u003ePlaying using Persona-Aware Contrastive Learning\u003cbr\u003eID: ji-etal-2025-enhancing\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Disentangling Preference Representation and Text\u003cbr\u003eGeneration for Efficient Individual Preference\u003cbr\u003eAlignment\u003cbr\u003eID: zhang-etal-2025-disentangling\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Persona-Consistent Dialogue Generation via Pseudo\u003cbr\u003ePreference Tuning\u003cbr\u003eID: takayama-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Aligning {LLM}s with Individual Preferences via\u003cbr\u003eInteraction\u003cbr\u003eID: wu-etal-2025-aligning\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Engagement-driven Persona Prompting for Rewriting\u003cbr\u003eNews Tweets\u003cbr\u003eID: gopalakrishna-pillai-etal-2025-engagement\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {PERSONA}: A Reproducible Testbed for Pluralistic\u003cbr\u003eAlignment\u003cbr\u003eID: castricato-etal-2025-persona\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Using {LLM}s to improve {RL} policies in\u003cbr\u003epersonalized health adaptive interventions\u003cbr\u003eID: karine-marlin-2025-using\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {MAPS}: Motivation-Aware Personalized Search via\u003cbr\u003e{LLM}-Driven Consultation Alignment\u003cbr\u003eID: qin-etal-2025-maps\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Whose Boat Does it Float? Improving\u003cbr\u003ePersonalization in Preference Tuning via Inferred\u003cbr\u003eUser Personas\u003cbr\u003eID: balepur-etal-2025-whose\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Know You First and Be You Better: Modeling Human-\u003cbr\u003eLike User Simulators via Implicit Profiles\u003cbr\u003eID: wang-etal-2025-know\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Evaluating Personalized Tool-Augmented {LLM}s from\u003cbr\u003ethe Perspectives of Personalization and\u003cbr\u003eProactivity\u003cbr\u003eID: hao-etal-2025-evaluating\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Comparison-based Active Preference Learning for\u003cbr\u003eMulti-dimensional Personalization\u003cbr\u003eID: oh-etal-2025-comparison\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: {G}reater{P}rompt: A Unified, Customizable, and\u003cbr\u003eHigh-Performing Open-Source Toolkit for Prompt\u003cbr\u003eOptimization\u003cbr\u003eID: zheng-etal-2025-greaterprompt\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025","Paper: Detecting Mode Collapse in Language Models via\u003cbr\u003eNarration\u003cbr\u003eID: hamilton-2024-detecting\u003cbr\u003eSubtopics: personalization\u003cbr\u003eYear: 2025"],"legendgroup":"personalization","marker":{"color":"rgb(248, 127, 33)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"personalization (31)","showlegend":false,"x":{"dtype":"f8","bdata":"wQang4AWvD\u002fWDyKPNmnpP4mLlRKcqOi\u002ftIkjpA967r8wPNgIkufXv26Kg1gzMOy\u002f3nAKtTuh7T\u002f0ci7qMYvhv3AZkTewJbM\u002f8D5wFK10vD+mpSBMOQLzP6QHaa2Xw9a\u002fp84SKzH+6b+GJCoOOjbnvyrwHt90E+6\u002fYr18u+JZ5r94UrmXlGTwvzB6zXzJD6K\u002fy5ITwQD55b8A7QLODDfov9KPAosXtue\u002fDPaLbMhM57+GqYdT2afcv0iP7FLmGs6\u002fSDtT1Elm67\u002fNu+cTuobcv5SagjMLuMC\u002fJFX4cfVD57\u002ff4u9B95Tev7u7BhYsF\u002fY\u002f20FXd7UD4L8="},"y":{"dtype":"f8","bdata":"thiDDQ8wBsDAGB0Lke7APw+f6Dr64gXAl3t4xuMvCsAM\u002fvU3HLcIwGco6iziIAbAzGpOotH287\u002fEXC8kRvcFwGIDNWQAdAfATL+122+bzD\u002fUEjqpXiztv1pxrcK1bgjAG7I3vohKCcBEj2uw4qgIwEDJtV\u002frRArAEVBX+XFbBcCGBoZlLnwDwLMYFubWPQrAeDsFt2THBcCColp7fPAIwB4EdaBBdwXAGtRLtB\u002fJBMAr+Gcp0HUIwAZDt4SNSwnAPkjlMgEZCcB1BybxbusEwDs0tRlUSQfAoW1IGpGeBcDjzrmCnNgGwMHPm1qC5OK\u002fs+FCnR65C8A="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: How Gender Interacts with Political Values: A Case\u003cbr\u003eStudy on {C}zech {BERT} Models\u003cbr\u003eID: al-ali-libovicky-2024-gender\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2025","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2025","Paper: Hidden Persuaders: {LLM}s' Political Leaning and\u003cbr\u003eTheir Influence on Voters\u003cbr\u003eID: potter-etal-2024-hidden\u003cbr\u003eSubtopics: political, bias\u003cbr\u003eYear: 2025","Paper: On the Relationship between Truth and Political\u003cbr\u003eBias in Language Models\u003cbr\u003eID: fulay-etal-2024-relationship\u003cbr\u003eSubtopics: political, factuality, bias\u003cbr\u003eYear: 2025","Paper: Moral Foundations of Large Language Models\u003cbr\u003eID: abdulhai-etal-2024-moral\u003cbr\u003eSubtopics: moral, political, bias\u003cbr\u003eYear: 2025","Paper: Beyond Prompt Brittleness: Evaluating the\u003cbr\u003eReliability and Consistency of Political\u003cbr\u003eWorldviews in {LLM}s\u003cbr\u003eID: ceron-etal-2024-beyond\u003cbr\u003eSubtopics: political\u003cbr\u003eYear: 2025"],"legendgroup":"political","marker":{"color":"rgb(241, 95, 20)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"political (6)","showlegend":false,"x":{"dtype":"f8","bdata":"LD+I6qI19D+QHvLUawr8P3cugkLNw\u002fs\u002fOuEMhIvI8T93ngB5Mn\u002fBPxurjxNpAOC\u002f"},"y":{"dtype":"f8","bdata":"cQOSsAOo+r\u002fI2xyZbcf9v17DsXTZvfi\u002fT1FIF70yzT+6Zds8lM30vwfr7yjlgQbA"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Smaller Large Language Models Can Do Moral Self-\u003cbr\u003eCorrection\u003cbr\u003eID: liu-etal-2025-smaller\u003cbr\u003eSubtopics: moral, safety\u003cbr\u003eYear: 2025","Paper: {I}nstruction{CP}: A Simple yet Effective Approach\u003cbr\u003efor Transferring Large Language Models to Target\u003cbr\u003eLanguages\u003cbr\u003eID: chen-etal-2025-instructioncp\u003cbr\u003eSubtopics: safety, multilingual\u003cbr\u003eYear: 2025","Paper: Unlocking Decoding-time Controllability: Gradient-\u003cbr\u003eFree Multi-Objective Alignment with Contrastive\u003cbr\u003ePrompts\u003cbr\u003eID: fu-etal-2025-unlocking\u003cbr\u003eSubtopics: safety, personalization\u003cbr\u003eYear: 2025","Paper: {S}eq{AR}: Jailbreak {LLM}s with Sequential Auto-\u003cbr\u003eGenerated Characters\u003cbr\u003eID: yang-etal-2025-seqar\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {DPL}: Diverse Preference Learning Without A\u003cbr\u003eReference Model\u003cbr\u003eID: nath-etal-2025-dpl\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2025","Paper: Navigating the Cultural Kaleidoscope: A\u003cbr\u003eHitchhiker{'}s Guide to Sensitivity in Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: banerjee-etal-2025-navigating\u003cbr\u003eSubtopics: cultural, safety\u003cbr\u003eYear: 2025","Paper: Multilingual Blending: Large Language Model Safety\u003cbr\u003eAlignment Evaluation with Language Mixture\u003cbr\u003eID: song-etal-2025-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: An Optimizable Suffix Is Worth A Thousand\u003cbr\u003eTemplates: Efficient Black-box Jailbreaking\u003cbr\u003ewithout Affirmative Phrases via {LLM} as Optimizer\u003cbr\u003eID: jiang-etal-2025-optimizable\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Safety Arithmetic: A Framework for Test-time\u003cbr\u003eSafety Alignment of Language Models by Steering\u003cbr\u003eParameters and Activations\u003cbr\u003eID: hazra-etal-2024-safety\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Gradient-Based Language Model Red Teaming\u003cbr\u003eID: wichers-etal-2024-gradient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {RLHFP}oison: Reward Poisoning Attack for\u003cbr\u003eReinforcement Learning with Human Feedback in\u003cbr\u003eLarge Language Models\u003cbr\u003eID: wang-etal-2024-rlhfpoison\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Jailbreak Open-Sourced Large Language Models via\u003cbr\u003eEnforced Decoding\u003cbr\u003eID: zhang-etal-2024-jailbreak\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {S}afe{D}ecoding: Defending against Jailbreak\u003cbr\u003eAttacks via Safety-Aware Decoding\u003cbr\u003eID: xu-etal-2024-safedecoding\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Defending Against Alignment-Breaking Attacks via\u003cbr\u003eRobustly Aligned {LLM}\u003cbr\u003eID: cao-etal-2024-defending\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Course-Correction: Safety Alignment Using\u003cbr\u003eSynthetic Preferences\u003cbr\u003eID: xu-etal-2024-course\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Intent-Aware and Hate-Mitigating Counterspeech\u003cbr\u003eGeneration via Dual-Discriminator Guided {LLM}s\u003cbr\u003eID: wang-etal-2024-intent\u003cbr\u003eSubtopics: safety, hate\u003cbr\u003eYear: 2025","Paper: {UNIWIZ}: A Unified Large Language Model\u003cbr\u003eOrchestrated Wizard for Safe Knowledge Grounded\u003cbr\u003eConversations\u003cbr\u003eID: das-srihari-2024-uniwiz\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2025","Paper: The Language Barrier: Dissecting Safety Challenges\u003cbr\u003eof {LLM}s in Multilingual Contexts\u003cbr\u003eID: shen-etal-2024-language\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Adversarial Preference Optimization: Enhancing\u003cbr\u003eYour Alignment via {RM}-{LLM} Game\u003cbr\u003eID: cheng-etal-2024-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: A Comprehensive Study of Jailbreak Attack versus\u003cbr\u003eDefense for Large Language Models\u003cbr\u003eID: xu-etal-2024-comprehensive\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: On the Vulnerability of Safety Alignment in Open-\u003cbr\u003eAccess {LLM}s\u003cbr\u003eID: yi-etal-2024-vulnerability\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Beyond One-Preference-Fits-All Alignment: Multi-\u003cbr\u003eObjective Direct Preference Optimization\u003cbr\u003eID: zhou-etal-2024-beyond\u003cbr\u003eSubtopics: safety, diversity\u003cbr\u003eYear: 2025","Paper: {C}ode{A}ttack: Revealing Safety Generalization\u003cbr\u003eChallenges of Large Language Models via Code\u003cbr\u003eCompletion\u003cbr\u003eID: ren-etal-2024-codeattack\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Reasons to Reject? Aligning Language Models with\u003cbr\u003eJudgments\u003cbr\u003eID: xu-etal-2024-reasons\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: From Representational Harms to Quality-of-Service\u003cbr\u003eHarms: A Case Study on Llama 2 Safety Safeguards\u003cbr\u003eID: chehbouni-etal-2024-representational\u003cbr\u003eSubtopics: demographics, safety, bias\u003cbr\u003eYear: 2025","Paper: Negating Negatives: Alignment with Human Negative\u003cbr\u003eSamples via Distributional Dispreference\u003cbr\u003eOptimization\u003cbr\u003eID: duan-etal-2024-negating\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Exploring Multilingual Concepts of Human Values in\u003cbr\u003eLarge Language Models: Is Value Alignment\u003cbr\u003eConsistent, Transferable and Controllable across\u003cbr\u003eLanguages?\u003cbr\u003eID: xu-etal-2024-exploring-multilingual\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Defending Large Language Models Against Jailbreak\u003cbr\u003eAttacks via Layer-specific Editing\u003cbr\u003eID: zhao-etal-2024-defending-large\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {PURE}: Aligning {LLM} via Pluggable Query\u003cbr\u003eReformulation for Enhanced Helpfulness\u003cbr\u003eID: yao-etal-2024-pure\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: A {LLM}-based Ranking Method for the Evaluation of\u003cbr\u003eAutomatic Counter-Narrative Generation\u003cbr\u003eID: zubiaga-etal-2024-llm\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Towards Effective Counter-Responses: Aligning\u003cbr\u003eHuman Preferences with Strategies to Combat Online\u003cbr\u003eTrolling\u003cbr\u003eID: lee-etal-2024-towards-effective\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Towards Tool Use Alignment of Large Language\u003cbr\u003eModels\u003cbr\u003eID: chen-etal-2024-towards-tool\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Controllable Preference Optimization: Toward\u003cbr\u003eControllable Multi-Objective Alignment\u003cbr\u003eID: guo-etal-2024-controllable\u003cbr\u003eSubtopics: safety, factuality\u003cbr\u003eYear: 2025","Paper: Alignment-Enhanced Decoding: Defending Jailbreaks\u003cbr\u003evia Token-Level Adaptive Refining of Probability\u003cbr\u003eDistributions\u003cbr\u003eID: liu-etal-2024-alignment\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: The Multilingual Alignment Prism: Aligning Global\u003cbr\u003eand Local Preferences to Reduce Harm\u003cbr\u003eID: aakanksha-etal-2024-multilingual\u003cbr\u003eSubtopics: cultural, multilingual, safety\u003cbr\u003eYear: 2025","Paper: Holistic Automated Red Teaming for Large Language\u003cbr\u003eModels through Top-Down Test Case Generation and\u003cbr\u003eMulti-turn Interaction\u003cbr\u003eID: zhang-etal-2024-holistic\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Distract Large Language Models for Automatic\u003cbr\u003eJailbreak Attack\u003cbr\u003eID: xiao-etal-2024-distract\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Adversarial Preference Learning for Robust {LLM}\u003cbr\u003eAlignment\u003cbr\u003eID: wang-etal-2025-adversarial\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Towards Safety Reasoning in {LLM}s: {AI}-agentic\u003cbr\u003eDeliberation for Policy-embedded {C}o{T} Data\u003cbr\u003eCreation\u003cbr\u003eID: kumarage-etal-2025-towards\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {DIESEL}: A Lightweight Inference-Time Safety\u003cbr\u003eEnhancement for Language Models\u003cbr\u003eID: ganon-etal-2025-diesel\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Don{'}t Say No: Jailbreaking {LLM} by Suppressing\u003cbr\u003eRefusal\u003cbr\u003eID: zhou-etal-2025-dont\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Intention Analysis Makes {LLM}s A Good Jailbreak\u003cbr\u003eDefender\u003cbr\u003eID: zhang-etal-2025-intention\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Unraveling the Mystery: Defending Against\u003cbr\u003eJailbreak Attacks Via Unearthing Real Intention\u003cbr\u003eID: li-etal-2025-unraveling\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Mixture of insigh{T}ful Experts ({M}o{TE}): The\u003cbr\u003eSynergy of Reasoning Chains and Expert Mixtures in\u003cbr\u003eSelf-Alignment\u003cbr\u003eID: liu-etal-2025-mixture\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Safer or Luckier? {LLM}s as Safety Evaluators Are\u003cbr\u003eNot Robust to Artifacts\u003cbr\u003eID: chen-goldfarb-tarrant-2025-safer\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Small Changes, Big Impact: How Manipulating a Few\u003cbr\u003eNeurons Can Drastically Alter {LLM} Aggression\u003cbr\u003eID: lee-etal-2025-small\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {MPO}: Multilingual Safety Alignment via Reward\u003cbr\u003eGap Optimization\u003cbr\u003eID: zhao-etal-2025-mpo\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {MTSA}: Multi-turn Safety Alignment for {LLM}s\u003cbr\u003ethrough Multi-round Red-teaming\u003cbr\u003eID: guo-etal-2025-mtsa\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {LSSF}: Safety Alignment for Large Language Models\u003cbr\u003ethrough Low-Rank Safety Subspace Fusion\u003cbr\u003eID: zhou-etal-2025-lssf\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Efficient Safety Alignment of Large Language\u003cbr\u003eModels via Preference Re-ranking and\u003cbr\u003eRepresentation-based Reward Modeling\u003cbr\u003eID: qiyuan-etal-2025-efficient\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: {PKU}-{S}afe{RLHF}: Towards Multi-Level Safety\u003cbr\u003eAlignment for {LLM}s with Human Preference\u003cbr\u003eID: ji-etal-2025-pku\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Guardrails and Security for {LLM}s: Safe, Secure\u003cbr\u003eand Controllable Steering of {LLM} Applications\u003cbr\u003eID: rebedea-etal-2025-guardrails\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Ensuring Safe and High-Quality Outputs: A\u003cbr\u003eGuideline Library Approach for Language Models\u003cbr\u003eID: luo-etal-2024-ensuring\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: {I}ter{A}lign: Iterative Constitutional Alignment\u003cbr\u003eof Large Language Models\u003cbr\u003eID: chen-etal-2024-iteralign\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2025","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2025","Paper: Stealthy and Persistent Unalignment on Large\u003cbr\u003eLanguage Models via Backdoor Injections\u003cbr\u003eID: cao-etal-2024-stealthy\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025","Paper: Safer-Instruct: Aligning Language Models with\u003cbr\u003eAutomated Preference Data\u003cbr\u003eID: shi-etal-2024-safer\u003cbr\u003eSubtopics: safety, general\u003cbr\u003eYear: 2025","Paper: Removing {RLHF} Protections in {GPT}-4 via Fine-\u003cbr\u003eTuning\u003cbr\u003eID: zhan-etal-2024-removing\u003cbr\u003eSubtopics: safety\u003cbr\u003eYear: 2025"],"legendgroup":"safety","marker":{"color":"rgb(226, 70, 11)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"safety (62)","showlegend":false,"x":{"dtype":"f8","bdata":"qupMTFE+779q4bacARXhv8EGp4OAFrw\u002ffi35kJr98D8CWot6DjDzP1X8P5lHs\u002f8\u002f8S2qazyV\u002fD+RP1E2zVvrP\u002fpM9voOOug\u002fku4UjDl08D\u002f4yMQn8tPoPwOERLby3Oc\u002fGEewQAEa4D+vXNMyQY3rP8WIVHn+mvM\u002fzUuLhWFh6T\u002f6g+QYvWXmvyOlDGkDkuE\u002f\u002f2nKgQtg+T9ih93iz5f4P0J7Xlv2Auc\u002fLlQqbNdg8T+oMJAjSd\u002f3P7yCRBl\u002fPPA\u002fqWP82raI7j\u002fDkNa4Hf8BQN802vhsm\u002fI\u002fS2s6t5377T\u002fjotKmcSDxPxBy9KtJUuY\u002fMXlcZ6\u002fV7D++6hfwNOf5PzdGopByDPU\u002fHBCyEgPa5D+Or5\u002fLs+rmP+sZ82q9xuU\u002fKpauDpa+9D97htYeFgXlP\u002f8gYNP2Ve0\u002fEd4xI9Lv6T\u002fF2cxiD\u002fXlP+qP2geehdg\u002ffip1epgB6D8Rcck2MvflP9I3C8\u002f4WfU\u002fCcd+u31L\u002fz8spqFdpJjzP6e5\u002f0F9ZOg\u002fOyp4V10K5z9KlL5vPhvxPzVd6awFCvI\u002fa\u002fYUdRaS3D8lGENMyzv5P7bQiPpohu4\u002fDdBGJTBc\u002fD8DXSPtRZnqP83X92\u002fIBt4\u002fU7KR5jIRAEDzn3Rgqnb+P5Do3lR5l9Q\u002f6cbWENcC0b8nE\u002fw\u002f\u002fdTnPw=="},"y":{"dtype":"f8","bdata":"bjn6x+pTAsDxKn7DDqECwLYYgw0PMAbA9\u002fj8u59KCcByyShLttDKvySecUhJ5QHArXT4u0TU8r97SKy5W50KwJrtOFrz\u002fQfASCBP6ExcBMD0HfFinYQGwHBJB69KJQLAikRV3MZwCMAiipbXBM0GwAFBc7ZReQXAyINEO0jTB8DcfE2DK6PUvyr1beIr\u002ftW\u002fuKiPw76SA8C0wqCQO0sGwPKvb4aY2wjAkOAsiNe6CsA8mPsgI\u002fyuP0u84B8PQgLAgv7CZMNwB8Dd6q8EQU\u002fdv2KLiQL4hQXAHX6ZaiWVCMCbywlVXJkGwFQLKcyfmQPAOHH8J\u002fhfBcDFh8Ayky4GwPpI6ocDrQfAOijzHMhoq7+EPJ6hHXkJwLKTQ5+i0fO\u002fVU3yrGB0B8BPp0IC+J4KwDuvxX6gygXAJwoTCn05A8CpLVfKze8JwBwQ1zJZLgbA9pjwUyfdAcCp1SCKLPkFwH9nLEFKwAPAuR97S50M\u002f7+Mv46Pfy8FwN7vkk+U6gfALhkSnahgBsALcs6pZcoGwIN8PMuodgrAu9j\u002fexy5BcCrfmJBTk\u002f6v39RTcMZJQbAgGtJv7MzCMBiVVvtXwoJwESGd+ihRwfAh9dOHHOj\u002fL9CNBN2F+b\u002fvyK2nn7AfAPAcPAPrKlR5b8T6lUNZMoGwA=="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Adaptable Moral Stances of Large Language Models\u003cbr\u003eon Sexist Content: Implications for Society and\u003cbr\u003eGender Discourse\u003cbr\u003eID: guo-etal-2024-adaptable\u003cbr\u003eSubtopics: moral, sexism, bias\u003cbr\u003eYear: 2025"],"legendgroup":"sexism","marker":{"color":"rgb(207, 48, 5)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"sexism (1)","showlegend":false,"x":{"dtype":"f8","bdata":"+gLOUxKx1z8="},"y":{"dtype":"f8","bdata":"3F\u002fTPy2O9r8="},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Do Large Language Models Learn Human-Like\u003cbr\u003eStrategic Preferences?\u003cbr\u003eID: roberts-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Team Conversational {AI}: Introducing Effervesce\u003cbr\u003eID: skenderi-etal-2025-team\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {G}uide{LLM}: Exploring {LLM}-Guided Conversation\u003cbr\u003ewith Applications in Autobiography Interviewing\u003cbr\u003eID: duan-etal-2025-guidellm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {R}esearch{A}gent: Iterative Research Idea\u003cbr\u003eGeneration over Scientific Literature with Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: baek-etal-2025-researchagent\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Northeastern Uni at Multilingual Counterspeech\u003cbr\u003eGeneration: Enhancing Counter Speech Generation\u003cbr\u003ewith {LLM} Alignment through Direct Preference\u003cbr\u003eOptimization\u003cbr\u003eID: wadhwa-etal-2025-northeastern\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {CBBQ}: A {C}hinese Bias Benchmark Dataset Curated\u003cbr\u003ewith Human-{AI} Collaboration for Large Language\u003cbr\u003eModels\u003cbr\u003eID: huang-xiong-2024-cbbq\u003cbr\u003eSubtopics: cultural, social, bias\u003cbr\u003eYear: 2025","Paper: {P}op{ALM}: Popularity-Aligned Language Models for\u003cbr\u003eSocial Media Trendy Response Prediction\u003cbr\u003eID: yu-etal-2024-popalm\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: {K}or{NAT}: {LLM} Alignment Benchmark for {K}orean\u003cbr\u003eSocial Values and Common Knowledge\u003cbr\u003eID: lee-etal-2024-kornat\u003cbr\u003eSubtopics: social, cultural\u003cbr\u003eYear: 2025","Paper: Rater Cohesion and Quality from a Vicarious\u003cbr\u003ePerspective\u003cbr\u003eID: pandita-etal-2024-rater\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: The Potential and Challenges of Evaluating\u003cbr\u003eAttitudes, Opinions, and Values in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ma-etal-2024-potential\u003cbr\u003eSubtopics: social, opinions\u003cbr\u003eYear: 2025","Paper: From Pixels to Personas: Investigating and\u003cbr\u003eModeling Self-Anthropomorphism in Human-Robot\u003cbr\u003eDialogues\u003cbr\u003eID: li-etal-2024-pixels\u003cbr\u003eSubtopics: social, ethical, personalization\u003cbr\u003eYear: 2025","Paper: {S}ocial{G}aze: Improving the Integration of Human\u003cbr\u003eSocial Norms in Large Language Models\u003cbr\u003eID: vijjini-etal-2024-socialgaze\u003cbr\u003eSubtopics: demographics, social, bias\u003cbr\u003eYear: 2025","Paper: Systematic Biases in {LLM} Simulations of Debates\u003cbr\u003eID: taubenfeld-etal-2024-systematic\u003cbr\u003eSubtopics: social, political, bias\u003cbr\u003eYear: 2025","Paper: Large Language Models with Reinforcement Learning\u003cbr\u003efrom Human Feedback Approach for Enhancing\u003cbr\u003eExplainable Sexism Detection\u003cbr\u003eID: riahi-samani-etal-2025-large\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Hire Me or Not? Examining Language Model{'}s\u003cbr\u003eBehavior with Occupation Attributes\u003cbr\u003eID: zhang-etal-2025-hire\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Veracity Bias and Beyond: Uncovering {LLM}s'\u003cbr\u003eHidden Beliefs in Problem-Solving Reasoning\u003cbr\u003eID: zhou-di-eugenio-2025-veracity\u003cbr\u003eSubtopics: social, demographics\u003cbr\u003eYear: 2025","Paper: Aligned but Blind: Alignment Increases Implicit\u003cbr\u003eBias by Reducing Awareness of Race\u003cbr\u003eID: sun-etal-2025-aligned\u003cbr\u003eSubtopics: social\u003cbr\u003eYear: 2025","Paper: Think Again! The Effect of Test-Time Compute on\u003cbr\u003ePreferences, Opinions, and Beliefs of Large\u003cbr\u003eLanguage Models\u003cbr\u003eID: kour-etal-2025-think\u003cbr\u003eSubtopics: social, cultural, ethical, personalization\u003cbr\u003eYear: 2025"],"legendgroup":"social","marker":{"color":"rgb(184, 30, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"social (18)","showlegend":false,"x":{"dtype":"f8","bdata":"xCMnWA9XAECilwv8MS8AQD0\u002f3FYRNgFAynAF79Do+T907UctEVEDQEK6uOaLOwNAWlZeeZseAECnzcoPxQIDQCGfosW92wRAjP+AbcNvuj+mpSBMOQLzPy\u002fxjFTxVwJAkB7y1GsK\u002fD9Ml1TkGUYEQLhAuQsQWgNAZD9joH4FBECoOmq6BtYBQLu7BhYsF\u002fY\u002f"},"y":{"dtype":"f8","bdata":"nSehjsBzAsCpUCA2Lxb\u002fv88uOyFwBALAdacq6LwFAcASWtdcKTYEwIxaYF47Ytu\u002fOWnTaT+YAMCkCZEibG3rv+RFdlisvdi\u002f2Eb\u002fqpYJBMDUEjqpXiztv67VwESb8bO\u002fyNscmW3H\u002fb+EoFo3qgn9vyUvhHM1eP+\u002fiDQzTYOvkz+233H5xRYCwMHPm1qC5OK\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Model Surgery: Modulating {LLM}{'}s Behavior Via\u003cbr\u003eSimple Parameter Editing\u003cbr\u003eID: wang-etal-2025-model\u003cbr\u003eSubtopics: safety, toxicity\u003cbr\u003eYear: 2025","Paper: Enhancing Reinforcement Learning with Dense\u003cbr\u003eRewards from Language Model Critic\u003cbr\u003eID: cao-etal-2024-enhancing\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2025","Paper: Towards Aligning Language Models with Textual\u003cbr\u003eFeedback\u003cbr\u003eID: lloret-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2025","Paper: Towards Healthy {AI}: Large Language Models Need\u003cbr\u003eTherapists Too\u003cbr\u003eID: lin-etal-2024-towards\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2025","Paper: Aligning as Debiasing: Causality-Aware Alignment\u003cbr\u003evia Reinforcement Learning with Interventional\u003cbr\u003eFeedback\u003cbr\u003eID: xia-etal-2024-aligning\u003cbr\u003eSubtopics: toxicity, safety\u003cbr\u003eYear: 2025","Paper: A Multi-Aspect Framework for Counter Narrative\u003cbr\u003eEvaluation using Large Language Models\u003cbr\u003eID: jones-etal-2024-multi\u003cbr\u003eSubtopics: toxicity\u003cbr\u003eYear: 2025"],"legendgroup":"toxicity","marker":{"color":"rgb(154, 16, 1)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"toxicity (6)","showlegend":false,"x":{"dtype":"f8","bdata":"Vfw\u002fmUez\u002fz\u002f8\u002fpTUbXwJQKAe8+FFAgZA3g4Bkwx8BUDzn3Rgqnb+P5YwYDS4RgNA"},"y":{"dtype":"f8","bdata":"JJ5xSEnlAcAeDuROpkr\u002fv+Tq7p7gNO2\u002f9KxT2j9z+b9CNBN2F+b\u002fv3I1u5ujHv+\u002f"},"type":"scatter"},{"hoverinfo":"text","hovertext":["Paper: Benchmarking Multi-National Value Alignment for\u003cbr\u003eLarge Language Models\u003cbr\u003eID: ju-etal-2025-benchmarking\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Are the Values of {LLM}s Structurally Aligned with\u003cbr\u003eHumans? A Causal Perspective\u003cbr\u003eID: kang-etal-2025-values\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Do language models practice what they preach?\u003cbr\u003eExamining language ideologies about gendered\u003cbr\u003elanguage reform encoded in {LLM}s\u003cbr\u003eID: watson-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: {CONTRANS}: Weak-to-Strong Alignment Engineering\u003cbr\u003evia Concept Transplantation\u003cbr\u003eID: dong-etal-2025-contrans\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: What{'}s the most important value? {INVP}:\u003cbr\u003e{IN}vestigating the Value Priorities of {LLM}s\u003cbr\u003ethrough Decision-making in Social Scenarios\u003cbr\u003eID: liu-etal-2025-whats\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Can Language Models Reason about Individualistic\u003cbr\u003eHuman Values and Preferences?\u003cbr\u003eID: jiang-etal-2025-language\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Generative Psycho-Lexical Approach for\u003cbr\u003eConstructing Value Systems in Large Language\u003cbr\u003eModels\u003cbr\u003eID: ye-etal-2025-generative\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Value Portrait: Assessing Language Models' Values\u003cbr\u003ethrough Psychometrically and Ecologically Valid\u003cbr\u003eItems\u003cbr\u003eID: han-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Mining the uncertainty patterns of humans and\u003cbr\u003emodels in the annotation of moral foundations and\u003cbr\u003ehuman values\u003cbr\u003eID: falk-lapesa-2025-mining\u003cbr\u003eSubtopics: moral, value\u003cbr\u003eYear: 2025","Paper: Internal Value Alignment in Large Language Models\u003cbr\u003ethrough Controlled Value Vector Activation\u003cbr\u003eID: jin-etal-2025-internal\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Towards Better Value Principles for Large Language\u003cbr\u003eModel Alignment: A Systematic Evaluation and\u003cbr\u003eEnhancement\u003cbr\u003eID: xu-etal-2025-towards\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Unintended Harms of Value-Aligned {LLM}s:\u003cbr\u003ePsychological and Empirical Insights\u003cbr\u003eID: choi-etal-2025-unintended\u003cbr\u003eSubtopics: value, safety\u003cbr\u003eYear: 2025","Paper: Value Compass Benchmarks: A Comprehensive,\u003cbr\u003eGenerative and Self-Evolving Platform for {LLM}s'\u003cbr\u003eValue Evaluation\u003cbr\u003eID: yao-etal-2025-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025","Paper: Flames: Benchmarking Value Alignment of {LLM}s in\u003cbr\u003e{C}hinese\u003cbr\u003eID: huang-etal-2024-flames\u003cbr\u003eSubtopics: safety, value\u003cbr\u003eYear: 2025","Paper: Value {FULCRA}: Mapping Large Language Models to\u003cbr\u003ethe Multidimensional Spectrum of Basic Human Value\u003cbr\u003eID: yao-etal-2024-value\u003cbr\u003eSubtopics: value\u003cbr\u003eYear: 2025"],"legendgroup":"value","marker":{"color":"rgb(122, 4, 2)","line":{"color":"black","width":1},"opacity":0.7,"size":12},"mode":"markers","name":"value (15)","showlegend":false,"x":{"dtype":"f8","bdata":"FzBL5HEtCECDaTho\u002fekHQHC94UNuBAVA0Sz9j5PWBUCenfDNaDIKQH0BOPhgqQNACcd+u31L\u002fz9xeGQSRigHQBSZ0lujT9c\u002fUIhHKyLnBkAWZ3tFF34IQCUYQ0zLO\u002fk\u002ffIXs4tSGBEBTspHmMhEAQKrCzStZaQJA"},"y":{"dtype":"f8","bdata":"qoBhFTat47\u002fcf+og00ztvyOStN\u002fbT9y\u002f2oPxC4Jd5r+0TJF6lw3wvzAe8SpGeuK\u002fuR97S50M\u002f7\u002fkMxCEbTbdv+OPWUrs2Oy\u002fkZa\u002f1GnC4b9PM5oM9Gnnv6t+YkFOT\u002fq\u002fkWPoTbF567+H104cc6P8vz5Gyc4VFPG\u002f"},"type":"scatter"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scattermap":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermap"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"font":{"size":16},"text":"Multi-label Clusters (All Years)"},"xaxis":{"range":[-4.5,4.5],"title":{"text":""},"showgrid":true,"gridcolor":"lightgray"},"yaxis":{"range":[-4.5,4.5],"title":{"text":""},"showgrid":true,"gridcolor":"lightgray","scaleanchor":"x","scaleratio":1},"height":800,"width":1000,"hovermode":"closest"},                        {"responsive": true}                    )                };            </script>        </div>
</body>
</html>